{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Franklinyeruan/SSRI_Classification/blob/main/K_Fold_CV_Stacked_Conv_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD9KIKMQhqwW"
      },
      "source": [
        "### Hello There! \n",
        "Below is the code for the paper \"Links Between Antidepressant Use and Physical Movement: Deep Learning Within Ambulatory Actigraphy Data\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWF8UhEhRMZP"
      },
      "source": [
        "## K-Fold CV Stacked Conv-LSTM Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzzQjVsLRRuR"
      },
      "source": [
        "# Set up and Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w7wfhXqR9lf"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShVOAyvLRD_v"
      },
      "outputs": [],
      "source": [
        "# Packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.metrics import AUC\n",
        "\n",
        "# Tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG1IS5pFR-d2"
      },
      "source": [
        "Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1SSPAQWRxXQ"
      },
      "outputs": [],
      "source": [
        "# Random Seed Generation\n",
        "r1 = random.randint(0,100)\n",
        "r2 = random.randint(0,100)\n",
        "\n",
        "# Set Random Seed\n",
        "random.seed(r1)\n",
        "tf.random.set_seed(r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNSwh1jeSBAk"
      },
      "source": [
        "TPU configuration: Ensure that you are connected to a TPU. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4fQlJYsSCF8",
        "outputId": "5cd4e8e5-deee-44fb-aa7e-65b44cfc79cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.76.78.114:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.76.78.114:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
            "c device:  /job:worker/replica:0/task:0/device:TPU:0\n",
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n",
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PerReplica:{\n",
            "  0: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  1: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  2: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  3: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  4: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  5: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  6: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  7: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# @title TPU Configuration\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "# ----------\n",
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(\"c device: \", c.device)\n",
        "print(c)\n",
        "# ----------\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "# ----------\n",
        "@tf.function\n",
        "def matmul_fn(x, y):\n",
        "  z = tf.matmul(x, y)\n",
        "  return z\n",
        "\n",
        "z = strategy.run(matmul_fn, args=(a, b))\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yx1mlI3TEV5"
      },
      "source": [
        "# Data Processing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qOeAs9nTHFv"
      },
      "source": [
        "Load Data. Please ensure you are mounted to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eOTU54rDTF_M"
      },
      "outputs": [],
      "source": [
        "# Load Data X\n",
        "Wide_X = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Data/All_Smooth_Wide_X.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2Lmq_4FaTscf"
      },
      "outputs": [],
      "source": [
        "# Process X --------\n",
        "\n",
        "# Drop Unnamed Column \n",
        "Wide_X = Wide_X.drop(\"Unnamed: 0\", axis = 1)\n",
        "data_wide = Wide_X\n",
        "\n",
        "# Standard Scalar\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(data_wide)\n",
        "data_wide = scaler.transform(data_wide)\n",
        "\n",
        "# Convert DF to array\n",
        "data_wide = np.array(data_wide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ljocU4yqT8h9"
      },
      "outputs": [],
      "source": [
        "# Load Data Y\n",
        "Y = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Data/All_Smooth_Y.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IXwnztnSUTDT"
      },
      "outputs": [],
      "source": [
        "# Process Y --------\n",
        "# Drop Unnamed Column \n",
        "Y = Y.drop(\"Unnamed: 0\", axis = 1)\n",
        "Y.head()\n",
        "\n",
        "# Change to Y Float \n",
        "Y['SSRI'] = Y['Medication'].apply(lambda x: float(x)) \n",
        "\n",
        "#Make y array as well \n",
        "y = np.hstack(np.asarray(Y.SSRI)).reshape(len(Y),1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9h04HzOTUhXo",
        "outputId": "0aca35ee-b3d1-462b-c59b-cb2f6d525ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of X: (7162, 10080)\n",
            "shape of y: (7162, 1)\n"
          ]
        }
      ],
      "source": [
        "# Shape Analysis \n",
        "print(\"shape of X:\", data_wide.shape)\n",
        "print(\"shape of y:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI1GgyOpUwkl"
      },
      "source": [
        "Create a held out test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JoH8XUyqVDA8"
      },
      "outputs": [],
      "source": [
        "# Train Test Split (keep random state in check)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_wide, y, test_size=0.2, stratify=y, random_state = 19)\n",
        "\n",
        "# Dimentions\n",
        "n_steps, n_length, n_width = 7, 24, 60  \n",
        "n_features = 1 \n",
        "\n",
        "# Reshape Train and Test \n",
        "X_train = X_train.reshape((X_train.shape[0], n_steps, n_length, n_width, n_features))\n",
        "X_test = X_test.reshape((X_test.shape[0], n_steps, n_length, n_width, n_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD1Pc_RmZH2Y"
      },
      "source": [
        "Graphical Analysis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kWFt05rRY6NY",
        "outputId": "3e1274f9-b911-40c0-d960-c2ffea4380da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 3\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 4\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 6\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 7\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADtCAYAAACvfY5sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAd0UlEQVR4nO3debhdVZ3m8e9LEFIyKBikMWGyjFXGtkUrIIoDKkOcQLtQg6WGKnx49IFHLLUVh8YqtLrRarVVqJKURnAAjPNtKyUiQzmiCYhCghSBEkhkkBAFBwK5efuPvW7YnJx7z7m5596zz+H9PM9+7p7XuuHwO+v+9tpryTYRETH4duh3BSIiojcS0CMihkQCekTEkEhAj4gYEgnoERFDYsd+VyAiommOfv4u3nD3aMfzrvz5potsL5qBKnUlAT0iosWGu0f5yUX7dTxv1j43zJmB6nQtAT0iooWBLWzpdzUmLQE9IqKFMQ+4c8qlaRLQIyLaSAs9ImIIGDM6gMOiJKBHRLSxhQT0iIiBZ2A0AT0iYjikhR4RMQQMPJAcekTE4DNOyiUiYigYRgcvniegR0S0qt4UHTwJ6BER2xCjqN+VmLQE9IiIFtVD0QT0iIiBV/VDT0CPiBgKW9JCj4gYfGmhR0QMCSNGB3CGzgT0iIg2BjHlMnhfQRER08yI+z2r49INSYskXS9praTT2hx/o6RrJF0t6fuSFpT9B0j6Y9l/taRPdiorLfSIiBbVi0VTb+9KmgWcDRwJrANWShqxvaZ22vm2P1nOPwb4CDA28fSNtg/qtry00CMi2hgtLxdNtHThEGCt7Zts3w9cCBxbP8H2PbXNXWD7B5FJCz0iooUtRt1Ve3eOpFW17aW2l9a25wK31rbXAc9ovYmkk4G3AjsBL6gdOlDST4F7gPfa/t5ElUlAj4hoY0t3LfC7bC+calm2zwbOlvQa4L3AEuA2YD/bGyT9BfB1SU9uadE/RAJ6RESL6qFoT8LjemDf2va8sm88FwL/DGB7E7CprF8p6UbgicCq8S5ODj0iosXYQ9FOSxdWAvMlHShpJ2AxMFI/QdL82uZLgBvK/r3KQ1UkPR6YD9w0UWFpoUdEtDHag37otjdLOgW4CJgFLLO9WtIZwCrbI8Apko4AHgA2UqVbAJ4LnCHpAarRfN9o++6JyktAj4ho0cs3RW2vAFa07Du9tn7qONd9BfjKZMpKQI+IaGNLd71cGiUBPSKiRTU4VwJ6RMTAM+KBLl/tb5IE9IiIFjbdvljUKAnoERHbULcvFjVKAnpERAuTFnpExNDIQ9GIiCFgNJATXCSgR0S0MPBAb8ZymVGDV+OIiGnX9XjnjZKAHhHRwuRN0YiIoZEWekTEELCVFno8vJRZyNfbfn+H8/YD1gCPsj06I5WLmILqoejgvfo/eF9B0ROSLpe0UdLOXZ5/gqTv1/fZfmOnYF7Ou8X2rmPBvJT9hu2ree9IOlzSFkm/K8s6ScslHTxN5X2yVtbvJG2SdO90lBVTVc0p2mlpmubVKKadpAOA51A1RI7pa2X671e2dwV2Aw4FfgF8T9ILe11Q+QLcdWwBLgC+1OtyYuqqh6LquDRNAvrD0+uBK4BzeXB2FAAk7Svpq5J+LWmDpLMkPQn4JPDM0rL8TTn3XEkfKOvXSXpp7T47lns8XdIBklz2/QPVl8lZ5V5nSTpb0odb6jEi6W/bVV7SsyStlPTb8vNZtWOXS3q/pB9IulfStyXN6fQP4sq6MvHAp4AP1u75MUm3SrpH0pWSnlP2/xdJf5D0mNq5Ty+/9yMmKk/SLsBfAud1qlv0xyg7dFyapnk1ipnweuALZTla0t4AZf7CbwI3AwcAc4ELbV8HvBH4UWldPrrNPS8Ajq9tH001I/pV9ZNsvwf4HnBKudcpVEHteEk7lHrMAY4Azm8tRNKewL8CHwceA3wE+Nd6UAVeA/w18FhgJ+DtXf67jPkq8PQSdKGaF/IgYM9Spy9Jmm37duBy4FW1a19H9W/2QIcy/hL4NfDdSdYtZsDYm6JpoUejSXo2sD+w3PaVwI1UARDgEOBxwP+w/Xvb99n+/ji3anU+cIykR5bt11AF+Y5s/wT4LTCW5lgMXG77jjanvwS4wfbnbG+2fQFVmuRltXM+Y/s/bP8RWE4VjCfjV4CAR5f6fd72hlLeh4GdgT8r554HvBa2fiEeD3yuizKWAJ+17UnWLWZIjyaJRtIiSddLWivptDbH3yjpGklXS/q+pAW1Y+8q110v6ehOZSWgP/wsAb5t+66yfT4Ppl32BW62vXmyN7W9FrgOeFkJ6sfQpoU9ga2BsfwcLyg+juoviLqbqf6aGHN7bf0PwK6TqAflXgbGUktvLyml35Z006OAsTTON4AFkg4EjgR+W76gxlV6/RwOfHaS9YoZYsMDW3bouHRSvuTPBl4ELKD6S3RBy2nn236K7YOAD1H91Uk5bzHwZGAR8E/lfuNKt8WHEUl/QpUemCVpLOjtDDxa0lOBW4H9JO3YJqh305IcS7vsAKwpQb6ddvf6PHBtqceTgK+Pc+2vqP7CqNsP+FYX9evWK4CrbP++5MvfQfXXw2rbWyRtpGrBY/s+ScupvoT+nO5a568DfmD7ph7WOXqoSrn0pL17CLB27L+1pAuBY6m68VZl2ffUzt+FB///OJYqfbcJ+E9Ja8v9fjReYWmhP7y8HBilaikcVJYnUeW0Xw/8BLgNOFPSLpJmSzqsXHsHME/SThPc/0LgKOBNTNw6vwN4fH2H7XVUuerPAV8p6ZJ2VgBPlPSa8pD11eX3+eYE5XWkylxJ7wPeALy7HNoN2EyV795R0unA7i2XfxY4geqvkm4C+uupHkhHg42W8VwmWrowl6qhNGYdD/1rEgBJJ0u6kaqF/ubJXFuXgP7wsoQqv3yL7dvHFuAs4K+oWp0vA54A3EL1AXp1ufZSYDVwu6S7tr012L6NqvXwLOCLE9TjY8BxqvrBf7y2/zzgKUwQFG1vAF4KvA3YQNV6fmkthTRZj5P0O+B3VF8oTwEOt/3tcvwiqtb/f1Cldu7jof+TYfsHwBaqVn1rOughJD0TmEe6KzbaJLotzpG0qractF3l2Wfb/lPgncB7t7feyjOZaApJz6VKvew/aA8LJV1KlQv9VL/rElO314I5fsVnX9LxvH85+LNX2l443vHyBf53to8u2+8CsP2/xzl/B2Cj7Ue1nivponKvpFyi2Uq/7VOBTw1gMD8YeDoT/1USA2ZLmVd0oqULK4H5kg4s6crFwEj9BEnza5svAW4o6yPAYkk7l4fu86nSouPKQ9Hou/Li0irgZ1T9xweGpPOonk2cajuv8Q+JqpfL1Mdysb1Z0ilUqbtZwDLbqyWdAayyPQKcIukI4AFgI6XXWTlvOdUD1M3AyZ3GQkrKJSKixWOetJdffO6xHc/7/KGfnjDlMtP6knLp1NE+IqLfepRymVEznnKpdbQ/kqoXxUpJI7bXjHfNTtrZs9llvMMREVvdy8a7bO81lXuM9XIZNP3IoXfsaN9qNrvwjN4PfhcRQ+g7/vKEXUe7lQkuutOus/wzWk8q/TlPApjNI1sPR0RMG1tsTkDvHdtLgaUAu2vPPLmNiBmVlEt31lMNAjVmXtkXEdEIyaF3b2tHe6pAvpgHh2+NiGiEBPQujNfRfqbrERExnrEJLgZNX3LotldQjZoXEdFITexn3kljH4pGRPSLDZu7mMCiaRLQIyLaSMolImIIJIceETFEnIAeETEc8lA0ImII2MmhR0QMCTGaXi4REcMhOfSIiCGQsVwiIoaFqzz6oBm8JFFExAzo1RR0nabclPRWSWsk/VzSJZL2rx0blXR1WUY6lZUWekREC/fooWiXU27+FFho+w+S3gR8CHh1OfZH2wd1W15a6BERbdidly5snXLT9v3A2JSbtXJ8me0/lM0rqOaI2C4J6BERbdjquABzJK2qLSe13KbdlJtzJyj2RODfatuzy32vkPTyTnXuS8pF0i+Be4FRYLPthf2oR0REO1ULvKsc+V29il+SXgssBJ5X272/7fWSHg9cKuka2zeOd49+5tCfb/uuPpYfETGuHnVb7GrKTUlHAO8Bnmd709h+2+vLz5skXQ48DRg3oCflEhHRRo9y6Fun3JS0E9WUmw/prSLpacA5wDG276zt30PSzmV9DnAYUH+Yuo1+tdANfFuSgXNsL209oeSiTgKYzSNnuHoR8XBmxJYe9HIZb8pNSWcAq2yPAP8I7Ap8SRLALbaPAZ4EnCNpC1Xj+8yW3jHb6FdAf3bJCz0WuFjSL2x/t35CCfJLAXbXngPYxT8iBlmvgk67KTdtn15bP2Kc634IPGUyZfUl5VLLC90JfI2qa09ERDO4614ujTLjAV3SLpJ2G1sHjgKunel6RERMyF0sDdOPlMvewNdKrmhH4Hzb3+pDPSIixtXEFngnMx7Qbd8EPHWmy42I6JaBLVsS0CMiBp+BtNAjIobDIA6fm4AeEdFOAnpExDBoZrfEThLQIyLaSQs9ImIIGJxeLhERwyIBPSJiOCTlEhExJBLQIyKGQF4siogYHnmxKCJiWAxgL5eOw+dKmiXpFzNRmYiIppA7L03TMaDbHgWul7TfZG4saZmkOyVdW9u3p6SLJd1Qfu6xHXWOiJhe3YyFPogBvdgDWC3pEkkjY0uHa84FFrXsOw24xPZ84JKyHRHRMKoeinZaGqbbHPr/nOyNbX9X0gEtu48FDi/r5wGXA++c7L0jIqZdj1rgkhYBH6OaJPpTts9sOf5W4A3AZuDXwN/YvrkcWwK8t5z6AdvnTVRWVwHd9r9P6jcY3962byvrt1PNXhQR0Txbpn4LSbOAs4EjgXXASkkjttfUTvspsND2HyS9CfgQ8GpJewLvAxZSfb1cWa7dOF55XaVcJN0r6Z6y3CdpVNI92/crVmxPmIWSdJKkVZJWPcCmqRQVETE5Y/3Qp55yOQRYa/sm2/cDF1JlKh4syr7M9h/K5hXAvLJ+NHCx7btLEL+YbdPYD9FtC323sXVVk4EeCxzazbUt7pC0j+3bJO0D3DlBmUuBpQC7a88GPn6IiGHWZS+WOZJW1baXltg1Zi5wa217HfCMCe53IvBvE1w7d6LKdPtQdCtXvk717TFZI8CSsr4E+MZ23CMiYvp118vlLtsLa8vSce7WkaTXUqVX/nF779FVC13Sf69t7lAKva/DNRdQPQCdI2kdVS7oTGC5pBOBm4FXbUedIyIGxXpg39r2vLLvISQdAbwHeJ7tTbVrD2+59vKJCuu2l8vLauubgV/SkgdqZfv4cQ69sMsyIyL6pkcvDq0E5ks6kCpALwZe85BypKcB5wCLbNfT0BcB/6v2vs5RwLsmKqzbHPpfd1f3iIghYHry6r/tzZJOoQrOs4BltldLOgNYZXuEKsWyK/Cl6hElt9g+xvbdkt5P9aUAcIbtuycqr9uUyzzgE8BhZdf3gFNtr5vk7xcRMRh61BXD9gpgRcu+02vrR0xw7TJgWbdldftQ9DNUDzQfV5b/V/ZFRAyloRzLpdjL9mdsby7LucBe01iviIj+GuKxXDZIem0ZeXFW6V6zYTorFhHRV0Mc0P+Gqovh7cBtwHFAHpRGxFDqJt3SxJRLt71cbgaOmea6REQ0xwBOcDFhQJf0CSb4w8L2m3teo4iIBmhiC7yTTi30+hgFf0/1tmdExPAbtoBeH3tX0ls6jcUbETEUGpoj72Qyk0QP4K8XEbGdBjDiTSagR0Q8bKgHE1zMtE4PRe/lwe+pR9YmtRDVSLq7T2flIiKie51y6LtNdDwiYmgNYMpl0hNcdEvSMkl3Srq2tu/vJK2XdHVZXjxd5UdEbLcBfbFo2gI6cC7t57/7qO2DyrKizfGIiP4b4lf/J832d4EJx+6NiGisBPSunCLp5yUls8d4J0k6SdIqSaseYNN4p0VE9Jyoerl0WppmpgP6PwN/ChxENcjXh8c70fbSsYlXH8HOM1W/iIjk0Lth+w7bo7a3AP8CHDKT5UdEdC0pl4lJ2qe2+Qrg2vHOjYjoqwT0B0m6APgR8GeS1kk6EfiQpGsk/Rx4PvC301V+RMRU9CrlImmRpOslrZV0Wpvjz5V0laTNko5rOTZa6+Y90qmsaXv13/bxbXZ/errKi4joqR60wCXNAs4GjgTWASsljdheUzvtFuAE4O1tbvFH2wd1W17GcomIaOWe9WI5BFhr+yYASRcCxwJbA7rtX5ZjUy6xH90WIyKar7sc+pyx7tVlOanlLnOBW2vb68q+bs0u971C0ss7nZwWekREG13myO+yvXAaq7G/7fWSHg9cKuka2zeOd3Ja6BER7fSml8t6YN/a9ryyr7sq2OvLz5uAy4GnTXR+AnpERKtugnl3AX0lMF/SgZJ2AhYDHXurAEjaQ9LOZX0OcBi13Hs7CegRES1Eb7ot2t4MnAJcBFwHLLe9WtIZko4BkHSwpHXAK4FzJK0ulz8JWCXpZ8BlwJktvWO2kRx6REQbvXq1v4wqu6Jl3+m19ZVUqZjW634IPGUyZSWgR0S008A3QTtJQI+IaCcBPSJiCDR0NMVOEtAjItpJQI+IGA5NnMCikwT0iIg2knKJiBgGDR3vvJPpHA99X0mXSVojabWkU8v+PSVdLOmG8nPceUUjIvomE1w8xGbgbbYXAIcCJ0taAJwGXGJ7PnBJ2Y6IaIxevSk606YtoNu+zfZVZf1eqtde51KNBXxeOe08oOOQkBERM01b3HFpmhnJoUs6gGqUsB8De9u+rRy6Hdh7nGtOAk4CmM0jp7+SERFjGppS6WTaB+eStCvwFeAttu+pH7M97j+b7aW2F9pe+Ah2nu5qRkQ8RFIuLSQ9giqYf8H2V8vuOyTtU47vA9w5nXWIiNgueSj6IEmimhT6OtsfqR0aAZaU9SXAN6arDhER22sQW+jTmUM/DHgdcI2kq8u+dwNnAsslnQjcDLxqGusQEbF9GhiwO5m2gG77+1S9f9p54XSVGxExZc6r/xERQ2GsH/qgSUCPiGjHgxfRE9AjItoYxBZ6JomOiGjVTZfFLgO+pEWSrpe0VtI2Q51Ieq6kqyRtlnRcy7ElZdyrGyQtab22VVroERFt9OKhqKRZwNnAkcA6YKWkEdtraqfdApwAvL3l2j2B9wELqb4+rizXbhyvvIEI6Pey8a7v+Ms3A3OAu/pdn+0wiPVOnWfOINa7yXXevxc36VEvl0OAtbZvApB0IdV4VlsDuu1flmOtJR4NXGz77nL8YmARcMF4hQ1EQLe9F4CkVbYX9rs+kzWI9U6dZ84g1nsQ6zwpptuHonMkraptL7W9tLY9F7i1tr0OeEaXtWh37dyJLhiIgB4RMdO6fCh6V5O+2PJQNCKind48FF0P7Fvbnlf2Tcu1gxbQl3Y+pZEGsd6p88wZxHoPYp271sMJLlYC8yUdKGknYDHVeFbduAg4StIeZWa3o8q+cQ1UQG/JTQ2MQax36jxzBrHeg1jnSXHnyS26meDC9mbgFKpAfB2w3PZqSWdIOgZA0sGS1gGvBM6RtLpcezfwfqovhZXAGWMPSMeTHHpERDs9erHI9gpgRcu+02vrK6nSKe2uXQYs67asBPSIiDbypug06vS2VRNIWibpTknX1vbtKeni8qbXxSUX1hiS9pV0maQ1klZLOrXsb3q9Z0v6iaSflXr/fdl/oKQfl8/JF0veslEkzZL0U0nfLNuDUOdfSrpG0tVj3fSa/hmZEgNb3HlpmIEI6LW3rV4ELACOl7Sgv7Vq61yqjv91pwGX2J4PXFK2m2Qz8DbbC4BDgZPLv23T670JeIHtpwIHAYskHQp8EPio7ScAG4ET+1jH8ZxKlU8dMwh1Bni+7YNq3fSa/hmZmsxYNG22vm1l+35g7G2rRrH9XaD1ocWxwHll/Tzg5TNaqQ5s32b7qrJ+L1WgmUvz623bvyubjyiLgRcAXy77G1dvSfOAlwCfKtui4XWeQKM/I1M1iDMWDUpAn/QbUw2yt+3byvrtwN79rMxEJB0APA34MQNQ75K6uJpqXtqLgRuB35SeBdDMz8n/Bd4BjL3m/RiaX2eoviy/LelKSSeVfY3/jExFL3q5zLQ8FJ1Bti018XsdJO1KNaH3W2zfUzUcK02tt+1R4CBJjwa+Bvx5n6s0IUkvBe60faWkw/tdn0l6tu31kh4LXCzpF/WDTf2MbLeGplQ6GZSAPpW3rfrtDkn72L5N0j5UrclGkfQIqmD+BdtfLbsbX+8xtn8j6TLgmcCjJe1YWrxN+5wcBhwj6cXAbGB34GM0u84A2F5fft4p6WtUadCB+YxMVvVi0eBF9EFJuUzlbat+GwHGxjFeAnyjj3XZRsnhfhq4zvZHaoeaXu+9SsscSX9CNTzpdcBlwNiY0o2qt+132Z5n+wCqz/Cltv+KBtcZQNIuknYbW6d6Y/FaGv4ZmbItXSwNMxAtdNubJY29bTULWGZ7dZ+rtQ1JFwCHU43Ato5qLOMzgeWSTgRuBl7Vvxq2dRjwOuCako8GeDfNr/c+wHmlB9QOVG/gfVPSGuBCSR8Afkr1ZdV076TZdd4b+FpJw+0InG/7W5JW0uzPyJQMYgtdHsBKR0RMp913m+eDF57c8bxLL3/3lU0abXEgWugRETOrmb1YOklAj4hoZwCzFwnoERGt3LMp6GZUAnpERDtpoUdEDInBi+cD0w89hpAkS/p8bXtHSb+ujUJ4zFRG1pT0FkmP7EVd4+FHW7Z0XJomAT366ffAfy0vBkH1ctDWtyRtj9g+cwr3fwuQgB6TZwbyxaIE9Oi3FVSjDwIcD1wwdkDSCZLOKuvnSvq4pB9KuknScWX/4WMt+rJ9VrnuzcDjgMvKsABIOkrSjyRdJelLZfyaiG0II3demiYBPfrtQmCxpNnAf6Ma6XE8+wDPBl5K9SbruGx/HPgV1Rjez5c0B3gvcITtpwOrgLf2oP4xrOzOS8MkoEdf2f45cABV63zFxGfzddtbbK9h8kO1Hko1OcoPyhAHS4D9J3mPeDjpUUBXh9nWJO1cZqpaW2auOqDsP0DSH8ssUVdL+mSnstLLJZpgBPg/VOPgPGaC8zbV1sfG993MQxsms8e5VsDFto/fzjrGw8lYDn2KarOtHUk11v1KSSOlUTLmRGCj7SdIWkw1g9Wry7EbbR/UbXlpoUcTLAP+3vY123HtzcCC0sp5NPDC2rF7gd3K+hXAYZKeAFtHEHziVCodw61HvVy6mW2tPvPTl4EXqj4hwSQkoEff2V5Xct7bc+2twHKq4VyXU41WOGYp8C1Jl9n+NXACcIGknwM/ouETYkQ/dZFuqVIucyStqi0ntdyom9nWtp5TxsT/LQ/+pXqgqgnF/13SczrVOimX6Bvb2/QysX05cHlZP5dq4m1snzDetbbfQTWtW+u9PgF8orZ9KXDw1GseQ890myO/axpHW7wN2M/2Bkl/AXxd0pNt3zPeBWmhR0S005t+6N3Mtrb1HEk7Ao8CNtjeZHsDgO0rqebMnTBNmIAeEdFGj/qhdzPbWn3mp+OoZrJymZVrFoCkxwPzgZsmKiwpl4iIdnrQz3y82dYknQGssj1CNUPV5yStBe6mCvoAzwXOkPQA1d8Db7R990TlJaBHRLSyYbQ37/bbXkHLOxa2T6+t3we8ss11X6GavL1rCegREe008E3QThLQIyLaSUCPiBgCBjKnaETEMDC4gePjdpCAHhHRyvTsoehMSkCPiGgnOfSIiCGRgB4RMQyaOYFFJwnoERGtDDRwEuhOEtAjItpJCz0iYhj07tX/mZSAHhHRyuD0Q4+IGBJ5UzQiYkgkhx4RMQTs9HKJiBgaaaFHRAwD49HRfldi0hLQIyJaZfjciIghMoDdFnfodwUiIprGgLe449INSYskXS9praTT2hzfWdIXy/EfSzqgduxdZf/1ko7uVFYCekREK5cJLjotHUiaBZwNvAhYABwvaUHLaScCG20/Afgo8MFy7QJgMfBkYBHwT+V+40pAj4how6OjHZcuHAKstX2T7fuBC4FjW845FjivrH8ZeKEklf0X2t5k+z+BteV+40oOPSKixb1svOg7/vKcLk6dLWlVbXup7aW17bnArbXtdcAzWu6x9RzbmyX9FnhM2X9Fy7VzJ6pMAnpERAvbi/pdh+2RlEtExPRZD+xb255X9rU9R9KOwKOADV1e+xAJ6BER02clMF/SgZJ2onrIOdJyzgiwpKwfB1xq22X/4tIL5kBgPvCTiQpLyiUiYpqUnPgpwEXALGCZ7dWSzgBW2R4BPg18TtJa4G6qoE85bzmwBtgMnGx7wiex8gCOVxAREdtKyiUiYkgkoEdEDIkE9IiIIZGAHhExJBLQIyKGRAJ6RMSQSECPiBgS/x/mCeaV8Haf5gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for day in range(0,7):\n",
        "  sli = X_train[11, day, 0:23, 0:59, 0]\n",
        "  print(\"day:\", day + 1)\n",
        "  plt.imshow(sli, interpolation='none', vmin=0, vmax=.39)\n",
        "  plt.colorbar(orientation='vertical')\n",
        "  plt.title(\"Activity on Day \" + str(day+1))\n",
        "  plt.xlabel(\"Minute\")\n",
        "  plt.ylabel(\"Hour\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK6Ia1wXX1aQ"
      },
      "source": [
        "# Model Architecture "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ1Z8SjSYEXk"
      },
      "source": [
        "Import certain files from Keras "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1ShU0hDYXrDd"
      },
      "outputs": [],
      "source": [
        "# Import Layers\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.convolutional import MaxPooling3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GYEzaQxSYUvX"
      },
      "outputs": [],
      "source": [
        "# Model Structure\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  # Conv Layers \n",
        "  model.add(ConvLSTM2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(n_steps, n_length, n_width, n_features) ,return_sequences=True) )\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
        "  model.add(ConvLSTM2D(filters=64, kernel_size=(2, 2), padding='valid', return_sequences= False))\n",
        "\n",
        "  # Feed Forward Layers \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLH5N9_8Z_Ys"
      },
      "source": [
        "# Model Compilation & Fitting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0YuZKfeaBIi"
      },
      "outputs": [],
      "source": [
        "# Compile the model -----\n",
        "with strategy.scope():\n",
        "  # Create the model we defined above\n",
        "  model = create_model()\n",
        "  # Compile \n",
        "  model.compile(\n",
        "    # Metrics \n",
        "    loss= tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics= tf.keras.metrics.AUC(name='auc'),\n",
        "    # Optimizer \n",
        "    optimizer= tf.keras.optimizers.Adam(\n",
        "      learning_rate=0.00001,\n",
        "      beta_1=0.9,\n",
        "      beta_2=0.999,\n",
        "      epsilon=1e-07,\n",
        "      amsgrad=False,\n",
        "    )\n",
        ")\n",
        "  \n",
        "model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/base_model_weights.h5\")\n",
        "\n",
        "def reset_model():\n",
        "  model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/base_model_weights.h5\")\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ajVi5MSm2m8"
      },
      "source": [
        "Set Parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kqRVK8ejmPbB"
      },
      "outputs": [],
      "source": [
        "# Params ----------\n",
        "# Balance Weights \n",
        "class_weights = {0: (266/7162),  # Custom Setting Class Weights \n",
        "                1: (6896/7162)}\n",
        "\n",
        "# Early Stopping \n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc',\n",
        "                                            patience=90,\n",
        "                                            restore_best_weights=True,                                       \n",
        "                                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZFiRi-Xba6j"
      },
      "source": [
        "Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J_dPCJD3bOKJ"
      },
      "outputs": [],
      "source": [
        "# Fit the Model \n",
        "def fit_model(X_training, y_training, X_val, y_val):\n",
        "  model.fit(\n",
        "      X_training, y_training,\n",
        "      epochs= 500, \n",
        "      batch_size= 64,  \n",
        "      validation_data = (X_val, y_val), \n",
        "      shuffle=False,\n",
        "      class_weight=class_weights,\n",
        "      callbacks = [callback],\n",
        "      verbose = 2\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H7ML-01Gm7Vs"
      },
      "outputs": [],
      "source": [
        "# Save the model \n",
        "def save_model(count):\n",
        "  model.save(\"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/Saved CV Model weights/full_model_\" + str(count) + \".h5\")\n",
        "  model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/Saved CV Model weights/weights_\" + str(count) + \".hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BfXMeHGPq16f"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "def model_eval():\n",
        "  print(\" \\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\ntest set:\")\n",
        "  scores = model.evaluate(X_test, y_test, batch_size=64) # Test Set\n",
        "  cv_test_scores.append(scores[1])\n",
        "  print(\" \\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\n-\\nval set:\")\n",
        "  scores = model.evaluate(X_val, y_val, batch_size=64)  # Validation Set\n",
        "  cv_val_scores.append(scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JZl04fpnrmkd"
      },
      "outputs": [],
      "source": [
        "# Save all predictions and file\n",
        "def save_files(count):\n",
        "  # Preds\n",
        "  pred_filepath = \"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/Prediction Files\"\n",
        "  np.save(pred_filepath + \"/y_pred_test_\" + str(count) + \".npy\", X_test, allow_pickle=True)\n",
        "  np.save(pred_filepath + \"/y_pred_val_\" + str(count) + \".npy\", X_val, allow_pickle=True)\n",
        "\n",
        "  # Train\n",
        "  train_filepath = \"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/Training files\"\n",
        "  np.save(train_filepath + \"/X_train_\" + str(count) + \".npy\", X_training, allow_pickle=True)\n",
        "  np.save(train_filepath + \"/y_train_\" + str(count) + \".npy\", y_training, allow_pickle=True)\n",
        "\n",
        "  # Test \n",
        "  test_filepath = \"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/Testing Files\"\n",
        "  np.save(test_filepath + \"/X_test_\" + str(count) + \".npy\", X_test, allow_pickle=True)\n",
        "  np.save(test_filepath + \"/y_test_\" + str(count) + \".npy\", y_test, allow_pickle=True)\n",
        "\n",
        "  # Validation\n",
        "  val_filepath = \"/content/drive/MyDrive/Colab Notebooks/Heinz SSRI Classification/Final Model /Clean Models/Validation Files\"\n",
        "  np.save(val_filepath + \"/X_val_\" + str(count) + \".npy\", X_val, allow_pickle=True)\n",
        "  np.save(val_filepath + \"/y_val_\" + str(count) + \".npy\", y_val, allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzirdpgrtMLc"
      },
      "source": [
        "# 10-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "orKly4jztOhL",
        "outputId": "2e77f4f8-361f-4c26-de82-ede9dcde7bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resetting model..\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "81/81 - 33s - loss: 0.0491 - auc: 0.5819 - val_loss: 0.6488 - val_auc: 0.5559 - 33s/epoch - 405ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0480 - auc: 0.6563 - val_loss: 0.6266 - val_auc: 0.5469 - 8s/epoch - 97ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0472 - auc: 0.6633 - val_loss: 0.6273 - val_auc: 0.5456 - 8s/epoch - 98ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6663 - val_loss: 0.6315 - val_auc: 0.5434 - 8s/epoch - 97ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0466 - auc: 0.6663 - val_loss: 0.6374 - val_auc: 0.5440 - 8s/epoch - 97ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6695 - val_loss: 0.6372 - val_auc: 0.5441 - 8s/epoch - 97ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6690 - val_loss: 0.6396 - val_auc: 0.5442 - 8s/epoch - 97ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6706 - val_loss: 0.6421 - val_auc: 0.5448 - 8s/epoch - 98ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6723 - val_loss: 0.6398 - val_auc: 0.5465 - 8s/epoch - 97ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6759 - val_loss: 0.6397 - val_auc: 0.5480 - 8s/epoch - 98ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6772 - val_loss: 0.6389 - val_auc: 0.5487 - 8s/epoch - 100ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6812 - val_loss: 0.6384 - val_auc: 0.5496 - 8s/epoch - 97ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6837 - val_loss: 0.6370 - val_auc: 0.5488 - 8s/epoch - 97ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6885 - val_loss: 0.6343 - val_auc: 0.5509 - 8s/epoch - 97ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6885 - val_loss: 0.6329 - val_auc: 0.5488 - 8s/epoch - 97ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6938 - val_loss: 0.6308 - val_auc: 0.5491 - 8s/epoch - 97ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6977 - val_loss: 0.6285 - val_auc: 0.5501 - 8s/epoch - 97ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6956 - val_loss: 0.6294 - val_auc: 0.5502 - 8s/epoch - 97ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.7026 - val_loss: 0.6287 - val_auc: 0.5513 - 8s/epoch - 97ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7045 - val_loss: 0.6279 - val_auc: 0.5516 - 8s/epoch - 97ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7042 - val_loss: 0.6283 - val_auc: 0.5514 - 8s/epoch - 97ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7076 - val_loss: 0.6302 - val_auc: 0.5514 - 8s/epoch - 97ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7082 - val_loss: 0.6290 - val_auc: 0.5523 - 8s/epoch - 98ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7088 - val_loss: 0.6310 - val_auc: 0.5519 - 8s/epoch - 98ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7112 - val_loss: 0.6306 - val_auc: 0.5534 - 8s/epoch - 97ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7159 - val_loss: 0.6290 - val_auc: 0.5554 - 8s/epoch - 97ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7223 - val_loss: 0.6282 - val_auc: 0.5565 - 8s/epoch - 98ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7250 - val_loss: 0.6243 - val_auc: 0.5577 - 8s/epoch - 101ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7228 - val_loss: 0.6306 - val_auc: 0.5580 - 8s/epoch - 100ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7285 - val_loss: 0.6279 - val_auc: 0.5589 - 8s/epoch - 99ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7303 - val_loss: 0.6283 - val_auc: 0.5599 - 8s/epoch - 99ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7336 - val_loss: 0.6215 - val_auc: 0.5613 - 8s/epoch - 98ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7350 - val_loss: 0.6211 - val_auc: 0.5616 - 8s/epoch - 99ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0420 - auc: 0.7331 - val_loss: 0.6218 - val_auc: 0.5597 - 8s/epoch - 98ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0417 - auc: 0.7378 - val_loss: 0.6243 - val_auc: 0.5609 - 8s/epoch - 98ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7407 - val_loss: 0.6206 - val_auc: 0.5627 - 8s/epoch - 98ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7431 - val_loss: 0.6190 - val_auc: 0.5620 - 8s/epoch - 98ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0412 - auc: 0.7461 - val_loss: 0.6176 - val_auc: 0.5619 - 8s/epoch - 98ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0411 - auc: 0.7462 - val_loss: 0.6198 - val_auc: 0.5598 - 8s/epoch - 98ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7480 - val_loss: 0.6169 - val_auc: 0.5615 - 8s/epoch - 98ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0409 - auc: 0.7501 - val_loss: 0.6149 - val_auc: 0.5616 - 8s/epoch - 103ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7513 - val_loss: 0.6138 - val_auc: 0.5623 - 8s/epoch - 97ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7539 - val_loss: 0.6121 - val_auc: 0.5613 - 8s/epoch - 98ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7562 - val_loss: 0.6100 - val_auc: 0.5634 - 8s/epoch - 99ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7555 - val_loss: 0.6109 - val_auc: 0.5615 - 8s/epoch - 98ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0402 - auc: 0.7588 - val_loss: 0.6102 - val_auc: 0.5663 - 8s/epoch - 99ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7594 - val_loss: 0.6079 - val_auc: 0.5657 - 8s/epoch - 98ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7610 - val_loss: 0.6109 - val_auc: 0.5651 - 8s/epoch - 98ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0398 - auc: 0.7644 - val_loss: 0.6065 - val_auc: 0.5676 - 8s/epoch - 98ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7686 - val_loss: 0.6052 - val_auc: 0.5670 - 8s/epoch - 98ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7663 - val_loss: 0.6097 - val_auc: 0.5645 - 8s/epoch - 98ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7702 - val_loss: 0.6004 - val_auc: 0.5695 - 8s/epoch - 99ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0392 - auc: 0.7731 - val_loss: 0.6008 - val_auc: 0.5688 - 8s/epoch - 99ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0392 - auc: 0.7724 - val_loss: 0.6027 - val_auc: 0.5700 - 8s/epoch - 98ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7758 - val_loss: 0.5990 - val_auc: 0.5694 - 8s/epoch - 98ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7750 - val_loss: 0.5987 - val_auc: 0.5688 - 8s/epoch - 98ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7809 - val_loss: 0.5966 - val_auc: 0.5704 - 8s/epoch - 99ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0384 - auc: 0.7816 - val_loss: 0.5970 - val_auc: 0.5693 - 8s/epoch - 98ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7811 - val_loss: 0.5975 - val_auc: 0.5699 - 8s/epoch - 97ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0383 - auc: 0.7860 - val_loss: 0.5976 - val_auc: 0.5711 - 8s/epoch - 99ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0381 - auc: 0.7886 - val_loss: 0.5976 - val_auc: 0.5697 - 8s/epoch - 98ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7878 - val_loss: 0.6027 - val_auc: 0.5685 - 8s/epoch - 98ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0379 - auc: 0.7886 - val_loss: 0.5999 - val_auc: 0.5686 - 8s/epoch - 97ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7939 - val_loss: 0.5930 - val_auc: 0.5667 - 8s/epoch - 98ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7908 - val_loss: 0.5959 - val_auc: 0.5676 - 8s/epoch - 97ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7960 - val_loss: 0.5930 - val_auc: 0.5670 - 8s/epoch - 98ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7973 - val_loss: 0.5969 - val_auc: 0.5681 - 8s/epoch - 100ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0370 - auc: 0.8022 - val_loss: 0.5827 - val_auc: 0.5739 - 8s/epoch - 99ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.8010 - val_loss: 0.5962 - val_auc: 0.5691 - 8s/epoch - 98ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.8016 - val_loss: 0.5992 - val_auc: 0.5693 - 8s/epoch - 98ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0366 - auc: 0.8039 - val_loss: 0.5994 - val_auc: 0.5695 - 8s/epoch - 99ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 9s - loss: 0.0363 - auc: 0.8062 - val_loss: 0.5919 - val_auc: 0.5660 - 9s/epoch - 106ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8102 - val_loss: 0.6015 - val_auc: 0.5625 - 8s/epoch - 99ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0359 - auc: 0.8126 - val_loss: 0.5992 - val_auc: 0.5705 - 8s/epoch - 99ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0357 - auc: 0.8130 - val_loss: 0.6045 - val_auc: 0.5710 - 8s/epoch - 98ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0356 - auc: 0.8170 - val_loss: 0.6011 - val_auc: 0.5704 - 8s/epoch - 99ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0354 - auc: 0.8157 - val_loss: 0.5957 - val_auc: 0.5688 - 8s/epoch - 98ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0352 - auc: 0.8223 - val_loss: 0.5944 - val_auc: 0.5655 - 8s/epoch - 98ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0348 - auc: 0.8245 - val_loss: 0.5961 - val_auc: 0.5661 - 8s/epoch - 99ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0349 - auc: 0.8276 - val_loss: 0.5940 - val_auc: 0.5688 - 8s/epoch - 99ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0346 - auc: 0.8300 - val_loss: 0.5907 - val_auc: 0.5705 - 8s/epoch - 98ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0344 - auc: 0.8296 - val_loss: 0.5980 - val_auc: 0.5710 - 8s/epoch - 98ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0343 - auc: 0.8298 - val_loss: 0.6045 - val_auc: 0.5728 - 8s/epoch - 98ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0339 - auc: 0.8360 - val_loss: 0.6021 - val_auc: 0.5709 - 8s/epoch - 98ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0340 - auc: 0.8335 - val_loss: 0.5902 - val_auc: 0.5733 - 8s/epoch - 98ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0337 - auc: 0.8372 - val_loss: 0.5998 - val_auc: 0.5683 - 8s/epoch - 98ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0335 - auc: 0.8380 - val_loss: 0.6086 - val_auc: 0.5654 - 8s/epoch - 99ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0334 - auc: 0.8413 - val_loss: 0.6009 - val_auc: 0.5683 - 8s/epoch - 98ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0334 - auc: 0.8434 - val_loss: 0.6021 - val_auc: 0.5647 - 8s/epoch - 99ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8451 - val_loss: 0.5973 - val_auc: 0.5690 - 8s/epoch - 98ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0328 - auc: 0.8458 - val_loss: 0.6052 - val_auc: 0.5648 - 8s/epoch - 100ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0326 - auc: 0.8494 - val_loss: 0.6006 - val_auc: 0.5672 - 8s/epoch - 98ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0325 - auc: 0.8496 - val_loss: 0.6029 - val_auc: 0.5680 - 8s/epoch - 98ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0323 - auc: 0.8547 - val_loss: 0.5941 - val_auc: 0.5676 - 8s/epoch - 98ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0324 - auc: 0.8506 - val_loss: 0.6014 - val_auc: 0.5718 - 8s/epoch - 97ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0319 - auc: 0.8578 - val_loss: 0.6097 - val_auc: 0.5669 - 8s/epoch - 98ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0317 - auc: 0.8567 - val_loss: 0.5952 - val_auc: 0.5675 - 8s/epoch - 99ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0317 - auc: 0.8588 - val_loss: 0.5928 - val_auc: 0.5691 - 8s/epoch - 98ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0314 - auc: 0.8597 - val_loss: 0.6032 - val_auc: 0.5700 - 8s/epoch - 98ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0314 - auc: 0.8581 - val_loss: 0.5978 - val_auc: 0.5660 - 8s/epoch - 99ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0316 - auc: 0.8592 - val_loss: 0.6045 - val_auc: 0.5664 - 8s/epoch - 98ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0313 - auc: 0.8588 - val_loss: 0.6098 - val_auc: 0.5631 - 8s/epoch - 98ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0310 - auc: 0.8637 - val_loss: 0.6053 - val_auc: 0.5642 - 8s/epoch - 97ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0311 - auc: 0.8644 - val_loss: 0.5961 - val_auc: 0.5638 - 8s/epoch - 98ms/step\n",
            "Epoch 105/500\n",
            "81/81 - 8s - loss: 0.0307 - auc: 0.8665 - val_loss: 0.5929 - val_auc: 0.5664 - 8s/epoch - 99ms/step\n",
            "Epoch 106/500\n",
            "81/81 - 8s - loss: 0.0308 - auc: 0.8648 - val_loss: 0.6172 - val_auc: 0.5613 - 8s/epoch - 99ms/step\n",
            "Epoch 107/500\n",
            "81/81 - 8s - loss: 0.0306 - auc: 0.8693 - val_loss: 0.6051 - val_auc: 0.5613 - 8s/epoch - 104ms/step\n",
            "Epoch 108/500\n",
            "81/81 - 8s - loss: 0.0304 - auc: 0.8672 - val_loss: 0.6006 - val_auc: 0.5653 - 8s/epoch - 97ms/step\n",
            "Epoch 109/500\n",
            "81/81 - 8s - loss: 0.0304 - auc: 0.8687 - val_loss: 0.6109 - val_auc: 0.5573 - 8s/epoch - 98ms/step\n",
            "Epoch 110/500\n",
            "81/81 - 8s - loss: 0.0303 - auc: 0.8710 - val_loss: 0.5988 - val_auc: 0.5599 - 8s/epoch - 97ms/step\n",
            "Epoch 111/500\n",
            "81/81 - 8s - loss: 0.0298 - auc: 0.8750 - val_loss: 0.6018 - val_auc: 0.5615 - 8s/epoch - 97ms/step\n",
            "Epoch 112/500\n",
            "81/81 - 8s - loss: 0.0301 - auc: 0.8704 - val_loss: 0.6239 - val_auc: 0.5593 - 8s/epoch - 98ms/step\n",
            "Epoch 113/500\n",
            "81/81 - 8s - loss: 0.0296 - auc: 0.8766 - val_loss: 0.5845 - val_auc: 0.5559 - 8s/epoch - 97ms/step\n",
            "Epoch 114/500\n",
            "81/81 - 8s - loss: 0.0297 - auc: 0.8761 - val_loss: 0.6263 - val_auc: 0.5598 - 8s/epoch - 98ms/step\n",
            "Epoch 115/500\n",
            "81/81 - 8s - loss: 0.0294 - auc: 0.8782 - val_loss: 0.6065 - val_auc: 0.5635 - 8s/epoch - 98ms/step\n",
            "Epoch 116/500\n",
            "81/81 - 8s - loss: 0.0294 - auc: 0.8779 - val_loss: 0.6029 - val_auc: 0.5601 - 8s/epoch - 98ms/step\n",
            "Epoch 117/500\n",
            "81/81 - 8s - loss: 0.0292 - auc: 0.8784 - val_loss: 0.6234 - val_auc: 0.5548 - 8s/epoch - 98ms/step\n",
            "Epoch 118/500\n",
            "81/81 - 8s - loss: 0.0291 - auc: 0.8807 - val_loss: 0.6148 - val_auc: 0.5539 - 8s/epoch - 97ms/step\n",
            "Epoch 119/500\n",
            "81/81 - 8s - loss: 0.0287 - auc: 0.8837 - val_loss: 0.6056 - val_auc: 0.5557 - 8s/epoch - 98ms/step\n",
            "Epoch 120/500\n",
            "81/81 - 8s - loss: 0.0288 - auc: 0.8825 - val_loss: 0.6048 - val_auc: 0.5544 - 8s/epoch - 99ms/step\n",
            "Epoch 121/500\n",
            "81/81 - 8s - loss: 0.0285 - auc: 0.8846 - val_loss: 0.6043 - val_auc: 0.5604 - 8s/epoch - 98ms/step\n",
            "Epoch 122/500\n",
            "81/81 - 8s - loss: 0.0285 - auc: 0.8848 - val_loss: 0.6159 - val_auc: 0.5616 - 8s/epoch - 98ms/step\n",
            "Epoch 123/500\n",
            "81/81 - 8s - loss: 0.0283 - auc: 0.8870 - val_loss: 0.6014 - val_auc: 0.5622 - 8s/epoch - 98ms/step\n",
            "Epoch 124/500\n",
            "81/81 - 8s - loss: 0.0293 - auc: 0.8762 - val_loss: 0.6290 - val_auc: 0.5584 - 8s/epoch - 98ms/step\n",
            "Epoch 125/500\n",
            "81/81 - 8s - loss: 0.0283 - auc: 0.8901 - val_loss: 0.6127 - val_auc: 0.5615 - 8s/epoch - 97ms/step\n",
            "Epoch 126/500\n",
            "81/81 - 8s - loss: 0.0278 - auc: 0.8933 - val_loss: 0.6051 - val_auc: 0.5451 - 8s/epoch - 98ms/step\n",
            "Epoch 127/500\n",
            "81/81 - 8s - loss: 0.0278 - auc: 0.8896 - val_loss: 0.6012 - val_auc: 0.5500 - 8s/epoch - 98ms/step\n",
            "Epoch 128/500\n",
            "81/81 - 8s - loss: 0.0280 - auc: 0.8910 - val_loss: 0.6334 - val_auc: 0.5534 - 8s/epoch - 98ms/step\n",
            "Epoch 129/500\n",
            "81/81 - 8s - loss: 0.0279 - auc: 0.8899 - val_loss: 0.6113 - val_auc: 0.5482 - 8s/epoch - 97ms/step\n",
            "Epoch 130/500\n",
            "81/81 - 8s - loss: 0.0277 - auc: 0.8917 - val_loss: 0.6089 - val_auc: 0.5473 - 8s/epoch - 98ms/step\n",
            "Epoch 131/500\n",
            "81/81 - 8s - loss: 0.0272 - auc: 0.8961 - val_loss: 0.5990 - val_auc: 0.5447 - 8s/epoch - 98ms/step\n",
            "Epoch 132/500\n",
            "81/81 - 8s - loss: 0.0270 - auc: 0.8980 - val_loss: 0.6078 - val_auc: 0.5488 - 8s/epoch - 97ms/step\n",
            "Epoch 133/500\n",
            "81/81 - 8s - loss: 0.0271 - auc: 0.8977 - val_loss: 0.6140 - val_auc: 0.5467 - 8s/epoch - 98ms/step\n",
            "Epoch 134/500\n",
            "81/81 - 8s - loss: 0.0270 - auc: 0.8980 - val_loss: 0.6116 - val_auc: 0.5424 - 8s/epoch - 98ms/step\n",
            "Epoch 135/500\n",
            "81/81 - 8s - loss: 0.0266 - auc: 0.9018 - val_loss: 0.6094 - val_auc: 0.5454 - 8s/epoch - 98ms/step\n",
            "Epoch 136/500\n",
            "81/81 - 8s - loss: 0.0269 - auc: 0.8983 - val_loss: 0.6123 - val_auc: 0.5503 - 8s/epoch - 98ms/step\n",
            "Epoch 137/500\n",
            "81/81 - 8s - loss: 0.0263 - auc: 0.9051 - val_loss: 0.6017 - val_auc: 0.5493 - 8s/epoch - 98ms/step\n",
            "Epoch 138/500\n",
            "81/81 - 8s - loss: 0.0269 - auc: 0.8997 - val_loss: 0.5908 - val_auc: 0.5462 - 8s/epoch - 98ms/step\n",
            "Epoch 139/500\n",
            "81/81 - 8s - loss: 0.0264 - auc: 0.9049 - val_loss: 0.6085 - val_auc: 0.5468 - 8s/epoch - 97ms/step\n",
            "Epoch 140/500\n",
            "81/81 - 8s - loss: 0.0264 - auc: 0.9034 - val_loss: 0.6187 - val_auc: 0.5488 - 8s/epoch - 97ms/step\n",
            "Epoch 141/500\n",
            "81/81 - 8s - loss: 0.0265 - auc: 0.9017 - val_loss: 0.6050 - val_auc: 0.5477 - 8s/epoch - 98ms/step\n",
            "Epoch 142/500\n",
            "81/81 - 8s - loss: 0.0266 - auc: 0.9002 - val_loss: 0.6198 - val_auc: 0.5420 - 8s/epoch - 104ms/step\n",
            "Epoch 143/500\n",
            "81/81 - 8s - loss: 0.0260 - auc: 0.9075 - val_loss: 0.5806 - val_auc: 0.5476 - 8s/epoch - 97ms/step\n",
            "Epoch 144/500\n",
            "81/81 - 8s - loss: 0.0261 - auc: 0.9066 - val_loss: 0.5951 - val_auc: 0.5493 - 8s/epoch - 100ms/step\n",
            "Epoch 145/500\n",
            "81/81 - 8s - loss: 0.0257 - auc: 0.9101 - val_loss: 0.5979 - val_auc: 0.5473 - 8s/epoch - 98ms/step\n",
            "Epoch 146/500\n",
            "81/81 - 8s - loss: 0.0257 - auc: 0.9100 - val_loss: 0.6054 - val_auc: 0.5444 - 8s/epoch - 97ms/step\n",
            "Epoch 147/500\n",
            "81/81 - 8s - loss: 0.0255 - auc: 0.9127 - val_loss: 0.6074 - val_auc: 0.5453 - 8s/epoch - 97ms/step\n",
            "Epoch 148/500\n",
            "81/81 - 8s - loss: 0.0254 - auc: 0.9119 - val_loss: 0.5910 - val_auc: 0.5493 - 8s/epoch - 98ms/step\n",
            "Epoch 149/500\n",
            "81/81 - 8s - loss: 0.0255 - auc: 0.9101 - val_loss: 0.6164 - val_auc: 0.5370 - 8s/epoch - 99ms/step\n",
            "Epoch 150/500\n",
            "81/81 - 8s - loss: 0.0252 - auc: 0.9129 - val_loss: 0.6006 - val_auc: 0.5401 - 8s/epoch - 99ms/step\n",
            "Epoch 151/500\n",
            "81/81 - 8s - loss: 0.0258 - auc: 0.9080 - val_loss: 0.6242 - val_auc: 0.5424 - 8s/epoch - 99ms/step\n",
            "Epoch 152/500\n",
            "81/81 - 8s - loss: 0.0253 - auc: 0.9111 - val_loss: 0.5950 - val_auc: 0.5412 - 8s/epoch - 98ms/step\n",
            "Epoch 153/500\n",
            "81/81 - 8s - loss: 0.0249 - auc: 0.9159 - val_loss: 0.6092 - val_auc: 0.5382 - 8s/epoch - 98ms/step\n",
            "Epoch 154/500\n",
            "81/81 - 8s - loss: 0.0253 - auc: 0.9116 - val_loss: 0.5980 - val_auc: 0.5408 - 8s/epoch - 97ms/step\n",
            "Epoch 155/500\n",
            "81/81 - 8s - loss: 0.0247 - auc: 0.9190 - val_loss: 0.6120 - val_auc: 0.5380 - 8s/epoch - 98ms/step\n",
            "Epoch 156/500\n",
            "81/81 - 8s - loss: 0.0248 - auc: 0.9166 - val_loss: 0.5984 - val_auc: 0.5425 - 8s/epoch - 99ms/step\n",
            "Epoch 157/500\n",
            "81/81 - 8s - loss: 0.0247 - auc: 0.9182 - val_loss: 0.6365 - val_auc: 0.5430 - 8s/epoch - 99ms/step\n",
            "Epoch 158/500\n",
            "81/81 - 8s - loss: 0.0245 - auc: 0.9209 - val_loss: 0.5966 - val_auc: 0.5441 - 8s/epoch - 101ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 3s 115ms/step - loss: 0.5719 - auc: 0.6836\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 35ms/step - loss: 0.5827 - auc: 0.5739\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 1\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 9s - loss: 0.0495 - auc: 0.4864 - val_loss: 0.6867 - val_auc: 0.6212 - 9s/epoch - 113ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0491 - auc: 0.6352 - val_loss: 0.6702 - val_auc: 0.6526 - 8s/epoch - 101ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0489 - auc: 0.6473 - val_loss: 0.6571 - val_auc: 0.6586 - 8s/epoch - 100ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0486 - auc: 0.6516 - val_loss: 0.6473 - val_auc: 0.6617 - 8s/epoch - 99ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0484 - auc: 0.6496 - val_loss: 0.6400 - val_auc: 0.6650 - 8s/epoch - 100ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0482 - auc: 0.6532 - val_loss: 0.6335 - val_auc: 0.6637 - 8s/epoch - 99ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0479 - auc: 0.6570 - val_loss: 0.6288 - val_auc: 0.6612 - 8s/epoch - 98ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0478 - auc: 0.6531 - val_loss: 0.6259 - val_auc: 0.6610 - 8s/epoch - 98ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6529 - val_loss: 0.6237 - val_auc: 0.6607 - 8s/epoch - 99ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0474 - auc: 0.6520 - val_loss: 0.6228 - val_auc: 0.6607 - 8s/epoch - 99ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0473 - auc: 0.6537 - val_loss: 0.6235 - val_auc: 0.6612 - 8s/epoch - 98ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6544 - val_loss: 0.6244 - val_auc: 0.6619 - 8s/epoch - 98ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6521 - val_loss: 0.6256 - val_auc: 0.6600 - 8s/epoch - 100ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0469 - auc: 0.6536 - val_loss: 0.6266 - val_auc: 0.6619 - 8s/epoch - 99ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6539 - val_loss: 0.6261 - val_auc: 0.6619 - 8s/epoch - 99ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6533 - val_loss: 0.6282 - val_auc: 0.6611 - 8s/epoch - 100ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0466 - auc: 0.6567 - val_loss: 0.6273 - val_auc: 0.6619 - 8s/epoch - 99ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 9s - loss: 0.0466 - auc: 0.6551 - val_loss: 0.6282 - val_auc: 0.6616 - 9s/epoch - 105ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6554 - val_loss: 0.6293 - val_auc: 0.6608 - 8s/epoch - 98ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6578 - val_loss: 0.6296 - val_auc: 0.6614 - 8s/epoch - 99ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6587 - val_loss: 0.6300 - val_auc: 0.6614 - 8s/epoch - 98ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6597 - val_loss: 0.6289 - val_auc: 0.6605 - 8s/epoch - 101ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6605 - val_loss: 0.6290 - val_auc: 0.6595 - 8s/epoch - 100ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6619 - val_loss: 0.6303 - val_auc: 0.6596 - 8s/epoch - 99ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6611 - val_loss: 0.6297 - val_auc: 0.6597 - 8s/epoch - 99ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6647 - val_loss: 0.6297 - val_auc: 0.6593 - 8s/epoch - 100ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6669 - val_loss: 0.6283 - val_auc: 0.6595 - 8s/epoch - 99ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6655 - val_loss: 0.6292 - val_auc: 0.6597 - 8s/epoch - 100ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6700 - val_loss: 0.6276 - val_auc: 0.6603 - 8s/epoch - 100ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6696 - val_loss: 0.6275 - val_auc: 0.6605 - 8s/epoch - 99ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6717 - val_loss: 0.6267 - val_auc: 0.6618 - 8s/epoch - 100ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6733 - val_loss: 0.6265 - val_auc: 0.6611 - 8s/epoch - 98ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6747 - val_loss: 0.6257 - val_auc: 0.6611 - 8s/epoch - 99ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6759 - val_loss: 0.6256 - val_auc: 0.6612 - 8s/epoch - 98ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6741 - val_loss: 0.6259 - val_auc: 0.6615 - 8s/epoch - 99ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6813 - val_loss: 0.6249 - val_auc: 0.6612 - 8s/epoch - 98ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6796 - val_loss: 0.6258 - val_auc: 0.6622 - 8s/epoch - 98ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6873 - val_loss: 0.6223 - val_auc: 0.6641 - 8s/epoch - 99ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0449 - auc: 0.6817 - val_loss: 0.6231 - val_auc: 0.6645 - 8s/epoch - 98ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6830 - val_loss: 0.6220 - val_auc: 0.6643 - 8s/epoch - 99ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6854 - val_loss: 0.6202 - val_auc: 0.6654 - 8s/epoch - 99ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0446 - auc: 0.6866 - val_loss: 0.6190 - val_auc: 0.6663 - 8s/epoch - 100ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6906 - val_loss: 0.6172 - val_auc: 0.6677 - 8s/epoch - 99ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0444 - auc: 0.6895 - val_loss: 0.6192 - val_auc: 0.6678 - 8s/epoch - 99ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6911 - val_loss: 0.6162 - val_auc: 0.6685 - 8s/epoch - 99ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6913 - val_loss: 0.6181 - val_auc: 0.6695 - 8s/epoch - 98ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0441 - auc: 0.6960 - val_loss: 0.6153 - val_auc: 0.6697 - 8s/epoch - 100ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6950 - val_loss: 0.6156 - val_auc: 0.6696 - 8s/epoch - 98ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.6953 - val_loss: 0.6140 - val_auc: 0.6695 - 8s/epoch - 99ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.6977 - val_loss: 0.6136 - val_auc: 0.6695 - 8s/epoch - 99ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.7005 - val_loss: 0.6109 - val_auc: 0.6704 - 8s/epoch - 98ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0437 - auc: 0.7013 - val_loss: 0.6099 - val_auc: 0.6710 - 8s/epoch - 100ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0437 - auc: 0.7031 - val_loss: 0.6092 - val_auc: 0.6696 - 8s/epoch - 99ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7040 - val_loss: 0.6087 - val_auc: 0.6705 - 8s/epoch - 104ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7059 - val_loss: 0.6069 - val_auc: 0.6713 - 8s/epoch - 99ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7067 - val_loss: 0.6078 - val_auc: 0.6704 - 8s/epoch - 99ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7060 - val_loss: 0.6074 - val_auc: 0.6716 - 8s/epoch - 100ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0432 - auc: 0.7119 - val_loss: 0.6049 - val_auc: 0.6724 - 8s/epoch - 99ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0432 - auc: 0.7103 - val_loss: 0.6048 - val_auc: 0.6717 - 8s/epoch - 100ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7120 - val_loss: 0.6043 - val_auc: 0.6724 - 8s/epoch - 99ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0429 - auc: 0.7139 - val_loss: 0.6014 - val_auc: 0.6719 - 8s/epoch - 101ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7162 - val_loss: 0.6026 - val_auc: 0.6721 - 8s/epoch - 98ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7205 - val_loss: 0.5983 - val_auc: 0.6732 - 8s/epoch - 99ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7219 - val_loss: 0.5970 - val_auc: 0.6710 - 8s/epoch - 99ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0425 - auc: 0.7231 - val_loss: 0.5941 - val_auc: 0.6714 - 8s/epoch - 99ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7246 - val_loss: 0.5970 - val_auc: 0.6721 - 8s/epoch - 98ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7260 - val_loss: 0.5969 - val_auc: 0.6713 - 8s/epoch - 99ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7294 - val_loss: 0.5939 - val_auc: 0.6704 - 8s/epoch - 99ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7310 - val_loss: 0.5940 - val_auc: 0.6699 - 8s/epoch - 100ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0418 - auc: 0.7366 - val_loss: 0.5915 - val_auc: 0.6718 - 8s/epoch - 99ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0418 - auc: 0.7350 - val_loss: 0.5906 - val_auc: 0.6709 - 8s/epoch - 100ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0417 - auc: 0.7363 - val_loss: 0.5930 - val_auc: 0.6695 - 8s/epoch - 98ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7451 - val_loss: 0.5890 - val_auc: 0.6693 - 8s/epoch - 99ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7431 - val_loss: 0.5891 - val_auc: 0.6670 - 8s/epoch - 98ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7412 - val_loss: 0.5896 - val_auc: 0.6678 - 8s/epoch - 98ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0412 - auc: 0.7452 - val_loss: 0.5865 - val_auc: 0.6661 - 8s/epoch - 98ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7453 - val_loss: 0.5891 - val_auc: 0.6650 - 8s/epoch - 99ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0409 - auc: 0.7491 - val_loss: 0.5834 - val_auc: 0.6636 - 8s/epoch - 99ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0408 - auc: 0.7511 - val_loss: 0.5868 - val_auc: 0.6633 - 8s/epoch - 98ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7526 - val_loss: 0.5818 - val_auc: 0.6615 - 8s/epoch - 99ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7514 - val_loss: 0.5854 - val_auc: 0.6595 - 8s/epoch - 98ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7517 - val_loss: 0.5822 - val_auc: 0.6610 - 8s/epoch - 97ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7543 - val_loss: 0.5819 - val_auc: 0.6594 - 8s/epoch - 97ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7528 - val_loss: 0.5841 - val_auc: 0.6575 - 8s/epoch - 99ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7595 - val_loss: 0.5829 - val_auc: 0.6582 - 8s/epoch - 98ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7599 - val_loss: 0.5816 - val_auc: 0.6566 - 8s/epoch - 98ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7587 - val_loss: 0.5871 - val_auc: 0.6562 - 8s/epoch - 98ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7620 - val_loss: 0.5841 - val_auc: 0.6555 - 8s/epoch - 99ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7630 - val_loss: 0.5851 - val_auc: 0.6537 - 8s/epoch - 98ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 9s - loss: 0.0395 - auc: 0.7623 - val_loss: 0.5832 - val_auc: 0.6536 - 9s/epoch - 105ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7653 - val_loss: 0.5811 - val_auc: 0.6532 - 8s/epoch - 99ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0392 - auc: 0.7675 - val_loss: 0.5804 - val_auc: 0.6522 - 8s/epoch - 99ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0392 - auc: 0.7679 - val_loss: 0.5817 - val_auc: 0.6511 - 8s/epoch - 98ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7704 - val_loss: 0.5810 - val_auc: 0.6515 - 8s/epoch - 98ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7707 - val_loss: 0.5852 - val_auc: 0.6510 - 8s/epoch - 98ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7690 - val_loss: 0.5852 - val_auc: 0.6512 - 8s/epoch - 99ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0386 - auc: 0.7764 - val_loss: 0.5836 - val_auc: 0.6503 - 8s/epoch - 98ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0388 - auc: 0.7707 - val_loss: 0.5837 - val_auc: 0.6500 - 8s/epoch - 99ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7794 - val_loss: 0.5794 - val_auc: 0.6510 - 8s/epoch - 101ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0384 - auc: 0.7773 - val_loss: 0.5862 - val_auc: 0.6499 - 8s/epoch - 99ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0381 - auc: 0.7825 - val_loss: 0.5734 - val_auc: 0.6511 - 8s/epoch - 99ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7819 - val_loss: 0.5819 - val_auc: 0.6506 - 8s/epoch - 99ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7827 - val_loss: 0.5809 - val_auc: 0.6502 - 8s/epoch - 99ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0379 - auc: 0.7827 - val_loss: 0.5811 - val_auc: 0.6495 - 8s/epoch - 98ms/step\n",
            "Epoch 105/500\n",
            "81/81 - 8s - loss: 0.0379 - auc: 0.7842 - val_loss: 0.5835 - val_auc: 0.6487 - 8s/epoch - 98ms/step\n",
            "Epoch 106/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7860 - val_loss: 0.5809 - val_auc: 0.6487 - 8s/epoch - 97ms/step\n",
            "Epoch 107/500\n",
            "81/81 - 8s - loss: 0.0375 - auc: 0.7881 - val_loss: 0.5839 - val_auc: 0.6482 - 8s/epoch - 97ms/step\n",
            "Epoch 108/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7917 - val_loss: 0.5814 - val_auc: 0.6478 - 8s/epoch - 97ms/step\n",
            "Epoch 109/500\n",
            "81/81 - 8s - loss: 0.0372 - auc: 0.7934 - val_loss: 0.5796 - val_auc: 0.6450 - 8s/epoch - 97ms/step\n",
            "Epoch 110/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7917 - val_loss: 0.5862 - val_auc: 0.6428 - 8s/epoch - 98ms/step\n",
            "Epoch 111/500\n",
            "81/81 - 8s - loss: 0.0369 - auc: 0.7972 - val_loss: 0.5828 - val_auc: 0.6436 - 8s/epoch - 98ms/step\n",
            "Epoch 112/500\n",
            "81/81 - 8s - loss: 0.0370 - auc: 0.7945 - val_loss: 0.5812 - val_auc: 0.6437 - 8s/epoch - 98ms/step\n",
            "Epoch 113/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.7989 - val_loss: 0.5782 - val_auc: 0.6442 - 8s/epoch - 98ms/step\n",
            "Epoch 114/500\n",
            "81/81 - 8s - loss: 0.0366 - auc: 0.8016 - val_loss: 0.5747 - val_auc: 0.6454 - 8s/epoch - 99ms/step\n",
            "Epoch 115/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8083 - val_loss: 0.5780 - val_auc: 0.6397 - 8s/epoch - 97ms/step\n",
            "Epoch 116/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8046 - val_loss: 0.5804 - val_auc: 0.6407 - 8s/epoch - 100ms/step\n",
            "Epoch 117/500\n",
            "81/81 - 8s - loss: 0.0361 - auc: 0.8076 - val_loss: 0.5857 - val_auc: 0.6397 - 8s/epoch - 98ms/step\n",
            "Epoch 118/500\n",
            "81/81 - 8s - loss: 0.0363 - auc: 0.8023 - val_loss: 0.5845 - val_auc: 0.6394 - 8s/epoch - 99ms/step\n",
            "Epoch 119/500\n",
            "81/81 - 8s - loss: 0.0359 - auc: 0.8081 - val_loss: 0.5837 - val_auc: 0.6401 - 8s/epoch - 100ms/step\n",
            "Epoch 120/500\n",
            "81/81 - 8s - loss: 0.0358 - auc: 0.8103 - val_loss: 0.5756 - val_auc: 0.6400 - 8s/epoch - 99ms/step\n",
            "Epoch 121/500\n",
            "81/81 - 8s - loss: 0.0359 - auc: 0.8063 - val_loss: 0.5758 - val_auc: 0.6401 - 8s/epoch - 99ms/step\n",
            "Epoch 122/500\n",
            "81/81 - 8s - loss: 0.0354 - auc: 0.8155 - val_loss: 0.5833 - val_auc: 0.6387 - 8s/epoch - 99ms/step\n",
            "Epoch 123/500\n",
            "81/81 - 8s - loss: 0.0353 - auc: 0.8170 - val_loss: 0.5759 - val_auc: 0.6387 - 8s/epoch - 99ms/step\n",
            "Epoch 124/500\n",
            "81/81 - 8s - loss: 0.0349 - auc: 0.8205 - val_loss: 0.5731 - val_auc: 0.6403 - 8s/epoch - 100ms/step\n",
            "Epoch 125/500\n",
            "81/81 - 9s - loss: 0.0351 - auc: 0.8185 - val_loss: 0.5760 - val_auc: 0.6397 - 9s/epoch - 107ms/step\n",
            "Epoch 126/500\n",
            "81/81 - 8s - loss: 0.0349 - auc: 0.8222 - val_loss: 0.5801 - val_auc: 0.6383 - 8s/epoch - 99ms/step\n",
            "Epoch 127/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8238 - val_loss: 0.5763 - val_auc: 0.6407 - 8s/epoch - 98ms/step\n",
            "Epoch 128/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8239 - val_loss: 0.5656 - val_auc: 0.6406 - 8s/epoch - 98ms/step\n",
            "Epoch 129/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8218 - val_loss: 0.5765 - val_auc: 0.6391 - 8s/epoch - 99ms/step\n",
            "Epoch 130/500\n",
            "81/81 - 8s - loss: 0.0346 - auc: 0.8215 - val_loss: 0.5765 - val_auc: 0.6387 - 8s/epoch - 98ms/step\n",
            "Epoch 131/500\n",
            "81/81 - 8s - loss: 0.0341 - auc: 0.8332 - val_loss: 0.5636 - val_auc: 0.6383 - 8s/epoch - 98ms/step\n",
            "Epoch 132/500\n",
            "81/81 - 8s - loss: 0.0340 - auc: 0.8338 - val_loss: 0.5679 - val_auc: 0.6408 - 8s/epoch - 99ms/step\n",
            "Epoch 133/500\n",
            "81/81 - 8s - loss: 0.0342 - auc: 0.8259 - val_loss: 0.5722 - val_auc: 0.6409 - 8s/epoch - 99ms/step\n",
            "Epoch 134/500\n",
            "81/81 - 8s - loss: 0.0335 - auc: 0.8390 - val_loss: 0.5766 - val_auc: 0.6384 - 8s/epoch - 98ms/step\n",
            "Epoch 135/500\n",
            "81/81 - 8s - loss: 0.0337 - auc: 0.8342 - val_loss: 0.5699 - val_auc: 0.6414 - 8s/epoch - 99ms/step\n",
            "Epoch 136/500\n",
            "81/81 - 8s - loss: 0.0335 - auc: 0.8365 - val_loss: 0.5594 - val_auc: 0.6430 - 8s/epoch - 99ms/step\n",
            "Epoch 137/500\n",
            "81/81 - 8s - loss: 0.0334 - auc: 0.8392 - val_loss: 0.5817 - val_auc: 0.6403 - 8s/epoch - 99ms/step\n",
            "Epoch 138/500\n",
            "81/81 - 8s - loss: 0.0334 - auc: 0.8373 - val_loss: 0.5678 - val_auc: 0.6423 - 8s/epoch - 100ms/step\n",
            "Epoch 139/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8416 - val_loss: 0.5772 - val_auc: 0.6418 - 8s/epoch - 100ms/step\n",
            "Epoch 140/500\n",
            "81/81 - 8s - loss: 0.0330 - auc: 0.8415 - val_loss: 0.5556 - val_auc: 0.6435 - 8s/epoch - 98ms/step\n",
            "Epoch 141/500\n",
            "81/81 - 8s - loss: 0.0327 - auc: 0.8473 - val_loss: 0.5660 - val_auc: 0.6420 - 8s/epoch - 99ms/step\n",
            "Epoch 142/500\n",
            "81/81 - 8s - loss: 0.0328 - auc: 0.8444 - val_loss: 0.5819 - val_auc: 0.6386 - 8s/epoch - 98ms/step\n",
            "Epoch 143/500\n",
            "81/81 - 8s - loss: 0.0323 - auc: 0.8495 - val_loss: 0.5710 - val_auc: 0.6429 - 8s/epoch - 98ms/step\n",
            "Epoch 144/500\n",
            "81/81 - 8s - loss: 0.0319 - auc: 0.8555 - val_loss: 0.5673 - val_auc: 0.6452 - 8s/epoch - 98ms/step\n",
            "Epoch 145/500\n",
            "81/81 - 8s - loss: 0.0324 - auc: 0.8478 - val_loss: 0.5634 - val_auc: 0.6463 - 8s/epoch - 100ms/step\n",
            "Epoch 146/500\n",
            "81/81 - 8s - loss: 0.0322 - auc: 0.8485 - val_loss: 0.5651 - val_auc: 0.6439 - 8s/epoch - 98ms/step\n",
            "Epoch 147/500\n",
            "81/81 - 8s - loss: 0.0318 - auc: 0.8524 - val_loss: 0.5676 - val_auc: 0.6468 - 8s/epoch - 98ms/step\n",
            "Epoch 148/500\n",
            "81/81 - 8s - loss: 0.0320 - auc: 0.8506 - val_loss: 0.5664 - val_auc: 0.6448 - 8s/epoch - 99ms/step\n",
            "Epoch 149/500\n",
            "81/81 - 8s - loss: 0.0321 - auc: 0.8493 - val_loss: 0.5550 - val_auc: 0.6470 - 8s/epoch - 99ms/step\n",
            "Epoch 150/500\n",
            "81/81 - 8s - loss: 0.0318 - auc: 0.8524 - val_loss: 0.5714 - val_auc: 0.6464 - 8s/epoch - 100ms/step\n",
            "Epoch 151/500\n",
            "81/81 - 8s - loss: 0.0312 - auc: 0.8589 - val_loss: 0.5615 - val_auc: 0.6470 - 8s/epoch - 99ms/step\n",
            "Epoch 152/500\n",
            "81/81 - 8s - loss: 0.0313 - auc: 0.8573 - val_loss: 0.5687 - val_auc: 0.6445 - 8s/epoch - 99ms/step\n",
            "Epoch 153/500\n",
            "81/81 - 8s - loss: 0.0311 - auc: 0.8585 - val_loss: 0.5659 - val_auc: 0.6469 - 8s/epoch - 100ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 37ms/step - loss: 0.6118 - auc: 0.6700\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 35ms/step - loss: 0.5983 - auc: 0.6732\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 2\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 10s - loss: 0.0495 - auc: 0.5044 - val_loss: 0.6866 - val_auc: 0.5722 - 10s/epoch - 123ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0491 - auc: 0.6442 - val_loss: 0.6711 - val_auc: 0.6113 - 8s/epoch - 101ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0487 - auc: 0.6594 - val_loss: 0.6606 - val_auc: 0.6152 - 8s/epoch - 100ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0483 - auc: 0.6612 - val_loss: 0.6548 - val_auc: 0.6098 - 8s/epoch - 98ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0480 - auc: 0.6566 - val_loss: 0.6467 - val_auc: 0.6115 - 8s/epoch - 98ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6650 - val_loss: 0.6398 - val_auc: 0.6125 - 8s/epoch - 98ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0474 - auc: 0.6597 - val_loss: 0.6353 - val_auc: 0.6096 - 8s/epoch - 99ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0472 - auc: 0.6579 - val_loss: 0.6332 - val_auc: 0.6070 - 8s/epoch - 98ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0470 - auc: 0.6601 - val_loss: 0.6308 - val_auc: 0.6091 - 8s/epoch - 98ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0469 - auc: 0.6600 - val_loss: 0.6301 - val_auc: 0.6089 - 8s/epoch - 97ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6604 - val_loss: 0.6306 - val_auc: 0.6104 - 8s/epoch - 97ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6604 - val_loss: 0.6296 - val_auc: 0.6087 - 8s/epoch - 97ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6624 - val_loss: 0.6308 - val_auc: 0.6096 - 8s/epoch - 97ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6625 - val_loss: 0.6326 - val_auc: 0.6110 - 8s/epoch - 98ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6619 - val_loss: 0.6330 - val_auc: 0.6105 - 8s/epoch - 98ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6627 - val_loss: 0.6331 - val_auc: 0.6127 - 8s/epoch - 98ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6632 - val_loss: 0.6326 - val_auc: 0.6136 - 8s/epoch - 98ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6652 - val_loss: 0.6330 - val_auc: 0.6136 - 8s/epoch - 97ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6680 - val_loss: 0.6325 - val_auc: 0.6147 - 8s/epoch - 97ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6694 - val_loss: 0.6325 - val_auc: 0.6172 - 8s/epoch - 100ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6691 - val_loss: 0.6315 - val_auc: 0.6173 - 8s/epoch - 101ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6722 - val_loss: 0.6310 - val_auc: 0.6157 - 8s/epoch - 99ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6721 - val_loss: 0.6312 - val_auc: 0.6190 - 8s/epoch - 98ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6751 - val_loss: 0.6286 - val_auc: 0.6185 - 8s/epoch - 99ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6752 - val_loss: 0.6289 - val_auc: 0.6182 - 8s/epoch - 100ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6809 - val_loss: 0.6269 - val_auc: 0.6186 - 8s/epoch - 98ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6799 - val_loss: 0.6291 - val_auc: 0.6186 - 8s/epoch - 98ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6812 - val_loss: 0.6271 - val_auc: 0.6172 - 8s/epoch - 99ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6843 - val_loss: 0.6261 - val_auc: 0.6171 - 8s/epoch - 99ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6842 - val_loss: 0.6237 - val_auc: 0.6189 - 8s/epoch - 99ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6864 - val_loss: 0.6242 - val_auc: 0.6177 - 8s/epoch - 99ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6852 - val_loss: 0.6259 - val_auc: 0.6168 - 8s/epoch - 99ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6888 - val_loss: 0.6237 - val_auc: 0.6163 - 8s/epoch - 99ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0444 - auc: 0.6900 - val_loss: 0.6221 - val_auc: 0.6148 - 8s/epoch - 99ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6922 - val_loss: 0.6244 - val_auc: 0.6143 - 8s/epoch - 99ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6956 - val_loss: 0.6229 - val_auc: 0.6141 - 8s/epoch - 98ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0441 - auc: 0.6960 - val_loss: 0.6231 - val_auc: 0.6132 - 8s/epoch - 103ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7017 - val_loss: 0.6193 - val_auc: 0.6140 - 8s/epoch - 98ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.6991 - val_loss: 0.6212 - val_auc: 0.6102 - 8s/epoch - 98ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0437 - auc: 0.7034 - val_loss: 0.6192 - val_auc: 0.6094 - 8s/epoch - 98ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7060 - val_loss: 0.6183 - val_auc: 0.6097 - 8s/epoch - 99ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7059 - val_loss: 0.6175 - val_auc: 0.6086 - 8s/epoch - 97ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7070 - val_loss: 0.6173 - val_auc: 0.6066 - 8s/epoch - 98ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7075 - val_loss: 0.6188 - val_auc: 0.6045 - 8s/epoch - 97ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7096 - val_loss: 0.6168 - val_auc: 0.6046 - 8s/epoch - 98ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7113 - val_loss: 0.6152 - val_auc: 0.6048 - 8s/epoch - 98ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7128 - val_loss: 0.6161 - val_auc: 0.6036 - 8s/epoch - 99ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0429 - auc: 0.7167 - val_loss: 0.6154 - val_auc: 0.6017 - 8s/epoch - 98ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7175 - val_loss: 0.6121 - val_auc: 0.6027 - 8s/epoch - 99ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7152 - val_loss: 0.6169 - val_auc: 0.6022 - 8s/epoch - 98ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0425 - auc: 0.7234 - val_loss: 0.6128 - val_auc: 0.5989 - 8s/epoch - 98ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0425 - auc: 0.7195 - val_loss: 0.6118 - val_auc: 0.6001 - 8s/epoch - 99ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7267 - val_loss: 0.6127 - val_auc: 0.5989 - 8s/epoch - 98ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7246 - val_loss: 0.6148 - val_auc: 0.5995 - 8s/epoch - 97ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7268 - val_loss: 0.6119 - val_auc: 0.5977 - 8s/epoch - 99ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7280 - val_loss: 0.6120 - val_auc: 0.5985 - 8s/epoch - 99ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7314 - val_loss: 0.6105 - val_auc: 0.5991 - 8s/epoch - 98ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0418 - auc: 0.7327 - val_loss: 0.6116 - val_auc: 0.5988 - 8s/epoch - 99ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0418 - auc: 0.7325 - val_loss: 0.6091 - val_auc: 0.5973 - 8s/epoch - 99ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7358 - val_loss: 0.6099 - val_auc: 0.5958 - 8s/epoch - 100ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7362 - val_loss: 0.6100 - val_auc: 0.5952 - 8s/epoch - 98ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0415 - auc: 0.7369 - val_loss: 0.6097 - val_auc: 0.5960 - 8s/epoch - 97ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7381 - val_loss: 0.6097 - val_auc: 0.5960 - 8s/epoch - 97ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0412 - auc: 0.7409 - val_loss: 0.6083 - val_auc: 0.5965 - 8s/epoch - 97ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7444 - val_loss: 0.6105 - val_auc: 0.5971 - 8s/epoch - 97ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7452 - val_loss: 0.6099 - val_auc: 0.5957 - 8s/epoch - 98ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7453 - val_loss: 0.6066 - val_auc: 0.5951 - 8s/epoch - 97ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7487 - val_loss: 0.6073 - val_auc: 0.5966 - 8s/epoch - 97ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7510 - val_loss: 0.6081 - val_auc: 0.5964 - 8s/epoch - 97ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7528 - val_loss: 0.6069 - val_auc: 0.5979 - 8s/epoch - 98ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0405 - auc: 0.7505 - val_loss: 0.6097 - val_auc: 0.5967 - 8s/epoch - 97ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7540 - val_loss: 0.6067 - val_auc: 0.5973 - 8s/epoch - 98ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7537 - val_loss: 0.6086 - val_auc: 0.5973 - 8s/epoch - 102ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7603 - val_loss: 0.6041 - val_auc: 0.5963 - 8s/epoch - 99ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7557 - val_loss: 0.6106 - val_auc: 0.5967 - 8s/epoch - 97ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7585 - val_loss: 0.6106 - val_auc: 0.5971 - 8s/epoch - 98ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7600 - val_loss: 0.6109 - val_auc: 0.5961 - 8s/epoch - 98ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7614 - val_loss: 0.6114 - val_auc: 0.5976 - 8s/epoch - 99ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7610 - val_loss: 0.6097 - val_auc: 0.5978 - 8s/epoch - 98ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0395 - auc: 0.7648 - val_loss: 0.6094 - val_auc: 0.5979 - 8s/epoch - 97ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0395 - auc: 0.7646 - val_loss: 0.6102 - val_auc: 0.5980 - 8s/epoch - 97ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7681 - val_loss: 0.6120 - val_auc: 0.5980 - 8s/epoch - 99ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7678 - val_loss: 0.6106 - val_auc: 0.5988 - 8s/epoch - 99ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7704 - val_loss: 0.6108 - val_auc: 0.5987 - 8s/epoch - 97ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7687 - val_loss: 0.6151 - val_auc: 0.5978 - 8s/epoch - 97ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7658 - val_loss: 0.6149 - val_auc: 0.5991 - 8s/epoch - 98ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0388 - auc: 0.7734 - val_loss: 0.6185 - val_auc: 0.5988 - 8s/epoch - 97ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7704 - val_loss: 0.6145 - val_auc: 0.6003 - 8s/epoch - 98ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7757 - val_loss: 0.6139 - val_auc: 0.6011 - 8s/epoch - 98ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7774 - val_loss: 0.6153 - val_auc: 0.6017 - 8s/epoch - 97ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0386 - auc: 0.7746 - val_loss: 0.6185 - val_auc: 0.6013 - 8s/epoch - 97ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0384 - auc: 0.7776 - val_loss: 0.6125 - val_auc: 0.6018 - 8s/epoch - 97ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7821 - val_loss: 0.6150 - val_auc: 0.6030 - 8s/epoch - 97ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7823 - val_loss: 0.6098 - val_auc: 0.6022 - 8s/epoch - 97ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7851 - val_loss: 0.6140 - val_auc: 0.6030 - 8s/epoch - 98ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7830 - val_loss: 0.6143 - val_auc: 0.6023 - 8s/epoch - 97ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0378 - auc: 0.7866 - val_loss: 0.6159 - val_auc: 0.6020 - 8s/epoch - 98ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0378 - auc: 0.7891 - val_loss: 0.6132 - val_auc: 0.6036 - 8s/epoch - 100ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7884 - val_loss: 0.6157 - val_auc: 0.6015 - 8s/epoch - 99ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7933 - val_loss: 0.6169 - val_auc: 0.6035 - 8s/epoch - 97ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0375 - auc: 0.7911 - val_loss: 0.6178 - val_auc: 0.6027 - 8s/epoch - 97ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7897 - val_loss: 0.6191 - val_auc: 0.6028 - 8s/epoch - 97ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0372 - auc: 0.7965 - val_loss: 0.6132 - val_auc: 0.6056 - 8s/epoch - 98ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7956 - val_loss: 0.6156 - val_auc: 0.6053 - 8s/epoch - 99ms/step\n",
            "Epoch 105/500\n",
            "81/81 - 8s - loss: 0.0369 - auc: 0.7974 - val_loss: 0.6128 - val_auc: 0.6066 - 8s/epoch - 98ms/step\n",
            "Epoch 106/500\n",
            "81/81 - 8s - loss: 0.0369 - auc: 0.7997 - val_loss: 0.6110 - val_auc: 0.6056 - 8s/epoch - 97ms/step\n",
            "Epoch 107/500\n",
            "81/81 - 8s - loss: 0.0367 - auc: 0.8003 - val_loss: 0.6160 - val_auc: 0.6067 - 8s/epoch - 98ms/step\n",
            "Epoch 108/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.7964 - val_loss: 0.6184 - val_auc: 0.6056 - 8s/epoch - 103ms/step\n",
            "Epoch 109/500\n",
            "81/81 - 8s - loss: 0.0366 - auc: 0.8015 - val_loss: 0.6206 - val_auc: 0.6076 - 8s/epoch - 97ms/step\n",
            "Epoch 110/500\n",
            "81/81 - 8s - loss: 0.0364 - auc: 0.8040 - val_loss: 0.6147 - val_auc: 0.6096 - 8s/epoch - 98ms/step\n",
            "Epoch 111/500\n",
            "81/81 - 8s - loss: 0.0364 - auc: 0.8049 - val_loss: 0.6193 - val_auc: 0.6092 - 8s/epoch - 98ms/step\n",
            "Epoch 112/500\n",
            "81/81 - 8s - loss: 0.0360 - auc: 0.8088 - val_loss: 0.6187 - val_auc: 0.6108 - 8s/epoch - 98ms/step\n",
            "Epoch 113/500\n",
            "81/81 - 8s - loss: 0.0361 - auc: 0.8093 - val_loss: 0.6223 - val_auc: 0.6099 - 8s/epoch - 100ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 36ms/step - loss: 0.6364 - auc: 0.6256\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 38ms/step - loss: 0.6312 - auc: 0.6190\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 3\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 9s - loss: 0.0496 - auc: 0.5110 - val_loss: 0.6861 - val_auc: 0.6344 - 9s/epoch - 110ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0492 - auc: 0.6305 - val_loss: 0.6715 - val_auc: 0.6585 - 8s/epoch - 99ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0488 - auc: 0.6405 - val_loss: 0.6601 - val_auc: 0.6558 - 8s/epoch - 98ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0484 - auc: 0.6549 - val_loss: 0.6526 - val_auc: 0.6647 - 8s/epoch - 98ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0481 - auc: 0.6535 - val_loss: 0.6480 - val_auc: 0.6664 - 8s/epoch - 98ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0478 - auc: 0.6565 - val_loss: 0.6420 - val_auc: 0.6702 - 8s/epoch - 99ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6559 - val_loss: 0.6410 - val_auc: 0.6709 - 8s/epoch - 98ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0474 - auc: 0.6560 - val_loss: 0.6404 - val_auc: 0.6669 - 8s/epoch - 97ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0472 - auc: 0.6540 - val_loss: 0.6410 - val_auc: 0.6718 - 8s/epoch - 98ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0470 - auc: 0.6569 - val_loss: 0.6422 - val_auc: 0.6700 - 8s/epoch - 98ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0470 - auc: 0.6527 - val_loss: 0.6421 - val_auc: 0.6719 - 8s/epoch - 99ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6552 - val_loss: 0.6430 - val_auc: 0.6715 - 8s/epoch - 99ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6575 - val_loss: 0.6424 - val_auc: 0.6710 - 8s/epoch - 98ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6586 - val_loss: 0.6414 - val_auc: 0.6732 - 8s/epoch - 99ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6596 - val_loss: 0.6420 - val_auc: 0.6728 - 8s/epoch - 99ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6595 - val_loss: 0.6428 - val_auc: 0.6715 - 8s/epoch - 99ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6620 - val_loss: 0.6419 - val_auc: 0.6725 - 8s/epoch - 98ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6637 - val_loss: 0.6405 - val_auc: 0.6715 - 8s/epoch - 98ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 9s - loss: 0.0459 - auc: 0.6661 - val_loss: 0.6393 - val_auc: 0.6723 - 9s/epoch - 106ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6675 - val_loss: 0.6394 - val_auc: 0.6709 - 8s/epoch - 98ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0457 - auc: 0.6693 - val_loss: 0.6379 - val_auc: 0.6715 - 8s/epoch - 98ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6705 - val_loss: 0.6361 - val_auc: 0.6708 - 8s/epoch - 100ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6726 - val_loss: 0.6364 - val_auc: 0.6712 - 8s/epoch - 100ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6757 - val_loss: 0.6351 - val_auc: 0.6714 - 8s/epoch - 98ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6764 - val_loss: 0.6324 - val_auc: 0.6714 - 8s/epoch - 98ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6794 - val_loss: 0.6337 - val_auc: 0.6706 - 8s/epoch - 99ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6796 - val_loss: 0.6326 - val_auc: 0.6724 - 8s/epoch - 99ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6844 - val_loss: 0.6297 - val_auc: 0.6711 - 8s/epoch - 99ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0449 - auc: 0.6865 - val_loss: 0.6308 - val_auc: 0.6692 - 8s/epoch - 99ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6899 - val_loss: 0.6280 - val_auc: 0.6707 - 8s/epoch - 99ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0446 - auc: 0.6899 - val_loss: 0.6286 - val_auc: 0.6705 - 8s/epoch - 99ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0446 - auc: 0.6915 - val_loss: 0.6296 - val_auc: 0.6710 - 8s/epoch - 99ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6934 - val_loss: 0.6261 - val_auc: 0.6714 - 8s/epoch - 99ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6985 - val_loss: 0.6251 - val_auc: 0.6708 - 8s/epoch - 99ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6972 - val_loss: 0.6258 - val_auc: 0.6699 - 8s/epoch - 99ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6981 - val_loss: 0.6250 - val_auc: 0.6706 - 8s/epoch - 99ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.7037 - val_loss: 0.6244 - val_auc: 0.6687 - 8s/epoch - 100ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.7042 - val_loss: 0.6234 - val_auc: 0.6698 - 8s/epoch - 98ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.7035 - val_loss: 0.6234 - val_auc: 0.6692 - 8s/epoch - 99ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7077 - val_loss: 0.6216 - val_auc: 0.6687 - 8s/epoch - 99ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0437 - auc: 0.7065 - val_loss: 0.6228 - val_auc: 0.6687 - 8s/epoch - 100ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7121 - val_loss: 0.6205 - val_auc: 0.6674 - 8s/epoch - 99ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7114 - val_loss: 0.6203 - val_auc: 0.6677 - 8s/epoch - 99ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7102 - val_loss: 0.6207 - val_auc: 0.6657 - 8s/epoch - 98ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7128 - val_loss: 0.6207 - val_auc: 0.6660 - 8s/epoch - 99ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0432 - auc: 0.7152 - val_loss: 0.6174 - val_auc: 0.6671 - 8s/epoch - 98ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7163 - val_loss: 0.6198 - val_auc: 0.6660 - 8s/epoch - 99ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7186 - val_loss: 0.6189 - val_auc: 0.6645 - 8s/epoch - 99ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7216 - val_loss: 0.6134 - val_auc: 0.6651 - 8s/epoch - 104ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7221 - val_loss: 0.6157 - val_auc: 0.6637 - 8s/epoch - 99ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7226 - val_loss: 0.6169 - val_auc: 0.6631 - 8s/epoch - 99ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7261 - val_loss: 0.6158 - val_auc: 0.6625 - 8s/epoch - 99ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7301 - val_loss: 0.6132 - val_auc: 0.6614 - 8s/epoch - 99ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7303 - val_loss: 0.6125 - val_auc: 0.6579 - 8s/epoch - 99ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0420 - auc: 0.7313 - val_loss: 0.6135 - val_auc: 0.6576 - 8s/epoch - 99ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7340 - val_loss: 0.6109 - val_auc: 0.6557 - 8s/epoch - 99ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0417 - auc: 0.7360 - val_loss: 0.6108 - val_auc: 0.6538 - 8s/epoch - 98ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7408 - val_loss: 0.6078 - val_auc: 0.6525 - 8s/epoch - 98ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7425 - val_loss: 0.6110 - val_auc: 0.6501 - 8s/epoch - 98ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7425 - val_loss: 0.6122 - val_auc: 0.6496 - 8s/epoch - 100ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7456 - val_loss: 0.6107 - val_auc: 0.6466 - 8s/epoch - 101ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7535 - val_loss: 0.6065 - val_auc: 0.6466 - 8s/epoch - 100ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0408 - auc: 0.7481 - val_loss: 0.6094 - val_auc: 0.6439 - 8s/epoch - 99ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7541 - val_loss: 0.6159 - val_auc: 0.6416 - 8s/epoch - 98ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7561 - val_loss: 0.6055 - val_auc: 0.6409 - 8s/epoch - 99ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7600 - val_loss: 0.6046 - val_auc: 0.6385 - 8s/epoch - 98ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7584 - val_loss: 0.6099 - val_auc: 0.6379 - 8s/epoch - 98ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7616 - val_loss: 0.6076 - val_auc: 0.6348 - 8s/epoch - 99ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7621 - val_loss: 0.6112 - val_auc: 0.6330 - 8s/epoch - 99ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7635 - val_loss: 0.6059 - val_auc: 0.6336 - 8s/epoch - 99ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7661 - val_loss: 0.6079 - val_auc: 0.6319 - 8s/epoch - 98ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7633 - val_loss: 0.6097 - val_auc: 0.6313 - 8s/epoch - 99ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7684 - val_loss: 0.6062 - val_auc: 0.6307 - 8s/epoch - 98ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7681 - val_loss: 0.6108 - val_auc: 0.6297 - 8s/epoch - 98ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7713 - val_loss: 0.6110 - val_auc: 0.6291 - 8s/epoch - 97ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7693 - val_loss: 0.6120 - val_auc: 0.6279 - 8s/epoch - 98ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7722 - val_loss: 0.6123 - val_auc: 0.6266 - 8s/epoch - 98ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7739 - val_loss: 0.6078 - val_auc: 0.6278 - 8s/epoch - 99ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7771 - val_loss: 0.6073 - val_auc: 0.6252 - 8s/epoch - 98ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7808 - val_loss: 0.6073 - val_auc: 0.6253 - 8s/epoch - 103ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0383 - auc: 0.7812 - val_loss: 0.6089 - val_auc: 0.6239 - 8s/epoch - 98ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7822 - val_loss: 0.6108 - val_auc: 0.6236 - 8s/epoch - 98ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7837 - val_loss: 0.6088 - val_auc: 0.6251 - 8s/epoch - 99ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0381 - auc: 0.7836 - val_loss: 0.6100 - val_auc: 0.6218 - 8s/epoch - 97ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7841 - val_loss: 0.6072 - val_auc: 0.6221 - 8s/epoch - 98ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0377 - auc: 0.7912 - val_loss: 0.6063 - val_auc: 0.6233 - 8s/epoch - 97ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7905 - val_loss: 0.6057 - val_auc: 0.6207 - 8s/epoch - 98ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0377 - auc: 0.7854 - val_loss: 0.6087 - val_auc: 0.6221 - 8s/epoch - 98ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0374 - auc: 0.7944 - val_loss: 0.6011 - val_auc: 0.6199 - 8s/epoch - 99ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0374 - auc: 0.7907 - val_loss: 0.6113 - val_auc: 0.6209 - 8s/epoch - 98ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7933 - val_loss: 0.6072 - val_auc: 0.6177 - 8s/epoch - 99ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7956 - val_loss: 0.6053 - val_auc: 0.6159 - 8s/epoch - 98ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0370 - auc: 0.7972 - val_loss: 0.6060 - val_auc: 0.6165 - 8s/epoch - 98ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0367 - auc: 0.7995 - val_loss: 0.6035 - val_auc: 0.6162 - 8s/epoch - 98ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0366 - auc: 0.8059 - val_loss: 0.6026 - val_auc: 0.6156 - 8s/epoch - 99ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.7992 - val_loss: 0.5990 - val_auc: 0.6153 - 8s/epoch - 98ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0365 - auc: 0.8026 - val_loss: 0.6084 - val_auc: 0.6170 - 8s/epoch - 99ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0364 - auc: 0.8043 - val_loss: 0.5965 - val_auc: 0.6148 - 8s/epoch - 99ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0361 - auc: 0.8092 - val_loss: 0.6008 - val_auc: 0.6148 - 8s/epoch - 101ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0361 - auc: 0.8083 - val_loss: 0.5952 - val_auc: 0.6147 - 8s/epoch - 98ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0360 - auc: 0.8090 - val_loss: 0.6023 - val_auc: 0.6154 - 8s/epoch - 98ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0359 - auc: 0.8100 - val_loss: 0.6011 - val_auc: 0.6151 - 8s/epoch - 98ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0358 - auc: 0.8115 - val_loss: 0.5980 - val_auc: 0.6141 - 8s/epoch - 97ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0356 - auc: 0.8150 - val_loss: 0.6066 - val_auc: 0.6142 - 8s/epoch - 101ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 37ms/step - loss: 0.6436 - auc: 0.6246\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 38ms/step - loss: 0.6414 - auc: 0.6732\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 4\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 10s - loss: 0.0496 - auc: 0.5159 - val_loss: 0.6826 - val_auc: 0.7127 - 10s/epoch - 119ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0492 - auc: 0.6303 - val_loss: 0.6689 - val_auc: 0.7361 - 8s/epoch - 100ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0489 - auc: 0.6340 - val_loss: 0.6616 - val_auc: 0.7401 - 8s/epoch - 98ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0486 - auc: 0.6423 - val_loss: 0.6555 - val_auc: 0.7383 - 8s/epoch - 100ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0483 - auc: 0.6483 - val_loss: 0.6510 - val_auc: 0.7408 - 8s/epoch - 98ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0480 - auc: 0.6479 - val_loss: 0.6482 - val_auc: 0.7368 - 8s/epoch - 98ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0479 - auc: 0.6441 - val_loss: 0.6479 - val_auc: 0.7351 - 8s/epoch - 97ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6451 - val_loss: 0.6477 - val_auc: 0.7339 - 8s/epoch - 98ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0474 - auc: 0.6507 - val_loss: 0.6498 - val_auc: 0.7340 - 8s/epoch - 97ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0473 - auc: 0.6485 - val_loss: 0.6511 - val_auc: 0.7339 - 8s/epoch - 97ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6476 - val_loss: 0.6529 - val_auc: 0.7334 - 8s/epoch - 98ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6485 - val_loss: 0.6563 - val_auc: 0.7325 - 8s/epoch - 97ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0469 - auc: 0.6514 - val_loss: 0.6559 - val_auc: 0.7358 - 8s/epoch - 99ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6513 - val_loss: 0.6568 - val_auc: 0.7338 - 8s/epoch - 98ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6539 - val_loss: 0.6555 - val_auc: 0.7355 - 8s/epoch - 98ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6508 - val_loss: 0.6580 - val_auc: 0.7350 - 8s/epoch - 98ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6561 - val_loss: 0.6568 - val_auc: 0.7355 - 8s/epoch - 99ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6570 - val_loss: 0.6563 - val_auc: 0.7355 - 8s/epoch - 98ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6584 - val_loss: 0.6555 - val_auc: 0.7339 - 8s/epoch - 99ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6603 - val_loss: 0.6553 - val_auc: 0.7351 - 8s/epoch - 100ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6645 - val_loss: 0.6530 - val_auc: 0.7339 - 8s/epoch - 98ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6628 - val_loss: 0.6553 - val_auc: 0.7346 - 8s/epoch - 98ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6664 - val_loss: 0.6548 - val_auc: 0.7321 - 8s/epoch - 98ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6681 - val_loss: 0.6543 - val_auc: 0.7311 - 8s/epoch - 98ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6725 - val_loss: 0.6518 - val_auc: 0.7317 - 8s/epoch - 97ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6749 - val_loss: 0.6508 - val_auc: 0.7316 - 8s/epoch - 98ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6761 - val_loss: 0.6512 - val_auc: 0.7309 - 8s/epoch - 98ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6796 - val_loss: 0.6510 - val_auc: 0.7291 - 8s/epoch - 99ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6812 - val_loss: 0.6503 - val_auc: 0.7297 - 8s/epoch - 99ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6829 - val_loss: 0.6501 - val_auc: 0.7303 - 8s/epoch - 99ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6825 - val_loss: 0.6513 - val_auc: 0.7305 - 8s/epoch - 99ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0449 - auc: 0.6858 - val_loss: 0.6476 - val_auc: 0.7316 - 8s/epoch - 102ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6889 - val_loss: 0.6471 - val_auc: 0.7332 - 8s/epoch - 99ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6909 - val_loss: 0.6492 - val_auc: 0.7320 - 8s/epoch - 99ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 9s - loss: 0.0447 - auc: 0.6915 - val_loss: 0.6469 - val_auc: 0.7327 - 9s/epoch - 106ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0444 - auc: 0.6957 - val_loss: 0.6456 - val_auc: 0.7321 - 8s/epoch - 98ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6942 - val_loss: 0.6461 - val_auc: 0.7347 - 8s/epoch - 99ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0444 - auc: 0.6940 - val_loss: 0.6447 - val_auc: 0.7326 - 8s/epoch - 100ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6962 - val_loss: 0.6455 - val_auc: 0.7321 - 8s/epoch - 99ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6986 - val_loss: 0.6464 - val_auc: 0.7323 - 8s/epoch - 99ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.7020 - val_loss: 0.6454 - val_auc: 0.7322 - 8s/epoch - 100ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.7026 - val_loss: 0.6423 - val_auc: 0.7337 - 8s/epoch - 100ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7041 - val_loss: 0.6448 - val_auc: 0.7336 - 8s/epoch - 99ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7034 - val_loss: 0.6467 - val_auc: 0.7335 - 8s/epoch - 100ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7072 - val_loss: 0.6433 - val_auc: 0.7336 - 8s/epoch - 100ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7076 - val_loss: 0.6424 - val_auc: 0.7345 - 8s/epoch - 99ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7094 - val_loss: 0.6424 - val_auc: 0.7360 - 8s/epoch - 100ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7124 - val_loss: 0.6433 - val_auc: 0.7334 - 8s/epoch - 99ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7088 - val_loss: 0.6450 - val_auc: 0.7355 - 8s/epoch - 99ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7163 - val_loss: 0.6393 - val_auc: 0.7342 - 8s/epoch - 100ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7195 - val_loss: 0.6421 - val_auc: 0.7361 - 8s/epoch - 99ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0429 - auc: 0.7196 - val_loss: 0.6423 - val_auc: 0.7359 - 8s/epoch - 98ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7209 - val_loss: 0.6420 - val_auc: 0.7379 - 8s/epoch - 99ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7239 - val_loss: 0.6397 - val_auc: 0.7401 - 8s/epoch - 99ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0425 - auc: 0.7260 - val_loss: 0.6422 - val_auc: 0.7402 - 8s/epoch - 99ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7265 - val_loss: 0.6392 - val_auc: 0.7408 - 8s/epoch - 98ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7323 - val_loss: 0.6425 - val_auc: 0.7395 - 8s/epoch - 99ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7333 - val_loss: 0.6335 - val_auc: 0.7407 - 8s/epoch - 99ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7365 - val_loss: 0.6339 - val_auc: 0.7397 - 8s/epoch - 97ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7400 - val_loss: 0.6365 - val_auc: 0.7398 - 8s/epoch - 99ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7404 - val_loss: 0.6362 - val_auc: 0.7408 - 8s/epoch - 100ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7429 - val_loss: 0.6371 - val_auc: 0.7397 - 8s/epoch - 99ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0411 - auc: 0.7515 - val_loss: 0.6348 - val_auc: 0.7408 - 8s/epoch - 98ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0411 - auc: 0.7461 - val_loss: 0.6364 - val_auc: 0.7420 - 8s/epoch - 99ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0409 - auc: 0.7478 - val_loss: 0.6391 - val_auc: 0.7397 - 8s/epoch - 99ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7524 - val_loss: 0.6342 - val_auc: 0.7390 - 8s/epoch - 98ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7525 - val_loss: 0.6308 - val_auc: 0.7378 - 8s/epoch - 99ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7540 - val_loss: 0.6407 - val_auc: 0.7372 - 8s/epoch - 99ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7553 - val_loss: 0.6334 - val_auc: 0.7368 - 8s/epoch - 98ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 9s - loss: 0.0401 - auc: 0.7619 - val_loss: 0.6353 - val_auc: 0.7348 - 9s/epoch - 105ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0400 - auc: 0.7628 - val_loss: 0.6395 - val_auc: 0.7334 - 8s/epoch - 100ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0400 - auc: 0.7599 - val_loss: 0.6349 - val_auc: 0.7327 - 8s/epoch - 98ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7633 - val_loss: 0.6343 - val_auc: 0.7299 - 8s/epoch - 98ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7678 - val_loss: 0.6415 - val_auc: 0.7293 - 8s/epoch - 99ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7664 - val_loss: 0.6365 - val_auc: 0.7289 - 8s/epoch - 98ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7727 - val_loss: 0.6374 - val_auc: 0.7289 - 8s/epoch - 99ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7675 - val_loss: 0.6409 - val_auc: 0.7253 - 8s/epoch - 98ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7739 - val_loss: 0.6350 - val_auc: 0.7276 - 8s/epoch - 99ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0388 - auc: 0.7796 - val_loss: 0.6352 - val_auc: 0.7263 - 8s/epoch - 99ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7714 - val_loss: 0.6434 - val_auc: 0.7240 - 8s/epoch - 99ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0388 - auc: 0.7787 - val_loss: 0.6368 - val_auc: 0.7255 - 8s/epoch - 98ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7766 - val_loss: 0.6348 - val_auc: 0.7245 - 8s/epoch - 98ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7829 - val_loss: 0.6385 - val_auc: 0.7236 - 8s/epoch - 100ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0386 - auc: 0.7790 - val_loss: 0.6251 - val_auc: 0.7240 - 8s/epoch - 99ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7840 - val_loss: 0.6332 - val_auc: 0.7220 - 8s/epoch - 99ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0381 - auc: 0.7844 - val_loss: 0.6327 - val_auc: 0.7225 - 8s/epoch - 99ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0379 - auc: 0.7904 - val_loss: 0.6311 - val_auc: 0.7213 - 8s/epoch - 99ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0378 - auc: 0.7897 - val_loss: 0.6365 - val_auc: 0.7209 - 8s/epoch - 98ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7929 - val_loss: 0.6352 - val_auc: 0.7205 - 8s/epoch - 98ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0377 - auc: 0.7943 - val_loss: 0.6315 - val_auc: 0.7193 - 8s/epoch - 98ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7962 - val_loss: 0.6344 - val_auc: 0.7183 - 8s/epoch - 100ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0372 - auc: 0.7979 - val_loss: 0.6322 - val_auc: 0.7170 - 8s/epoch - 99ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7964 - val_loss: 0.6356 - val_auc: 0.7158 - 8s/epoch - 98ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0370 - auc: 0.8002 - val_loss: 0.6247 - val_auc: 0.7165 - 8s/epoch - 98ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.8044 - val_loss: 0.6278 - val_auc: 0.7164 - 8s/epoch - 99ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0369 - auc: 0.7982 - val_loss: 0.6264 - val_auc: 0.7137 - 8s/epoch - 99ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0364 - auc: 0.8108 - val_loss: 0.6195 - val_auc: 0.7136 - 8s/epoch - 100ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0365 - auc: 0.8055 - val_loss: 0.6338 - val_auc: 0.7090 - 8s/epoch - 98ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8095 - val_loss: 0.6220 - val_auc: 0.7089 - 8s/epoch - 98ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0361 - auc: 0.8111 - val_loss: 0.6248 - val_auc: 0.7073 - 8s/epoch - 98ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0359 - auc: 0.8142 - val_loss: 0.6273 - val_auc: 0.7061 - 8s/epoch - 98ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0357 - auc: 0.8171 - val_loss: 0.6267 - val_auc: 0.7047 - 8s/epoch - 98ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0358 - auc: 0.8137 - val_loss: 0.6339 - val_auc: 0.7021 - 8s/epoch - 99ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0356 - auc: 0.8172 - val_loss: 0.6324 - val_auc: 0.7012 - 8s/epoch - 99ms/step\n",
            "Epoch 105/500\n",
            "81/81 - 9s - loss: 0.0355 - auc: 0.8206 - val_loss: 0.6280 - val_auc: 0.7019 - 9s/epoch - 107ms/step\n",
            "Epoch 106/500\n",
            "81/81 - 8s - loss: 0.0353 - auc: 0.8211 - val_loss: 0.6277 - val_auc: 0.7014 - 8s/epoch - 99ms/step\n",
            "Epoch 107/500\n",
            "81/81 - 8s - loss: 0.0350 - auc: 0.8253 - val_loss: 0.6201 - val_auc: 0.7039 - 8s/epoch - 100ms/step\n",
            "Epoch 108/500\n",
            "81/81 - 8s - loss: 0.0351 - auc: 0.8232 - val_loss: 0.5960 - val_auc: 0.7036 - 8s/epoch - 101ms/step\n",
            "Epoch 109/500\n",
            "81/81 - 8s - loss: 0.0348 - auc: 0.8260 - val_loss: 0.6239 - val_auc: 0.7009 - 8s/epoch - 102ms/step\n",
            "Epoch 110/500\n",
            "81/81 - 8s - loss: 0.0349 - auc: 0.8257 - val_loss: 0.6174 - val_auc: 0.7016 - 8s/epoch - 100ms/step\n",
            "Epoch 111/500\n",
            "81/81 - 8s - loss: 0.0343 - auc: 0.8352 - val_loss: 0.6199 - val_auc: 0.6991 - 8s/epoch - 99ms/step\n",
            "Epoch 112/500\n",
            "81/81 - 8s - loss: 0.0345 - auc: 0.8315 - val_loss: 0.6294 - val_auc: 0.6972 - 8s/epoch - 99ms/step\n",
            "Epoch 113/500\n",
            "81/81 - 8s - loss: 0.0343 - auc: 0.8352 - val_loss: 0.6182 - val_auc: 0.6989 - 8s/epoch - 100ms/step\n",
            "Epoch 114/500\n",
            "81/81 - 8s - loss: 0.0337 - auc: 0.8414 - val_loss: 0.6153 - val_auc: 0.6996 - 8s/epoch - 99ms/step\n",
            "Epoch 115/500\n",
            "81/81 - 8s - loss: 0.0338 - auc: 0.8418 - val_loss: 0.6227 - val_auc: 0.6992 - 8s/epoch - 99ms/step\n",
            "Epoch 116/500\n",
            "81/81 - 8s - loss: 0.0337 - auc: 0.8420 - val_loss: 0.6136 - val_auc: 0.6986 - 8s/epoch - 99ms/step\n",
            "Epoch 117/500\n",
            "81/81 - 8s - loss: 0.0338 - auc: 0.8370 - val_loss: 0.6188 - val_auc: 0.6984 - 8s/epoch - 99ms/step\n",
            "Epoch 118/500\n",
            "81/81 - 8s - loss: 0.0336 - auc: 0.8410 - val_loss: 0.6152 - val_auc: 0.6959 - 8s/epoch - 99ms/step\n",
            "Epoch 119/500\n",
            "81/81 - 8s - loss: 0.0333 - auc: 0.8480 - val_loss: 0.6034 - val_auc: 0.6948 - 8s/epoch - 98ms/step\n",
            "Epoch 120/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8469 - val_loss: 0.5983 - val_auc: 0.6972 - 8s/epoch - 98ms/step\n",
            "Epoch 121/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8457 - val_loss: 0.6259 - val_auc: 0.6919 - 8s/epoch - 99ms/step\n",
            "Epoch 122/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8440 - val_loss: 0.6140 - val_auc: 0.6953 - 8s/epoch - 99ms/step\n",
            "Epoch 123/500\n",
            "81/81 - 8s - loss: 0.0330 - auc: 0.8489 - val_loss: 0.6156 - val_auc: 0.6937 - 8s/epoch - 99ms/step\n",
            "Epoch 124/500\n",
            "81/81 - 8s - loss: 0.0330 - auc: 0.8499 - val_loss: 0.6038 - val_auc: 0.6946 - 8s/epoch - 99ms/step\n",
            "Epoch 125/500\n",
            "81/81 - 8s - loss: 0.0326 - auc: 0.8518 - val_loss: 0.5953 - val_auc: 0.6978 - 8s/epoch - 99ms/step\n",
            "Epoch 126/500\n",
            "81/81 - 8s - loss: 0.0325 - auc: 0.8520 - val_loss: 0.6284 - val_auc: 0.6871 - 8s/epoch - 99ms/step\n",
            "Epoch 127/500\n",
            "81/81 - 8s - loss: 0.0324 - auc: 0.8545 - val_loss: 0.5930 - val_auc: 0.6946 - 8s/epoch - 99ms/step\n",
            "Epoch 128/500\n",
            "81/81 - 8s - loss: 0.0322 - auc: 0.8575 - val_loss: 0.5973 - val_auc: 0.6922 - 8s/epoch - 99ms/step\n",
            "Epoch 129/500\n",
            "81/81 - 8s - loss: 0.0320 - auc: 0.8568 - val_loss: 0.5932 - val_auc: 0.6929 - 8s/epoch - 99ms/step\n",
            "Epoch 130/500\n",
            "81/81 - 8s - loss: 0.0321 - auc: 0.8550 - val_loss: 0.6022 - val_auc: 0.6930 - 8s/epoch - 98ms/step\n",
            "Epoch 131/500\n",
            "81/81 - 8s - loss: 0.0315 - auc: 0.8624 - val_loss: 0.5943 - val_auc: 0.6904 - 8s/epoch - 99ms/step\n",
            "Epoch 132/500\n",
            "81/81 - 8s - loss: 0.0314 - auc: 0.8642 - val_loss: 0.5968 - val_auc: 0.6912 - 8s/epoch - 100ms/step\n",
            "Epoch 133/500\n",
            "81/81 - 8s - loss: 0.0313 - auc: 0.8645 - val_loss: 0.6133 - val_auc: 0.6875 - 8s/epoch - 100ms/step\n",
            "Epoch 134/500\n",
            "81/81 - 8s - loss: 0.0313 - auc: 0.8618 - val_loss: 0.6007 - val_auc: 0.6944 - 8s/epoch - 100ms/step\n",
            "Epoch 135/500\n",
            "81/81 - 8s - loss: 0.0310 - auc: 0.8693 - val_loss: 0.6112 - val_auc: 0.6893 - 8s/epoch - 100ms/step\n",
            "Epoch 136/500\n",
            "81/81 - 8s - loss: 0.0309 - auc: 0.8662 - val_loss: 0.5916 - val_auc: 0.6935 - 8s/epoch - 101ms/step\n",
            "Epoch 137/500\n",
            "81/81 - 8s - loss: 0.0310 - auc: 0.8654 - val_loss: 0.5843 - val_auc: 0.6954 - 8s/epoch - 99ms/step\n",
            "Epoch 138/500\n",
            "81/81 - 8s - loss: 0.0308 - auc: 0.8662 - val_loss: 0.5946 - val_auc: 0.6939 - 8s/epoch - 101ms/step\n",
            "Epoch 139/500\n",
            "81/81 - 8s - loss: 0.0305 - auc: 0.8709 - val_loss: 0.5888 - val_auc: 0.6907 - 8s/epoch - 99ms/step\n",
            "Epoch 140/500\n",
            "81/81 - 9s - loss: 0.0305 - auc: 0.8683 - val_loss: 0.5947 - val_auc: 0.6925 - 9s/epoch - 106ms/step\n",
            "Epoch 141/500\n",
            "81/81 - 8s - loss: 0.0304 - auc: 0.8727 - val_loss: 0.5815 - val_auc: 0.6900 - 8s/epoch - 99ms/step\n",
            "Epoch 142/500\n",
            "81/81 - 8s - loss: 0.0300 - auc: 0.8753 - val_loss: 0.5910 - val_auc: 0.6905 - 8s/epoch - 99ms/step\n",
            "Epoch 143/500\n",
            "81/81 - 8s - loss: 0.0302 - auc: 0.8715 - val_loss: 0.6026 - val_auc: 0.6879 - 8s/epoch - 99ms/step\n",
            "Epoch 144/500\n",
            "81/81 - 8s - loss: 0.0297 - auc: 0.8771 - val_loss: 0.5732 - val_auc: 0.6931 - 8s/epoch - 99ms/step\n",
            "Epoch 145/500\n",
            "81/81 - 8s - loss: 0.0299 - auc: 0.8775 - val_loss: 0.5925 - val_auc: 0.6930 - 8s/epoch - 99ms/step\n",
            "Epoch 146/500\n",
            "81/81 - 8s - loss: 0.0297 - auc: 0.8761 - val_loss: 0.5879 - val_auc: 0.6894 - 8s/epoch - 100ms/step\n",
            "Epoch 147/500\n",
            "81/81 - 8s - loss: 0.0294 - auc: 0.8800 - val_loss: 0.5900 - val_auc: 0.6936 - 8s/epoch - 100ms/step\n",
            "Epoch 148/500\n",
            "81/81 - 8s - loss: 0.0294 - auc: 0.8800 - val_loss: 0.5841 - val_auc: 0.6946 - 8s/epoch - 99ms/step\n",
            "Epoch 149/500\n",
            "81/81 - 8s - loss: 0.0291 - auc: 0.8843 - val_loss: 0.5760 - val_auc: 0.6914 - 8s/epoch - 99ms/step\n",
            "Epoch 150/500\n",
            "81/81 - 8s - loss: 0.0290 - auc: 0.8826 - val_loss: 0.5754 - val_auc: 0.6960 - 8s/epoch - 99ms/step\n",
            "Epoch 151/500\n",
            "81/81 - 8s - loss: 0.0289 - auc: 0.8829 - val_loss: 0.5822 - val_auc: 0.6923 - 8s/epoch - 99ms/step\n",
            "Epoch 152/500\n",
            "81/81 - 8s - loss: 0.0289 - auc: 0.8850 - val_loss: 0.5647 - val_auc: 0.6951 - 8s/epoch - 100ms/step\n",
            "Epoch 153/500\n",
            "81/81 - 8s - loss: 0.0283 - auc: 0.8893 - val_loss: 0.5495 - val_auc: 0.6971 - 8s/epoch - 98ms/step\n",
            "Epoch 154/500\n",
            "81/81 - 8s - loss: 0.0283 - auc: 0.8912 - val_loss: 0.5582 - val_auc: 0.6935 - 8s/epoch - 102ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 37ms/step - loss: 0.6140 - auc: 0.7019\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 39ms/step - loss: 0.6364 - auc: 0.7420\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 5\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 10s - loss: 0.0496 - auc: 0.4900 - val_loss: 0.6870 - val_auc: 0.6233 - 10s/epoch - 123ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0492 - auc: 0.6308 - val_loss: 0.6729 - val_auc: 0.6484 - 8s/epoch - 101ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0489 - auc: 0.6554 - val_loss: 0.6625 - val_auc: 0.6533 - 8s/epoch - 99ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0485 - auc: 0.6527 - val_loss: 0.6548 - val_auc: 0.6449 - 8s/epoch - 99ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0482 - auc: 0.6541 - val_loss: 0.6483 - val_auc: 0.6467 - 8s/epoch - 98ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0479 - auc: 0.6532 - val_loss: 0.6445 - val_auc: 0.6474 - 8s/epoch - 99ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6564 - val_loss: 0.6428 - val_auc: 0.6469 - 8s/epoch - 99ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0473 - auc: 0.6545 - val_loss: 0.6421 - val_auc: 0.6476 - 8s/epoch - 99ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6598 - val_loss: 0.6421 - val_auc: 0.6458 - 8s/epoch - 99ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0470 - auc: 0.6536 - val_loss: 0.6447 - val_auc: 0.6456 - 8s/epoch - 100ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6538 - val_loss: 0.6469 - val_auc: 0.6477 - 8s/epoch - 99ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6536 - val_loss: 0.6501 - val_auc: 0.6495 - 8s/epoch - 99ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6568 - val_loss: 0.6516 - val_auc: 0.6509 - 8s/epoch - 99ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6549 - val_loss: 0.6556 - val_auc: 0.6511 - 8s/epoch - 100ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6559 - val_loss: 0.6574 - val_auc: 0.6536 - 8s/epoch - 100ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6588 - val_loss: 0.6579 - val_auc: 0.6528 - 8s/epoch - 99ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6604 - val_loss: 0.6586 - val_auc: 0.6552 - 8s/epoch - 98ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6605 - val_loss: 0.6591 - val_auc: 0.6571 - 8s/epoch - 104ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6599 - val_loss: 0.6594 - val_auc: 0.6570 - 8s/epoch - 99ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6616 - val_loss: 0.6594 - val_auc: 0.6608 - 8s/epoch - 100ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6605 - val_loss: 0.6621 - val_auc: 0.6600 - 8s/epoch - 98ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6617 - val_loss: 0.6606 - val_auc: 0.6616 - 8s/epoch - 99ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0457 - auc: 0.6654 - val_loss: 0.6609 - val_auc: 0.6636 - 8s/epoch - 100ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6670 - val_loss: 0.6594 - val_auc: 0.6660 - 8s/epoch - 100ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6652 - val_loss: 0.6596 - val_auc: 0.6656 - 8s/epoch - 98ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6693 - val_loss: 0.6609 - val_auc: 0.6668 - 8s/epoch - 100ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6731 - val_loss: 0.6606 - val_auc: 0.6691 - 8s/epoch - 99ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6700 - val_loss: 0.6607 - val_auc: 0.6707 - 8s/epoch - 100ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6737 - val_loss: 0.6598 - val_auc: 0.6719 - 8s/epoch - 101ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6744 - val_loss: 0.6609 - val_auc: 0.6730 - 8s/epoch - 99ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 9s - loss: 0.0451 - auc: 0.6765 - val_loss: 0.6588 - val_auc: 0.6737 - 9s/epoch - 107ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6777 - val_loss: 0.6603 - val_auc: 0.6757 - 8s/epoch - 100ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6767 - val_loss: 0.6604 - val_auc: 0.6741 - 8s/epoch - 99ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6816 - val_loss: 0.6597 - val_auc: 0.6744 - 8s/epoch - 99ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6819 - val_loss: 0.6603 - val_auc: 0.6752 - 8s/epoch - 99ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6827 - val_loss: 0.6612 - val_auc: 0.6754 - 8s/epoch - 99ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6836 - val_loss: 0.6616 - val_auc: 0.6766 - 8s/epoch - 100ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6895 - val_loss: 0.6597 - val_auc: 0.6754 - 8s/epoch - 99ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6871 - val_loss: 0.6619 - val_auc: 0.6772 - 8s/epoch - 100ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0444 - auc: 0.6861 - val_loss: 0.6624 - val_auc: 0.6781 - 8s/epoch - 99ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6904 - val_loss: 0.6619 - val_auc: 0.6791 - 8s/epoch - 101ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0444 - auc: 0.6890 - val_loss: 0.6636 - val_auc: 0.6785 - 8s/epoch - 100ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6936 - val_loss: 0.6615 - val_auc: 0.6808 - 8s/epoch - 100ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6919 - val_loss: 0.6621 - val_auc: 0.6809 - 8s/epoch - 100ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.6967 - val_loss: 0.6613 - val_auc: 0.6818 - 8s/epoch - 100ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.6995 - val_loss: 0.6602 - val_auc: 0.6811 - 8s/epoch - 99ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.6986 - val_loss: 0.6636 - val_auc: 0.6799 - 8s/epoch - 99ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7034 - val_loss: 0.6632 - val_auc: 0.6802 - 8s/epoch - 99ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7030 - val_loss: 0.6612 - val_auc: 0.6807 - 8s/epoch - 99ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7040 - val_loss: 0.6639 - val_auc: 0.6845 - 8s/epoch - 100ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7058 - val_loss: 0.6611 - val_auc: 0.6826 - 8s/epoch - 99ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0432 - auc: 0.7097 - val_loss: 0.6607 - val_auc: 0.6825 - 8s/epoch - 99ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0432 - auc: 0.7087 - val_loss: 0.6630 - val_auc: 0.6844 - 8s/epoch - 99ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 9s - loss: 0.0430 - auc: 0.7118 - val_loss: 0.6606 - val_auc: 0.6850 - 9s/epoch - 107ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7138 - val_loss: 0.6627 - val_auc: 0.6824 - 8s/epoch - 99ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7166 - val_loss: 0.6589 - val_auc: 0.6794 - 8s/epoch - 99ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7146 - val_loss: 0.6616 - val_auc: 0.6826 - 8s/epoch - 99ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7171 - val_loss: 0.6636 - val_auc: 0.6788 - 8s/epoch - 99ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0425 - auc: 0.7206 - val_loss: 0.6592 - val_auc: 0.6819 - 8s/epoch - 99ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7211 - val_loss: 0.6601 - val_auc: 0.6803 - 8s/epoch - 98ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7254 - val_loss: 0.6579 - val_auc: 0.6764 - 8s/epoch - 100ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7231 - val_loss: 0.6616 - val_auc: 0.6734 - 8s/epoch - 100ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7226 - val_loss: 0.6627 - val_auc: 0.6736 - 8s/epoch - 99ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0418 - auc: 0.7307 - val_loss: 0.6596 - val_auc: 0.6725 - 8s/epoch - 99ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0418 - auc: 0.7298 - val_loss: 0.6629 - val_auc: 0.6665 - 8s/epoch - 100ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7371 - val_loss: 0.6577 - val_auc: 0.6682 - 8s/epoch - 100ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0415 - auc: 0.7362 - val_loss: 0.6598 - val_auc: 0.6690 - 8s/epoch - 101ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7384 - val_loss: 0.6608 - val_auc: 0.6639 - 8s/epoch - 99ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0411 - auc: 0.7402 - val_loss: 0.6531 - val_auc: 0.6611 - 8s/epoch - 99ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0411 - auc: 0.7390 - val_loss: 0.6586 - val_auc: 0.6608 - 8s/epoch - 99ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0408 - auc: 0.7473 - val_loss: 0.6590 - val_auc: 0.6591 - 8s/epoch - 99ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7471 - val_loss: 0.6563 - val_auc: 0.6601 - 8s/epoch - 99ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7475 - val_loss: 0.6580 - val_auc: 0.6612 - 8s/epoch - 98ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0405 - auc: 0.7518 - val_loss: 0.6565 - val_auc: 0.6594 - 8s/epoch - 98ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7538 - val_loss: 0.6593 - val_auc: 0.6585 - 8s/epoch - 99ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7541 - val_loss: 0.6664 - val_auc: 0.6550 - 8s/epoch - 100ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7527 - val_loss: 0.6639 - val_auc: 0.6545 - 8s/epoch - 99ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7572 - val_loss: 0.6611 - val_auc: 0.6521 - 8s/epoch - 99ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7633 - val_loss: 0.6606 - val_auc: 0.6539 - 8s/epoch - 99ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0398 - auc: 0.7618 - val_loss: 0.6611 - val_auc: 0.6589 - 8s/epoch - 99ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7628 - val_loss: 0.6657 - val_auc: 0.6545 - 8s/epoch - 99ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7592 - val_loss: 0.6644 - val_auc: 0.6550 - 8s/epoch - 99ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7649 - val_loss: 0.6642 - val_auc: 0.6528 - 8s/epoch - 99ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7661 - val_loss: 0.6594 - val_auc: 0.6566 - 8s/epoch - 99ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0392 - auc: 0.7686 - val_loss: 0.6611 - val_auc: 0.6515 - 8s/epoch - 99ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7726 - val_loss: 0.6630 - val_auc: 0.6512 - 8s/epoch - 99ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7723 - val_loss: 0.6692 - val_auc: 0.6483 - 8s/epoch - 100ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7745 - val_loss: 0.6627 - val_auc: 0.6471 - 8s/epoch - 98ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7731 - val_loss: 0.6699 - val_auc: 0.6460 - 8s/epoch - 98ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7719 - val_loss: 0.6670 - val_auc: 0.6524 - 8s/epoch - 103ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7763 - val_loss: 0.6606 - val_auc: 0.6602 - 8s/epoch - 99ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0383 - auc: 0.7797 - val_loss: 0.6595 - val_auc: 0.6490 - 8s/epoch - 99ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0383 - auc: 0.7782 - val_loss: 0.6670 - val_auc: 0.6455 - 8s/epoch - 98ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7784 - val_loss: 0.6694 - val_auc: 0.6435 - 8s/epoch - 98ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7834 - val_loss: 0.6634 - val_auc: 0.6464 - 8s/epoch - 98ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7824 - val_loss: 0.6687 - val_auc: 0.6420 - 8s/epoch - 97ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0377 - auc: 0.7874 - val_loss: 0.6696 - val_auc: 0.6373 - 8s/epoch - 98ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0377 - auc: 0.7892 - val_loss: 0.6687 - val_auc: 0.6369 - 8s/epoch - 99ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0375 - auc: 0.7918 - val_loss: 0.6693 - val_auc: 0.6334 - 8s/epoch - 98ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0377 - auc: 0.7913 - val_loss: 0.6560 - val_auc: 0.6443 - 8s/epoch - 98ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7960 - val_loss: 0.6676 - val_auc: 0.6361 - 8s/epoch - 98ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7925 - val_loss: 0.6747 - val_auc: 0.6326 - 8s/epoch - 98ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7915 - val_loss: 0.6748 - val_auc: 0.6297 - 8s/epoch - 98ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0369 - auc: 0.7998 - val_loss: 0.6713 - val_auc: 0.6293 - 8s/epoch - 98ms/step\n",
            "Epoch 105/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.8008 - val_loss: 0.6682 - val_auc: 0.6261 - 8s/epoch - 99ms/step\n",
            "Epoch 106/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.7979 - val_loss: 0.6739 - val_auc: 0.6289 - 8s/epoch - 100ms/step\n",
            "Epoch 107/500\n",
            "81/81 - 8s - loss: 0.0367 - auc: 0.8003 - val_loss: 0.6746 - val_auc: 0.6255 - 8s/epoch - 98ms/step\n",
            "Epoch 108/500\n",
            "81/81 - 8s - loss: 0.0363 - auc: 0.8058 - val_loss: 0.6764 - val_auc: 0.6224 - 8s/epoch - 99ms/step\n",
            "Epoch 109/500\n",
            "81/81 - 8s - loss: 0.0363 - auc: 0.8071 - val_loss: 0.6788 - val_auc: 0.6201 - 8s/epoch - 99ms/step\n",
            "Epoch 110/500\n",
            "81/81 - 8s - loss: 0.0365 - auc: 0.8034 - val_loss: 0.6719 - val_auc: 0.6251 - 8s/epoch - 98ms/step\n",
            "Epoch 111/500\n",
            "81/81 - 8s - loss: 0.0361 - auc: 0.8074 - val_loss: 0.6712 - val_auc: 0.6231 - 8s/epoch - 97ms/step\n",
            "Epoch 112/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8068 - val_loss: 0.6814 - val_auc: 0.6212 - 8s/epoch - 97ms/step\n",
            "Epoch 113/500\n",
            "81/81 - 8s - loss: 0.0357 - auc: 0.8142 - val_loss: 0.6709 - val_auc: 0.6193 - 8s/epoch - 99ms/step\n",
            "Epoch 114/500\n",
            "81/81 - 8s - loss: 0.0356 - auc: 0.8161 - val_loss: 0.6708 - val_auc: 0.6202 - 8s/epoch - 99ms/step\n",
            "Epoch 115/500\n",
            "81/81 - 8s - loss: 0.0357 - auc: 0.8110 - val_loss: 0.6729 - val_auc: 0.6168 - 8s/epoch - 100ms/step\n",
            "Epoch 116/500\n",
            "81/81 - 8s - loss: 0.0354 - auc: 0.8172 - val_loss: 0.6730 - val_auc: 0.6190 - 8s/epoch - 101ms/step\n",
            "Epoch 117/500\n",
            "81/81 - 8s - loss: 0.0353 - auc: 0.8193 - val_loss: 0.6767 - val_auc: 0.6142 - 8s/epoch - 99ms/step\n",
            "Epoch 118/500\n",
            "81/81 - 8s - loss: 0.0352 - auc: 0.8203 - val_loss: 0.6762 - val_auc: 0.6120 - 8s/epoch - 99ms/step\n",
            "Epoch 119/500\n",
            "81/81 - 8s - loss: 0.0348 - auc: 0.8251 - val_loss: 0.6785 - val_auc: 0.6139 - 8s/epoch - 99ms/step\n",
            "Epoch 120/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8247 - val_loss: 0.6780 - val_auc: 0.6143 - 8s/epoch - 100ms/step\n",
            "Epoch 121/500\n",
            "81/81 - 8s - loss: 0.0345 - auc: 0.8298 - val_loss: 0.6677 - val_auc: 0.6148 - 8s/epoch - 99ms/step\n",
            "Epoch 122/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8264 - val_loss: 0.6815 - val_auc: 0.6136 - 8s/epoch - 99ms/step\n",
            "Epoch 123/500\n",
            "81/81 - 8s - loss: 0.0344 - auc: 0.8299 - val_loss: 0.6622 - val_auc: 0.6125 - 8s/epoch - 99ms/step\n",
            "Epoch 124/500\n",
            "81/81 - 8s - loss: 0.0343 - auc: 0.8333 - val_loss: 0.6753 - val_auc: 0.6125 - 8s/epoch - 98ms/step\n",
            "Epoch 125/500\n",
            "81/81 - 8s - loss: 0.0341 - auc: 0.8370 - val_loss: 0.6797 - val_auc: 0.6111 - 8s/epoch - 98ms/step\n",
            "Epoch 126/500\n",
            "81/81 - 9s - loss: 0.0340 - auc: 0.8334 - val_loss: 0.6766 - val_auc: 0.6128 - 9s/epoch - 106ms/step\n",
            "Epoch 127/500\n",
            "81/81 - 8s - loss: 0.0338 - auc: 0.8351 - val_loss: 0.6869 - val_auc: 0.6126 - 8s/epoch - 99ms/step\n",
            "Epoch 128/500\n",
            "81/81 - 8s - loss: 0.0335 - auc: 0.8420 - val_loss: 0.6859 - val_auc: 0.6102 - 8s/epoch - 100ms/step\n",
            "Epoch 129/500\n",
            "81/81 - 8s - loss: 0.0335 - auc: 0.8405 - val_loss: 0.6785 - val_auc: 0.6063 - 8s/epoch - 98ms/step\n",
            "Epoch 130/500\n",
            "81/81 - 8s - loss: 0.0336 - auc: 0.8367 - val_loss: 0.6822 - val_auc: 0.6043 - 8s/epoch - 98ms/step\n",
            "Epoch 131/500\n",
            "81/81 - 8s - loss: 0.0333 - auc: 0.8431 - val_loss: 0.6844 - val_auc: 0.6047 - 8s/epoch - 99ms/step\n",
            "Epoch 132/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8465 - val_loss: 0.6963 - val_auc: 0.6008 - 8s/epoch - 99ms/step\n",
            "Epoch 133/500\n",
            "81/81 - 8s - loss: 0.0328 - auc: 0.8488 - val_loss: 0.6815 - val_auc: 0.6028 - 8s/epoch - 98ms/step\n",
            "Epoch 134/500\n",
            "81/81 - 8s - loss: 0.0326 - auc: 0.8504 - val_loss: 0.6873 - val_auc: 0.6047 - 8s/epoch - 98ms/step\n",
            "Epoch 135/500\n",
            "81/81 - 8s - loss: 0.0327 - auc: 0.8482 - val_loss: 0.6691 - val_auc: 0.6084 - 8s/epoch - 98ms/step\n",
            "Epoch 136/500\n",
            "81/81 - 8s - loss: 0.0322 - auc: 0.8512 - val_loss: 0.6872 - val_auc: 0.6060 - 8s/epoch - 98ms/step\n",
            "Epoch 137/500\n",
            "81/81 - 8s - loss: 0.0322 - auc: 0.8563 - val_loss: 0.6809 - val_auc: 0.6039 - 8s/epoch - 99ms/step\n",
            "Epoch 138/500\n",
            "81/81 - 8s - loss: 0.0320 - auc: 0.8547 - val_loss: 0.6772 - val_auc: 0.6049 - 8s/epoch - 98ms/step\n",
            "Epoch 139/500\n",
            "81/81 - 8s - loss: 0.0321 - auc: 0.8540 - val_loss: 0.6923 - val_auc: 0.6019 - 8s/epoch - 98ms/step\n",
            "Epoch 140/500\n",
            "81/81 - 8s - loss: 0.0320 - auc: 0.8540 - val_loss: 0.6676 - val_auc: 0.6062 - 8s/epoch - 99ms/step\n",
            "Epoch 141/500\n",
            "81/81 - 8s - loss: 0.0317 - auc: 0.8572 - val_loss: 0.7043 - val_auc: 0.6034 - 8s/epoch - 100ms/step\n",
            "Epoch 142/500\n",
            "81/81 - 8s - loss: 0.0314 - auc: 0.8618 - val_loss: 0.6962 - val_auc: 0.5994 - 8s/epoch - 99ms/step\n",
            "Epoch 143/500\n",
            "81/81 - 8s - loss: 0.0313 - auc: 0.8648 - val_loss: 0.6746 - val_auc: 0.6057 - 8s/epoch - 99ms/step\n",
            "Epoch 144/500\n",
            "81/81 - 8s - loss: 0.0313 - auc: 0.8616 - val_loss: 0.6744 - val_auc: 0.6062 - 8s/epoch - 102ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 36ms/step - loss: 0.6225 - auc: 0.6615\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 38ms/step - loss: 0.6606 - auc: 0.6850\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 6\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 9s - loss: 0.0496 - auc: 0.5174 - val_loss: 0.6858 - val_auc: 0.6108 - 9s/epoch - 115ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0491 - auc: 0.6377 - val_loss: 0.6708 - val_auc: 0.6041 - 8s/epoch - 99ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0488 - auc: 0.6487 - val_loss: 0.6597 - val_auc: 0.6044 - 8s/epoch - 98ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0484 - auc: 0.6561 - val_loss: 0.6517 - val_auc: 0.6084 - 8s/epoch - 98ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0482 - auc: 0.6524 - val_loss: 0.6455 - val_auc: 0.6114 - 8s/epoch - 98ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0479 - auc: 0.6551 - val_loss: 0.6409 - val_auc: 0.6103 - 8s/epoch - 98ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6546 - val_loss: 0.6373 - val_auc: 0.6092 - 8s/epoch - 99ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 9s - loss: 0.0474 - auc: 0.6554 - val_loss: 0.6363 - val_auc: 0.6096 - 9s/epoch - 105ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0472 - auc: 0.6547 - val_loss: 0.6352 - val_auc: 0.6089 - 8s/epoch - 98ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6572 - val_loss: 0.6364 - val_auc: 0.6074 - 8s/epoch - 99ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0469 - auc: 0.6574 - val_loss: 0.6374 - val_auc: 0.6109 - 8s/epoch - 99ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6600 - val_loss: 0.6374 - val_auc: 0.6123 - 8s/epoch - 99ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0466 - auc: 0.6601 - val_loss: 0.6381 - val_auc: 0.6109 - 8s/epoch - 99ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0466 - auc: 0.6575 - val_loss: 0.6377 - val_auc: 0.6121 - 8s/epoch - 98ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6608 - val_loss: 0.6390 - val_auc: 0.6137 - 8s/epoch - 98ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6622 - val_loss: 0.6367 - val_auc: 0.6140 - 8s/epoch - 99ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6629 - val_loss: 0.6370 - val_auc: 0.6135 - 8s/epoch - 98ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6654 - val_loss: 0.6358 - val_auc: 0.6162 - 8s/epoch - 100ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6654 - val_loss: 0.6353 - val_auc: 0.6153 - 8s/epoch - 100ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6659 - val_loss: 0.6347 - val_auc: 0.6139 - 8s/epoch - 98ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6659 - val_loss: 0.6341 - val_auc: 0.6159 - 8s/epoch - 99ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6681 - val_loss: 0.6332 - val_auc: 0.6155 - 8s/epoch - 98ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0457 - auc: 0.6694 - val_loss: 0.6329 - val_auc: 0.6160 - 8s/epoch - 98ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0457 - auc: 0.6689 - val_loss: 0.6321 - val_auc: 0.6155 - 8s/epoch - 99ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6708 - val_loss: 0.6302 - val_auc: 0.6177 - 8s/epoch - 100ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6728 - val_loss: 0.6297 - val_auc: 0.6155 - 8s/epoch - 98ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6750 - val_loss: 0.6292 - val_auc: 0.6166 - 8s/epoch - 99ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6767 - val_loss: 0.6297 - val_auc: 0.6159 - 8s/epoch - 98ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6763 - val_loss: 0.6278 - val_auc: 0.6145 - 8s/epoch - 99ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6789 - val_loss: 0.6278 - val_auc: 0.6150 - 8s/epoch - 98ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6791 - val_loss: 0.6252 - val_auc: 0.6152 - 8s/epoch - 98ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6799 - val_loss: 0.6257 - val_auc: 0.6140 - 8s/epoch - 99ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0449 - auc: 0.6833 - val_loss: 0.6248 - val_auc: 0.6126 - 8s/epoch - 100ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6883 - val_loss: 0.6220 - val_auc: 0.6136 - 8s/epoch - 98ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0446 - auc: 0.6876 - val_loss: 0.6223 - val_auc: 0.6145 - 8s/epoch - 99ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6908 - val_loss: 0.6202 - val_auc: 0.6115 - 8s/epoch - 100ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6890 - val_loss: 0.6192 - val_auc: 0.6128 - 8s/epoch - 100ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6934 - val_loss: 0.6179 - val_auc: 0.6115 - 8s/epoch - 98ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6945 - val_loss: 0.6164 - val_auc: 0.6102 - 8s/epoch - 97ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0441 - auc: 0.6964 - val_loss: 0.6144 - val_auc: 0.6096 - 8s/epoch - 97ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.6993 - val_loss: 0.6127 - val_auc: 0.6094 - 8s/epoch - 98ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.6998 - val_loss: 0.6133 - val_auc: 0.6087 - 8s/epoch - 97ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7035 - val_loss: 0.6121 - val_auc: 0.6092 - 8s/epoch - 101ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7030 - val_loss: 0.6116 - val_auc: 0.6098 - 8s/epoch - 100ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7078 - val_loss: 0.6101 - val_auc: 0.6089 - 8s/epoch - 99ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7058 - val_loss: 0.6111 - val_auc: 0.6095 - 8s/epoch - 97ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7069 - val_loss: 0.6079 - val_auc: 0.6109 - 8s/epoch - 98ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7097 - val_loss: 0.6065 - val_auc: 0.6116 - 8s/epoch - 97ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7105 - val_loss: 0.6053 - val_auc: 0.6116 - 8s/epoch - 99ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0432 - auc: 0.7128 - val_loss: 0.6052 - val_auc: 0.6130 - 8s/epoch - 100ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0432 - auc: 0.7119 - val_loss: 0.6050 - val_auc: 0.6128 - 8s/epoch - 99ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0429 - auc: 0.7165 - val_loss: 0.6010 - val_auc: 0.6123 - 8s/epoch - 99ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7216 - val_loss: 0.6008 - val_auc: 0.6122 - 8s/epoch - 98ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7216 - val_loss: 0.5991 - val_auc: 0.6133 - 8s/epoch - 98ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7218 - val_loss: 0.5999 - val_auc: 0.6159 - 8s/epoch - 98ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7215 - val_loss: 0.6000 - val_auc: 0.6159 - 8s/epoch - 98ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0425 - auc: 0.7231 - val_loss: 0.5984 - val_auc: 0.6149 - 8s/epoch - 97ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7272 - val_loss: 0.5949 - val_auc: 0.6164 - 8s/epoch - 98ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7290 - val_loss: 0.5955 - val_auc: 0.6152 - 8s/epoch - 98ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0420 - auc: 0.7317 - val_loss: 0.5940 - val_auc: 0.6159 - 8s/epoch - 98ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0420 - auc: 0.7321 - val_loss: 0.5956 - val_auc: 0.6174 - 8s/epoch - 99ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0418 - auc: 0.7348 - val_loss: 0.5925 - val_auc: 0.6178 - 8s/epoch - 100ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0417 - auc: 0.7372 - val_loss: 0.5900 - val_auc: 0.6193 - 8s/epoch - 99ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0415 - auc: 0.7397 - val_loss: 0.5879 - val_auc: 0.6202 - 8s/epoch - 100ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7435 - val_loss: 0.5905 - val_auc: 0.6184 - 8s/epoch - 98ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0412 - auc: 0.7440 - val_loss: 0.5893 - val_auc: 0.6198 - 8s/epoch - 98ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0411 - auc: 0.7489 - val_loss: 0.5842 - val_auc: 0.6202 - 8s/epoch - 98ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0409 - auc: 0.7506 - val_loss: 0.5861 - val_auc: 0.6207 - 8s/epoch - 98ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7525 - val_loss: 0.5843 - val_auc: 0.6210 - 8s/epoch - 99ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7501 - val_loss: 0.5869 - val_auc: 0.6219 - 8s/epoch - 97ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7524 - val_loss: 0.5887 - val_auc: 0.6211 - 8s/epoch - 97ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7564 - val_loss: 0.5827 - val_auc: 0.6234 - 8s/epoch - 98ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7555 - val_loss: 0.5874 - val_auc: 0.6215 - 8s/epoch - 97ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7575 - val_loss: 0.5883 - val_auc: 0.6229 - 8s/epoch - 99ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0402 - auc: 0.7586 - val_loss: 0.5892 - val_auc: 0.6217 - 8s/epoch - 100ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7633 - val_loss: 0.5832 - val_auc: 0.6233 - 8s/epoch - 99ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7666 - val_loss: 0.5847 - val_auc: 0.6251 - 8s/epoch - 99ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7680 - val_loss: 0.5832 - val_auc: 0.6249 - 8s/epoch - 105ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7687 - val_loss: 0.5881 - val_auc: 0.6253 - 8s/epoch - 99ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7703 - val_loss: 0.5838 - val_auc: 0.6273 - 8s/epoch - 99ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7674 - val_loss: 0.5872 - val_auc: 0.6275 - 8s/epoch - 99ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7728 - val_loss: 0.5855 - val_auc: 0.6281 - 8s/epoch - 98ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7749 - val_loss: 0.5840 - val_auc: 0.6295 - 8s/epoch - 100ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7722 - val_loss: 0.5851 - val_auc: 0.6296 - 8s/epoch - 99ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7788 - val_loss: 0.5842 - val_auc: 0.6313 - 8s/epoch - 99ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7800 - val_loss: 0.5826 - val_auc: 0.6322 - 8s/epoch - 100ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0385 - auc: 0.7817 - val_loss: 0.5890 - val_auc: 0.6316 - 8s/epoch - 98ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0383 - auc: 0.7830 - val_loss: 0.5845 - val_auc: 0.6350 - 8s/epoch - 98ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0384 - auc: 0.7804 - val_loss: 0.5867 - val_auc: 0.6358 - 8s/epoch - 98ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7837 - val_loss: 0.5863 - val_auc: 0.6362 - 8s/epoch - 98ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7834 - val_loss: 0.5820 - val_auc: 0.6369 - 8s/epoch - 99ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0381 - auc: 0.7840 - val_loss: 0.5849 - val_auc: 0.6356 - 8s/epoch - 98ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7937 - val_loss: 0.5784 - val_auc: 0.6378 - 8s/epoch - 100ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0378 - auc: 0.7904 - val_loss: 0.5833 - val_auc: 0.6383 - 8s/epoch - 98ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7917 - val_loss: 0.5840 - val_auc: 0.6363 - 8s/epoch - 98ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0374 - auc: 0.7923 - val_loss: 0.5805 - val_auc: 0.6396 - 8s/epoch - 98ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0373 - auc: 0.7944 - val_loss: 0.5832 - val_auc: 0.6393 - 8s/epoch - 98ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7955 - val_loss: 0.5805 - val_auc: 0.6406 - 8s/epoch - 99ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7963 - val_loss: 0.5842 - val_auc: 0.6413 - 8s/epoch - 99ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7983 - val_loss: 0.5771 - val_auc: 0.6403 - 8s/epoch - 98ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0370 - auc: 0.7985 - val_loss: 0.5824 - val_auc: 0.6424 - 8s/epoch - 98ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0365 - auc: 0.8021 - val_loss: 0.5797 - val_auc: 0.6454 - 8s/epoch - 99ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0366 - auc: 0.8029 - val_loss: 0.5804 - val_auc: 0.6454 - 8s/epoch - 98ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0365 - auc: 0.8049 - val_loss: 0.5791 - val_auc: 0.6451 - 8s/epoch - 98ms/step\n",
            "Epoch 105/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8095 - val_loss: 0.5726 - val_auc: 0.6480 - 8s/epoch - 98ms/step\n",
            "Epoch 106/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8087 - val_loss: 0.5763 - val_auc: 0.6495 - 8s/epoch - 97ms/step\n",
            "Epoch 107/500\n",
            "81/81 - 8s - loss: 0.0359 - auc: 0.8079 - val_loss: 0.5721 - val_auc: 0.6500 - 8s/epoch - 98ms/step\n",
            "Epoch 108/500\n",
            "81/81 - 8s - loss: 0.0359 - auc: 0.8096 - val_loss: 0.5791 - val_auc: 0.6495 - 8s/epoch - 97ms/step\n",
            "Epoch 109/500\n",
            "81/81 - 8s - loss: 0.0358 - auc: 0.8120 - val_loss: 0.5738 - val_auc: 0.6521 - 8s/epoch - 99ms/step\n",
            "Epoch 110/500\n",
            "81/81 - 8s - loss: 0.0356 - auc: 0.8112 - val_loss: 0.5753 - val_auc: 0.6522 - 8s/epoch - 98ms/step\n",
            "Epoch 111/500\n",
            "81/81 - 8s - loss: 0.0357 - auc: 0.8131 - val_loss: 0.5705 - val_auc: 0.6548 - 8s/epoch - 98ms/step\n",
            "Epoch 112/500\n",
            "81/81 - 8s - loss: 0.0353 - auc: 0.8177 - val_loss: 0.5703 - val_auc: 0.6563 - 8s/epoch - 98ms/step\n",
            "Epoch 113/500\n",
            "81/81 - 8s - loss: 0.0350 - auc: 0.8200 - val_loss: 0.5665 - val_auc: 0.6572 - 8s/epoch - 105ms/step\n",
            "Epoch 114/500\n",
            "81/81 - 8s - loss: 0.0351 - auc: 0.8205 - val_loss: 0.5694 - val_auc: 0.6558 - 8s/epoch - 99ms/step\n",
            "Epoch 115/500\n",
            "81/81 - 8s - loss: 0.0348 - auc: 0.8240 - val_loss: 0.5656 - val_auc: 0.6599 - 8s/epoch - 98ms/step\n",
            "Epoch 116/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8240 - val_loss: 0.5665 - val_auc: 0.6582 - 8s/epoch - 98ms/step\n",
            "Epoch 117/500\n",
            "81/81 - 8s - loss: 0.0348 - auc: 0.8240 - val_loss: 0.5627 - val_auc: 0.6553 - 8s/epoch - 98ms/step\n",
            "Epoch 118/500\n",
            "81/81 - 8s - loss: 0.0342 - auc: 0.8303 - val_loss: 0.5610 - val_auc: 0.6568 - 8s/epoch - 98ms/step\n",
            "Epoch 119/500\n",
            "81/81 - 8s - loss: 0.0343 - auc: 0.8270 - val_loss: 0.5652 - val_auc: 0.6573 - 8s/epoch - 98ms/step\n",
            "Epoch 120/500\n",
            "81/81 - 8s - loss: 0.0342 - auc: 0.8300 - val_loss: 0.5677 - val_auc: 0.6597 - 8s/epoch - 98ms/step\n",
            "Epoch 121/500\n",
            "81/81 - 8s - loss: 0.0339 - auc: 0.8344 - val_loss: 0.5603 - val_auc: 0.6605 - 8s/epoch - 98ms/step\n",
            "Epoch 122/500\n",
            "81/81 - 8s - loss: 0.0338 - auc: 0.8329 - val_loss: 0.5524 - val_auc: 0.6627 - 8s/epoch - 98ms/step\n",
            "Epoch 123/500\n",
            "81/81 - 8s - loss: 0.0337 - auc: 0.8386 - val_loss: 0.5542 - val_auc: 0.6599 - 8s/epoch - 102ms/step\n",
            "Epoch 124/500\n",
            "81/81 - 8s - loss: 0.0334 - auc: 0.8394 - val_loss: 0.5574 - val_auc: 0.6625 - 8s/epoch - 98ms/step\n",
            "Epoch 125/500\n",
            "81/81 - 8s - loss: 0.0338 - auc: 0.8346 - val_loss: 0.5488 - val_auc: 0.6624 - 8s/epoch - 97ms/step\n",
            "Epoch 126/500\n",
            "81/81 - 8s - loss: 0.0334 - auc: 0.8364 - val_loss: 0.5637 - val_auc: 0.6615 - 8s/epoch - 98ms/step\n",
            "Epoch 127/500\n",
            "81/81 - 8s - loss: 0.0332 - auc: 0.8418 - val_loss: 0.5472 - val_auc: 0.6645 - 8s/epoch - 99ms/step\n",
            "Epoch 128/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8412 - val_loss: 0.5525 - val_auc: 0.6647 - 8s/epoch - 99ms/step\n",
            "Epoch 129/500\n",
            "81/81 - 8s - loss: 0.0330 - auc: 0.8421 - val_loss: 0.5393 - val_auc: 0.6648 - 8s/epoch - 98ms/step\n",
            "Epoch 130/500\n",
            "81/81 - 8s - loss: 0.0329 - auc: 0.8426 - val_loss: 0.5523 - val_auc: 0.6646 - 8s/epoch - 97ms/step\n",
            "Epoch 131/500\n",
            "81/81 - 8s - loss: 0.0327 - auc: 0.8467 - val_loss: 0.5420 - val_auc: 0.6639 - 8s/epoch - 97ms/step\n",
            "Epoch 132/500\n",
            "81/81 - 8s - loss: 0.0326 - auc: 0.8472 - val_loss: 0.5429 - val_auc: 0.6646 - 8s/epoch - 97ms/step\n",
            "Epoch 133/500\n",
            "81/81 - 8s - loss: 0.0325 - auc: 0.8473 - val_loss: 0.5433 - val_auc: 0.6659 - 8s/epoch - 99ms/step\n",
            "Epoch 134/500\n",
            "81/81 - 8s - loss: 0.0321 - auc: 0.8538 - val_loss: 0.5357 - val_auc: 0.6673 - 8s/epoch - 98ms/step\n",
            "Epoch 135/500\n",
            "81/81 - 8s - loss: 0.0319 - auc: 0.8546 - val_loss: 0.5360 - val_auc: 0.6662 - 8s/epoch - 98ms/step\n",
            "Epoch 136/500\n",
            "81/81 - 8s - loss: 0.0318 - auc: 0.8561 - val_loss: 0.5349 - val_auc: 0.6660 - 8s/epoch - 98ms/step\n",
            "Epoch 137/500\n",
            "81/81 - 8s - loss: 0.0320 - auc: 0.8531 - val_loss: 0.5270 - val_auc: 0.6672 - 8s/epoch - 99ms/step\n",
            "Epoch 138/500\n",
            "81/81 - 8s - loss: 0.0316 - auc: 0.8594 - val_loss: 0.5257 - val_auc: 0.6645 - 8s/epoch - 97ms/step\n",
            "Epoch 139/500\n",
            "81/81 - 8s - loss: 0.0318 - auc: 0.8544 - val_loss: 0.5454 - val_auc: 0.6652 - 8s/epoch - 98ms/step\n",
            "Epoch 140/500\n",
            "81/81 - 8s - loss: 0.0312 - auc: 0.8612 - val_loss: 0.5245 - val_auc: 0.6652 - 8s/epoch - 99ms/step\n",
            "Epoch 141/500\n",
            "81/81 - 8s - loss: 0.0317 - auc: 0.8586 - val_loss: 0.5025 - val_auc: 0.6608 - 8s/epoch - 98ms/step\n",
            "Epoch 142/500\n",
            "81/81 - 8s - loss: 0.0315 - auc: 0.8567 - val_loss: 0.5370 - val_auc: 0.6612 - 8s/epoch - 98ms/step\n",
            "Epoch 143/500\n",
            "81/81 - 8s - loss: 0.0312 - auc: 0.8595 - val_loss: 0.5420 - val_auc: 0.6649 - 8s/epoch - 99ms/step\n",
            "Epoch 144/500\n",
            "81/81 - 8s - loss: 0.0309 - auc: 0.8627 - val_loss: 0.5444 - val_auc: 0.6677 - 8s/epoch - 100ms/step\n",
            "Epoch 145/500\n",
            "81/81 - 8s - loss: 0.0309 - auc: 0.8648 - val_loss: 0.5369 - val_auc: 0.6598 - 8s/epoch - 99ms/step\n",
            "Epoch 146/500\n",
            "81/81 - 8s - loss: 0.0307 - auc: 0.8652 - val_loss: 0.5321 - val_auc: 0.6635 - 8s/epoch - 99ms/step\n",
            "Epoch 147/500\n",
            "81/81 - 8s - loss: 0.0306 - auc: 0.8658 - val_loss: 0.5359 - val_auc: 0.6630 - 8s/epoch - 99ms/step\n",
            "Epoch 148/500\n",
            "81/81 - 8s - loss: 0.0305 - auc: 0.8684 - val_loss: 0.5391 - val_auc: 0.6614 - 8s/epoch - 104ms/step\n",
            "Epoch 149/500\n",
            "81/81 - 8s - loss: 0.0302 - auc: 0.8711 - val_loss: 0.5376 - val_auc: 0.6614 - 8s/epoch - 100ms/step\n",
            "Epoch 150/500\n",
            "81/81 - 8s - loss: 0.0304 - auc: 0.8686 - val_loss: 0.5178 - val_auc: 0.6641 - 8s/epoch - 100ms/step\n",
            "Epoch 151/500\n",
            "81/81 - 8s - loss: 0.0299 - auc: 0.8752 - val_loss: 0.5249 - val_auc: 0.6636 - 8s/epoch - 101ms/step\n",
            "Epoch 152/500\n",
            "81/81 - 8s - loss: 0.0299 - auc: 0.8731 - val_loss: 0.5359 - val_auc: 0.6636 - 8s/epoch - 102ms/step\n",
            "Epoch 153/500\n",
            "81/81 - 8s - loss: 0.0298 - auc: 0.8758 - val_loss: 0.5379 - val_auc: 0.6605 - 8s/epoch - 100ms/step\n",
            "Epoch 154/500\n",
            "81/81 - 8s - loss: 0.0297 - auc: 0.8748 - val_loss: 0.5251 - val_auc: 0.6624 - 8s/epoch - 100ms/step\n",
            "Epoch 155/500\n",
            "81/81 - 8s - loss: 0.0295 - auc: 0.8776 - val_loss: 0.5230 - val_auc: 0.6664 - 8s/epoch - 99ms/step\n",
            "Epoch 156/500\n",
            "81/81 - 8s - loss: 0.0292 - auc: 0.8806 - val_loss: 0.5200 - val_auc: 0.6613 - 8s/epoch - 99ms/step\n",
            "Epoch 157/500\n",
            "81/81 - 8s - loss: 0.0293 - auc: 0.8779 - val_loss: 0.5232 - val_auc: 0.6590 - 8s/epoch - 99ms/step\n",
            "Epoch 158/500\n",
            "81/81 - 8s - loss: 0.0290 - auc: 0.8828 - val_loss: 0.5201 - val_auc: 0.6667 - 8s/epoch - 99ms/step\n",
            "Epoch 159/500\n",
            "81/81 - 8s - loss: 0.0289 - auc: 0.8836 - val_loss: 0.5287 - val_auc: 0.6653 - 8s/epoch - 98ms/step\n",
            "Epoch 160/500\n",
            "81/81 - 8s - loss: 0.0288 - auc: 0.8808 - val_loss: 0.5480 - val_auc: 0.6671 - 8s/epoch - 98ms/step\n",
            "Epoch 161/500\n",
            "81/81 - 8s - loss: 0.0287 - auc: 0.8837 - val_loss: 0.5246 - val_auc: 0.6619 - 8s/epoch - 99ms/step\n",
            "Epoch 162/500\n",
            "81/81 - 8s - loss: 0.0289 - auc: 0.8825 - val_loss: 0.5052 - val_auc: 0.6594 - 8s/epoch - 98ms/step\n",
            "Epoch 163/500\n",
            "81/81 - 8s - loss: 0.0287 - auc: 0.8846 - val_loss: 0.5073 - val_auc: 0.6624 - 8s/epoch - 99ms/step\n",
            "Epoch 164/500\n",
            "81/81 - 8s - loss: 0.0286 - auc: 0.8841 - val_loss: 0.5130 - val_auc: 0.6618 - 8s/epoch - 99ms/step\n",
            "Epoch 165/500\n",
            "81/81 - 8s - loss: 0.0282 - auc: 0.8907 - val_loss: 0.5184 - val_auc: 0.6683 - 8s/epoch - 98ms/step\n",
            "Epoch 166/500\n",
            "81/81 - 8s - loss: 0.0281 - auc: 0.8891 - val_loss: 0.5100 - val_auc: 0.6599 - 8s/epoch - 98ms/step\n",
            "Epoch 167/500\n",
            "81/81 - 8s - loss: 0.0284 - auc: 0.8874 - val_loss: 0.5249 - val_auc: 0.6668 - 8s/epoch - 97ms/step\n",
            "Epoch 168/500\n",
            "81/81 - 8s - loss: 0.0280 - auc: 0.8906 - val_loss: 0.5252 - val_auc: 0.6582 - 8s/epoch - 99ms/step\n",
            "Epoch 169/500\n",
            "81/81 - 8s - loss: 0.0280 - auc: 0.8892 - val_loss: 0.5201 - val_auc: 0.6685 - 8s/epoch - 99ms/step\n",
            "Epoch 170/500\n",
            "81/81 - 8s - loss: 0.0279 - auc: 0.8918 - val_loss: 0.5199 - val_auc: 0.6685 - 8s/epoch - 98ms/step\n",
            "Epoch 171/500\n",
            "81/81 - 8s - loss: 0.0278 - auc: 0.8909 - val_loss: 0.5113 - val_auc: 0.6615 - 8s/epoch - 99ms/step\n",
            "Epoch 172/500\n",
            "81/81 - 8s - loss: 0.0276 - auc: 0.8936 - val_loss: 0.5164 - val_auc: 0.6610 - 8s/epoch - 99ms/step\n",
            "Epoch 173/500\n",
            "81/81 - 8s - loss: 0.0277 - auc: 0.8943 - val_loss: 0.5025 - val_auc: 0.6673 - 8s/epoch - 98ms/step\n",
            "Epoch 174/500\n",
            "81/81 - 8s - loss: 0.0272 - auc: 0.8966 - val_loss: 0.5194 - val_auc: 0.6588 - 8s/epoch - 99ms/step\n",
            "Epoch 175/500\n",
            "81/81 - 8s - loss: 0.0271 - auc: 0.8971 - val_loss: 0.5172 - val_auc: 0.6611 - 8s/epoch - 99ms/step\n",
            "Epoch 176/500\n",
            "81/81 - 8s - loss: 0.0271 - auc: 0.8978 - val_loss: 0.5052 - val_auc: 0.6613 - 8s/epoch - 99ms/step\n",
            "Epoch 177/500\n",
            "81/81 - 8s - loss: 0.0271 - auc: 0.8971 - val_loss: 0.5193 - val_auc: 0.6610 - 8s/epoch - 99ms/step\n",
            "Epoch 178/500\n",
            "81/81 - 8s - loss: 0.0270 - auc: 0.8995 - val_loss: 0.5164 - val_auc: 0.6606 - 8s/epoch - 98ms/step\n",
            "Epoch 179/500\n",
            "81/81 - 8s - loss: 0.0267 - auc: 0.9007 - val_loss: 0.5145 - val_auc: 0.6680 - 8s/epoch - 98ms/step\n",
            "Epoch 180/500\n",
            "81/81 - 8s - loss: 0.0268 - auc: 0.9005 - val_loss: 0.5548 - val_auc: 0.6677 - 8s/epoch - 98ms/step\n",
            "Epoch 181/500\n",
            "81/81 - 8s - loss: 0.0268 - auc: 0.8990 - val_loss: 0.5062 - val_auc: 0.6648 - 8s/epoch - 98ms/step\n",
            "Epoch 182/500\n",
            "81/81 - 8s - loss: 0.0268 - auc: 0.9006 - val_loss: 0.5109 - val_auc: 0.6658 - 8s/epoch - 99ms/step\n",
            "Epoch 183/500\n",
            "81/81 - 8s - loss: 0.0266 - auc: 0.9004 - val_loss: 0.5112 - val_auc: 0.6605 - 8s/epoch - 98ms/step\n",
            "Epoch 184/500\n",
            "81/81 - 8s - loss: 0.0262 - auc: 0.9044 - val_loss: 0.5056 - val_auc: 0.6705 - 8s/epoch - 100ms/step\n",
            "Epoch 185/500\n",
            "81/81 - 9s - loss: 0.0261 - auc: 0.9063 - val_loss: 0.5194 - val_auc: 0.6608 - 9s/epoch - 106ms/step\n",
            "Epoch 186/500\n",
            "81/81 - 8s - loss: 0.0260 - auc: 0.9090 - val_loss: 0.5217 - val_auc: 0.6695 - 8s/epoch - 98ms/step\n",
            "Epoch 187/500\n",
            "81/81 - 8s - loss: 0.0259 - auc: 0.9085 - val_loss: 0.5021 - val_auc: 0.6658 - 8s/epoch - 99ms/step\n",
            "Epoch 188/500\n",
            "81/81 - 8s - loss: 0.0256 - auc: 0.9109 - val_loss: 0.5209 - val_auc: 0.6628 - 8s/epoch - 99ms/step\n",
            "Epoch 189/500\n",
            "81/81 - 8s - loss: 0.0257 - auc: 0.9089 - val_loss: 0.5053 - val_auc: 0.6641 - 8s/epoch - 99ms/step\n",
            "Epoch 190/500\n",
            "81/81 - 8s - loss: 0.0259 - auc: 0.9069 - val_loss: 0.5004 - val_auc: 0.6723 - 8s/epoch - 102ms/step\n",
            "Epoch 191/500\n",
            "81/81 - 8s - loss: 0.0264 - auc: 0.9030 - val_loss: 0.4877 - val_auc: 0.6694 - 8s/epoch - 98ms/step\n",
            "Epoch 192/500\n",
            "81/81 - 8s - loss: 0.0251 - auc: 0.9134 - val_loss: 0.5034 - val_auc: 0.6642 - 8s/epoch - 98ms/step\n",
            "Epoch 193/500\n",
            "81/81 - 8s - loss: 0.0254 - auc: 0.9112 - val_loss: 0.5370 - val_auc: 0.6676 - 8s/epoch - 97ms/step\n",
            "Epoch 194/500\n",
            "81/81 - 8s - loss: 0.0252 - auc: 0.9114 - val_loss: 0.4871 - val_auc: 0.6674 - 8s/epoch - 98ms/step\n",
            "Epoch 195/500\n",
            "81/81 - 8s - loss: 0.0250 - auc: 0.9151 - val_loss: 0.5119 - val_auc: 0.6722 - 8s/epoch - 98ms/step\n",
            "Epoch 196/500\n",
            "81/81 - 8s - loss: 0.0266 - auc: 0.9009 - val_loss: 0.5003 - val_auc: 0.6617 - 8s/epoch - 98ms/step\n",
            "Epoch 197/500\n",
            "81/81 - 8s - loss: 0.0247 - auc: 0.9185 - val_loss: 0.4890 - val_auc: 0.6651 - 8s/epoch - 99ms/step\n",
            "Epoch 198/500\n",
            "81/81 - 8s - loss: 0.0247 - auc: 0.9175 - val_loss: 0.4937 - val_auc: 0.6622 - 8s/epoch - 99ms/step\n",
            "Epoch 199/500\n",
            "81/81 - 8s - loss: 0.0250 - auc: 0.9143 - val_loss: 0.4988 - val_auc: 0.6688 - 8s/epoch - 99ms/step\n",
            "Epoch 200/500\n",
            "81/81 - 8s - loss: 0.0245 - auc: 0.9184 - val_loss: 0.5041 - val_auc: 0.6615 - 8s/epoch - 97ms/step\n",
            "Epoch 201/500\n",
            "81/81 - 8s - loss: 0.0247 - auc: 0.9158 - val_loss: 0.5257 - val_auc: 0.6683 - 8s/epoch - 98ms/step\n",
            "Epoch 202/500\n",
            "81/81 - 8s - loss: 0.0243 - auc: 0.9213 - val_loss: 0.4903 - val_auc: 0.6644 - 8s/epoch - 98ms/step\n",
            "Epoch 203/500\n",
            "81/81 - 8s - loss: 0.0244 - auc: 0.9194 - val_loss: 0.4974 - val_auc: 0.6601 - 8s/epoch - 98ms/step\n",
            "Epoch 204/500\n",
            "81/81 - 8s - loss: 0.0241 - auc: 0.9224 - val_loss: 0.4930 - val_auc: 0.6643 - 8s/epoch - 99ms/step\n",
            "Epoch 205/500\n",
            "81/81 - 8s - loss: 0.0240 - auc: 0.9218 - val_loss: 0.5001 - val_auc: 0.6643 - 8s/epoch - 98ms/step\n",
            "Epoch 206/500\n",
            "81/81 - 8s - loss: 0.0242 - auc: 0.9209 - val_loss: 0.4942 - val_auc: 0.6635 - 8s/epoch - 98ms/step\n",
            "Epoch 207/500\n",
            "81/81 - 8s - loss: 0.0238 - auc: 0.9229 - val_loss: 0.5025 - val_auc: 0.6661 - 8s/epoch - 99ms/step\n",
            "Epoch 208/500\n",
            "81/81 - 8s - loss: 0.0241 - auc: 0.9224 - val_loss: 0.4957 - val_auc: 0.6735 - 8s/epoch - 98ms/step\n",
            "Epoch 209/500\n",
            "81/81 - 8s - loss: 0.0239 - auc: 0.9243 - val_loss: 0.5064 - val_auc: 0.6743 - 8s/epoch - 99ms/step\n",
            "Epoch 210/500\n",
            "81/81 - 8s - loss: 0.0249 - auc: 0.9131 - val_loss: 0.5586 - val_auc: 0.6668 - 8s/epoch - 99ms/step\n",
            "Epoch 211/500\n",
            "81/81 - 8s - loss: 0.0238 - auc: 0.9211 - val_loss: 0.5046 - val_auc: 0.6657 - 8s/epoch - 99ms/step\n",
            "Epoch 212/500\n",
            "81/81 - 8s - loss: 0.0236 - auc: 0.9250 - val_loss: 0.5082 - val_auc: 0.6656 - 8s/epoch - 99ms/step\n",
            "Epoch 213/500\n",
            "81/81 - 8s - loss: 0.0236 - auc: 0.9252 - val_loss: 0.4983 - val_auc: 0.6558 - 8s/epoch - 99ms/step\n",
            "Epoch 214/500\n",
            "81/81 - 8s - loss: 0.0230 - auc: 0.9284 - val_loss: 0.4962 - val_auc: 0.6576 - 8s/epoch - 98ms/step\n",
            "Epoch 215/500\n",
            "81/81 - 8s - loss: 0.0232 - auc: 0.9275 - val_loss: 0.4929 - val_auc: 0.6573 - 8s/epoch - 98ms/step\n",
            "Epoch 216/500\n",
            "81/81 - 8s - loss: 0.0233 - auc: 0.9262 - val_loss: 0.5000 - val_auc: 0.6595 - 8s/epoch - 97ms/step\n",
            "Epoch 217/500\n",
            "81/81 - 8s - loss: 0.0232 - auc: 0.9278 - val_loss: 0.4831 - val_auc: 0.6558 - 8s/epoch - 99ms/step\n",
            "Epoch 218/500\n",
            "81/81 - 8s - loss: 0.0231 - auc: 0.9279 - val_loss: 0.4909 - val_auc: 0.6589 - 8s/epoch - 98ms/step\n",
            "Epoch 219/500\n",
            "81/81 - 8s - loss: 0.0231 - auc: 0.9274 - val_loss: 0.4814 - val_auc: 0.6609 - 8s/epoch - 97ms/step\n",
            "Epoch 220/500\n",
            "81/81 - 8s - loss: 0.0228 - auc: 0.9301 - val_loss: 0.4979 - val_auc: 0.6578 - 8s/epoch - 98ms/step\n",
            "Epoch 221/500\n",
            "81/81 - 8s - loss: 0.0228 - auc: 0.9317 - val_loss: 0.5017 - val_auc: 0.6630 - 8s/epoch - 102ms/step\n",
            "Epoch 222/500\n",
            "81/81 - 8s - loss: 0.0230 - auc: 0.9276 - val_loss: 0.5328 - val_auc: 0.6611 - 8s/epoch - 98ms/step\n",
            "Epoch 223/500\n",
            "81/81 - 8s - loss: 0.0226 - auc: 0.9304 - val_loss: 0.4886 - val_auc: 0.6580 - 8s/epoch - 99ms/step\n",
            "Epoch 224/500\n",
            "81/81 - 8s - loss: 0.0223 - auc: 0.9328 - val_loss: 0.4988 - val_auc: 0.6554 - 8s/epoch - 98ms/step\n",
            "Epoch 225/500\n",
            "81/81 - 8s - loss: 0.0223 - auc: 0.9337 - val_loss: 0.5116 - val_auc: 0.6514 - 8s/epoch - 97ms/step\n",
            "Epoch 226/500\n",
            "81/81 - 8s - loss: 0.0225 - auc: 0.9313 - val_loss: 0.4951 - val_auc: 0.6558 - 8s/epoch - 98ms/step\n",
            "Epoch 227/500\n",
            "81/81 - 8s - loss: 0.0226 - auc: 0.9308 - val_loss: 0.5204 - val_auc: 0.6612 - 8s/epoch - 97ms/step\n",
            "Epoch 228/500\n",
            "81/81 - 8s - loss: 0.0225 - auc: 0.9309 - val_loss: 0.5049 - val_auc: 0.6533 - 8s/epoch - 99ms/step\n",
            "Epoch 229/500\n",
            "81/81 - 8s - loss: 0.0218 - auc: 0.9348 - val_loss: 0.5100 - val_auc: 0.6530 - 8s/epoch - 100ms/step\n",
            "Epoch 230/500\n",
            "81/81 - 8s - loss: 0.0222 - auc: 0.9329 - val_loss: 0.5134 - val_auc: 0.6539 - 8s/epoch - 99ms/step\n",
            "Epoch 231/500\n",
            "81/81 - 8s - loss: 0.0219 - auc: 0.9361 - val_loss: 0.5098 - val_auc: 0.6444 - 8s/epoch - 98ms/step\n",
            "Epoch 232/500\n",
            "81/81 - 8s - loss: 0.0217 - auc: 0.9381 - val_loss: 0.4838 - val_auc: 0.6483 - 8s/epoch - 99ms/step\n",
            "Epoch 233/500\n",
            "81/81 - 8s - loss: 0.0218 - auc: 0.9359 - val_loss: 0.5081 - val_auc: 0.6429 - 8s/epoch - 98ms/step\n",
            "Epoch 234/500\n",
            "81/81 - 8s - loss: 0.0219 - auc: 0.9346 - val_loss: 0.5100 - val_auc: 0.6465 - 8s/epoch - 98ms/step\n",
            "Epoch 235/500\n",
            "81/81 - 8s - loss: 0.0216 - auc: 0.9384 - val_loss: 0.4938 - val_auc: 0.6505 - 8s/epoch - 98ms/step\n",
            "Epoch 236/500\n",
            "81/81 - 8s - loss: 0.0216 - auc: 0.9375 - val_loss: 0.5014 - val_auc: 0.6389 - 8s/epoch - 98ms/step\n",
            "Epoch 237/500\n",
            "81/81 - 8s - loss: 0.0227 - auc: 0.9321 - val_loss: 0.5337 - val_auc: 0.6284 - 8s/epoch - 98ms/step\n",
            "Epoch 238/500\n",
            "81/81 - 8s - loss: 0.0219 - auc: 0.9357 - val_loss: 0.5048 - val_auc: 0.6291 - 8s/epoch - 97ms/step\n",
            "Epoch 239/500\n",
            "81/81 - 8s - loss: 0.0212 - auc: 0.9394 - val_loss: 0.5390 - val_auc: 0.6307 - 8s/epoch - 99ms/step\n",
            "Epoch 240/500\n",
            "81/81 - 8s - loss: 0.0212 - auc: 0.9391 - val_loss: 0.5144 - val_auc: 0.6334 - 8s/epoch - 99ms/step\n",
            "Epoch 241/500\n",
            "81/81 - 8s - loss: 0.0211 - auc: 0.9408 - val_loss: 0.5486 - val_auc: 0.6520 - 8s/epoch - 99ms/step\n",
            "Epoch 242/500\n",
            "81/81 - 8s - loss: 0.0210 - auc: 0.9413 - val_loss: 0.5260 - val_auc: 0.6353 - 8s/epoch - 98ms/step\n",
            "Epoch 243/500\n",
            "81/81 - 8s - loss: 0.0210 - auc: 0.9404 - val_loss: 0.5221 - val_auc: 0.6318 - 8s/epoch - 98ms/step\n",
            "Epoch 244/500\n",
            "81/81 - 8s - loss: 0.0211 - auc: 0.9403 - val_loss: 0.5215 - val_auc: 0.6369 - 8s/epoch - 97ms/step\n",
            "Epoch 245/500\n",
            "81/81 - 8s - loss: 0.0207 - auc: 0.9440 - val_loss: 0.5178 - val_auc: 0.6349 - 8s/epoch - 98ms/step\n",
            "Epoch 246/500\n",
            "81/81 - 8s - loss: 0.0207 - auc: 0.9434 - val_loss: 0.5149 - val_auc: 0.6373 - 8s/epoch - 97ms/step\n",
            "Epoch 247/500\n",
            "81/81 - 8s - loss: 0.0206 - auc: 0.9421 - val_loss: 0.5173 - val_auc: 0.6368 - 8s/epoch - 98ms/step\n",
            "Epoch 248/500\n",
            "81/81 - 8s - loss: 0.0202 - auc: 0.9453 - val_loss: 0.5151 - val_auc: 0.6382 - 8s/epoch - 98ms/step\n",
            "Epoch 249/500\n",
            "81/81 - 8s - loss: 0.0206 - auc: 0.9417 - val_loss: 0.5072 - val_auc: 0.6377 - 8s/epoch - 99ms/step\n",
            "Epoch 250/500\n",
            "81/81 - 8s - loss: 0.0204 - auc: 0.9450 - val_loss: 0.5317 - val_auc: 0.6342 - 8s/epoch - 99ms/step\n",
            "Epoch 251/500\n",
            "81/81 - 8s - loss: 0.0208 - auc: 0.9422 - val_loss: 0.4871 - val_auc: 0.6400 - 8s/epoch - 98ms/step\n",
            "Epoch 252/500\n",
            "81/81 - 8s - loss: 0.0205 - auc: 0.9424 - val_loss: 0.5092 - val_auc: 0.6371 - 8s/epoch - 98ms/step\n",
            "Epoch 253/500\n",
            "81/81 - 8s - loss: 0.0198 - auc: 0.9495 - val_loss: 0.5246 - val_auc: 0.6376 - 8s/epoch - 97ms/step\n",
            "Epoch 254/500\n",
            "81/81 - 8s - loss: 0.0201 - auc: 0.9466 - val_loss: 0.5278 - val_auc: 0.6337 - 8s/epoch - 98ms/step\n",
            "Epoch 255/500\n",
            "81/81 - 8s - loss: 0.0199 - auc: 0.9482 - val_loss: 0.5148 - val_auc: 0.6340 - 8s/epoch - 99ms/step\n",
            "Epoch 256/500\n",
            "81/81 - 8s - loss: 0.0197 - auc: 0.9476 - val_loss: 0.5181 - val_auc: 0.6387 - 8s/epoch - 99ms/step\n",
            "Epoch 257/500\n",
            "81/81 - 8s - loss: 0.0200 - auc: 0.9467 - val_loss: 0.5398 - val_auc: 0.6412 - 8s/epoch - 105ms/step\n",
            "Epoch 258/500\n",
            "81/81 - 8s - loss: 0.0195 - auc: 0.9492 - val_loss: 0.5239 - val_auc: 0.6348 - 8s/epoch - 97ms/step\n",
            "Epoch 259/500\n",
            "81/81 - 8s - loss: 0.0197 - auc: 0.9493 - val_loss: 0.5172 - val_auc: 0.6337 - 8s/epoch - 97ms/step\n",
            "Epoch 260/500\n",
            "81/81 - 8s - loss: 0.0193 - auc: 0.9511 - val_loss: 0.5298 - val_auc: 0.6360 - 8s/epoch - 97ms/step\n",
            "Epoch 261/500\n",
            "81/81 - 8s - loss: 0.0192 - auc: 0.9500 - val_loss: 0.5180 - val_auc: 0.6359 - 8s/epoch - 97ms/step\n",
            "Epoch 262/500\n",
            "81/81 - 8s - loss: 0.0191 - auc: 0.9514 - val_loss: 0.5098 - val_auc: 0.6367 - 8s/epoch - 98ms/step\n",
            "Epoch 263/500\n",
            "81/81 - 8s - loss: 0.0195 - auc: 0.9491 - val_loss: 0.5319 - val_auc: 0.6457 - 8s/epoch - 97ms/step\n",
            "Epoch 264/500\n",
            "81/81 - 8s - loss: 0.0194 - auc: 0.9514 - val_loss: 0.5866 - val_auc: 0.6231 - 8s/epoch - 98ms/step\n",
            "Epoch 265/500\n",
            "81/81 - 8s - loss: 0.0192 - auc: 0.9496 - val_loss: 0.5338 - val_auc: 0.6370 - 8s/epoch - 98ms/step\n",
            "Epoch 266/500\n",
            "81/81 - 8s - loss: 0.0190 - auc: 0.9506 - val_loss: 0.5341 - val_auc: 0.6376 - 8s/epoch - 97ms/step\n",
            "Epoch 267/500\n",
            "81/81 - 8s - loss: 0.0192 - auc: 0.9514 - val_loss: 0.5366 - val_auc: 0.6377 - 8s/epoch - 100ms/step\n",
            "Epoch 268/500\n",
            "81/81 - 8s - loss: 0.0188 - auc: 0.9532 - val_loss: 0.5330 - val_auc: 0.6355 - 8s/epoch - 99ms/step\n",
            "Epoch 269/500\n",
            "81/81 - 8s - loss: 0.0189 - auc: 0.9514 - val_loss: 0.5363 - val_auc: 0.6379 - 8s/epoch - 98ms/step\n",
            "Epoch 270/500\n",
            "81/81 - 8s - loss: 0.0190 - auc: 0.9513 - val_loss: 0.5884 - val_auc: 0.6263 - 8s/epoch - 97ms/step\n",
            "Epoch 271/500\n",
            "81/81 - 8s - loss: 0.0185 - auc: 0.9554 - val_loss: 0.5285 - val_auc: 0.6393 - 8s/epoch - 97ms/step\n",
            "Epoch 272/500\n",
            "81/81 - 8s - loss: 0.0185 - auc: 0.9574 - val_loss: 0.5261 - val_auc: 0.6392 - 8s/epoch - 98ms/step\n",
            "Epoch 273/500\n",
            "81/81 - 8s - loss: 0.0183 - auc: 0.9556 - val_loss: 0.5392 - val_auc: 0.6385 - 8s/epoch - 98ms/step\n",
            "Epoch 274/500\n",
            "81/81 - 8s - loss: 0.0184 - auc: 0.9550 - val_loss: 0.5281 - val_auc: 0.6409 - 8s/epoch - 99ms/step\n",
            "Epoch 275/500\n",
            "81/81 - 8s - loss: 0.0185 - auc: 0.9547 - val_loss: 0.5330 - val_auc: 0.6391 - 8s/epoch - 97ms/step\n",
            "Epoch 276/500\n",
            "81/81 - 8s - loss: 0.0183 - auc: 0.9552 - val_loss: 0.5153 - val_auc: 0.6376 - 8s/epoch - 97ms/step\n",
            "Epoch 277/500\n",
            "81/81 - 8s - loss: 0.0182 - auc: 0.9564 - val_loss: 0.5183 - val_auc: 0.6343 - 8s/epoch - 98ms/step\n",
            "Epoch 278/500\n",
            "81/81 - 8s - loss: 0.0186 - auc: 0.9528 - val_loss: 0.5415 - val_auc: 0.6331 - 8s/epoch - 98ms/step\n",
            "Epoch 279/500\n",
            "81/81 - 8s - loss: 0.0177 - auc: 0.9606 - val_loss: 0.5390 - val_auc: 0.6343 - 8s/epoch - 98ms/step\n",
            "Epoch 280/500\n",
            "81/81 - 8s - loss: 0.0177 - auc: 0.9591 - val_loss: 0.5290 - val_auc: 0.6237 - 8s/epoch - 98ms/step\n",
            "Epoch 281/500\n",
            "81/81 - 8s - loss: 0.0179 - auc: 0.9576 - val_loss: 0.5431 - val_auc: 0.6379 - 8s/epoch - 97ms/step\n",
            "Epoch 282/500\n",
            "81/81 - 8s - loss: 0.0174 - auc: 0.9606 - val_loss: 0.5277 - val_auc: 0.6285 - 8s/epoch - 97ms/step\n",
            "Epoch 283/500\n",
            "81/81 - 8s - loss: 0.0173 - auc: 0.9620 - val_loss: 0.5356 - val_auc: 0.6309 - 8s/epoch - 97ms/step\n",
            "Epoch 284/500\n",
            "81/81 - 8s - loss: 0.0178 - auc: 0.9578 - val_loss: 0.5305 - val_auc: 0.6283 - 8s/epoch - 98ms/step\n",
            "Epoch 285/500\n",
            "81/81 - 8s - loss: 0.0179 - auc: 0.9556 - val_loss: 0.5649 - val_auc: 0.6266 - 8s/epoch - 97ms/step\n",
            "Epoch 286/500\n",
            "81/81 - 8s - loss: 0.0175 - auc: 0.9594 - val_loss: 0.5302 - val_auc: 0.6269 - 8s/epoch - 97ms/step\n",
            "Epoch 287/500\n",
            "81/81 - 8s - loss: 0.0174 - auc: 0.9604 - val_loss: 0.5592 - val_auc: 0.6255 - 8s/epoch - 97ms/step\n",
            "Epoch 288/500\n",
            "81/81 - 8s - loss: 0.0170 - auc: 0.9633 - val_loss: 0.5379 - val_auc: 0.6251 - 8s/epoch - 97ms/step\n",
            "Epoch 289/500\n",
            "81/81 - 8s - loss: 0.0169 - auc: 0.9626 - val_loss: 0.5441 - val_auc: 0.6299 - 8s/epoch - 97ms/step\n",
            "Epoch 290/500\n",
            "81/81 - 8s - loss: 0.0169 - auc: 0.9628 - val_loss: 0.5511 - val_auc: 0.6297 - 8s/epoch - 98ms/step\n",
            "Epoch 291/500\n",
            "81/81 - 8s - loss: 0.0172 - auc: 0.9615 - val_loss: 0.5324 - val_auc: 0.6244 - 8s/epoch - 98ms/step\n",
            "Epoch 292/500\n",
            "81/81 - 8s - loss: 0.0171 - auc: 0.9618 - val_loss: 0.5609 - val_auc: 0.6212 - 8s/epoch - 97ms/step\n",
            "Epoch 293/500\n",
            "81/81 - 8s - loss: 0.0164 - auc: 0.9663 - val_loss: 0.5551 - val_auc: 0.6236 - 8s/epoch - 105ms/step\n",
            "Epoch 294/500\n",
            "81/81 - 8s - loss: 0.0166 - auc: 0.9653 - val_loss: 0.5460 - val_auc: 0.6256 - 8s/epoch - 97ms/step\n",
            "Epoch 295/500\n",
            "81/81 - 8s - loss: 0.0170 - auc: 0.9625 - val_loss: 0.5561 - val_auc: 0.6260 - 8s/epoch - 98ms/step\n",
            "Epoch 296/500\n",
            "81/81 - 8s - loss: 0.0172 - auc: 0.9613 - val_loss: 0.5305 - val_auc: 0.6308 - 8s/epoch - 98ms/step\n",
            "Epoch 297/500\n",
            "81/81 - 8s - loss: 0.0168 - auc: 0.9632 - val_loss: 0.5794 - val_auc: 0.6210 - 8s/epoch - 98ms/step\n",
            "Epoch 298/500\n",
            "81/81 - 8s - loss: 0.0163 - auc: 0.9671 - val_loss: 0.5694 - val_auc: 0.6222 - 8s/epoch - 98ms/step\n",
            "Epoch 299/500\n",
            "81/81 - 8s - loss: 0.0161 - auc: 0.9677 - val_loss: 0.5674 - val_auc: 0.6262 - 8s/epoch - 99ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 45ms/step - loss: 0.5250 - auc: 0.6781\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 39ms/step - loss: 0.5064 - auc: 0.6743\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 7\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 9s - loss: 0.0497 - auc: 0.4763 - val_loss: 0.6834 - val_auc: 0.6550 - 9s/epoch - 117ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0493 - auc: 0.6259 - val_loss: 0.6711 - val_auc: 0.6702 - 8s/epoch - 100ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0491 - auc: 0.6382 - val_loss: 0.6619 - val_auc: 0.6573 - 8s/epoch - 97ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0488 - auc: 0.6579 - val_loss: 0.6574 - val_auc: 0.6572 - 8s/epoch - 98ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0485 - auc: 0.6575 - val_loss: 0.6536 - val_auc: 0.6467 - 8s/epoch - 101ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0483 - auc: 0.6587 - val_loss: 0.6513 - val_auc: 0.6424 - 8s/epoch - 99ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0480 - auc: 0.6544 - val_loss: 0.6493 - val_auc: 0.6424 - 8s/epoch - 97ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0478 - auc: 0.6546 - val_loss: 0.6482 - val_auc: 0.6440 - 8s/epoch - 98ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6542 - val_loss: 0.6479 - val_auc: 0.6441 - 8s/epoch - 99ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0474 - auc: 0.6584 - val_loss: 0.6488 - val_auc: 0.6408 - 8s/epoch - 99ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0472 - auc: 0.6557 - val_loss: 0.6488 - val_auc: 0.6346 - 8s/epoch - 99ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6564 - val_loss: 0.6522 - val_auc: 0.6363 - 8s/epoch - 99ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0469 - auc: 0.6594 - val_loss: 0.6534 - val_auc: 0.6358 - 8s/epoch - 97ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6601 - val_loss: 0.6543 - val_auc: 0.6320 - 8s/epoch - 97ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6618 - val_loss: 0.6559 - val_auc: 0.6312 - 8s/epoch - 97ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0466 - auc: 0.6609 - val_loss: 0.6567 - val_auc: 0.6285 - 8s/epoch - 97ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6617 - val_loss: 0.6585 - val_auc: 0.6242 - 8s/epoch - 99ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6646 - val_loss: 0.6583 - val_auc: 0.6235 - 8s/epoch - 104ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6649 - val_loss: 0.6576 - val_auc: 0.6227 - 8s/epoch - 99ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0462 - auc: 0.6645 - val_loss: 0.6588 - val_auc: 0.6183 - 8s/epoch - 99ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6660 - val_loss: 0.6587 - val_auc: 0.6181 - 8s/epoch - 99ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6677 - val_loss: 0.6575 - val_auc: 0.6162 - 8s/epoch - 100ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6663 - val_loss: 0.6563 - val_auc: 0.6148 - 8s/epoch - 100ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0457 - auc: 0.6709 - val_loss: 0.6544 - val_auc: 0.6133 - 8s/epoch - 100ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0457 - auc: 0.6721 - val_loss: 0.6552 - val_auc: 0.6119 - 8s/epoch - 100ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6756 - val_loss: 0.6528 - val_auc: 0.6105 - 8s/epoch - 100ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6719 - val_loss: 0.6541 - val_auc: 0.6084 - 8s/epoch - 100ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6762 - val_loss: 0.6525 - val_auc: 0.6074 - 8s/epoch - 100ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6772 - val_loss: 0.6508 - val_auc: 0.6063 - 8s/epoch - 100ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6775 - val_loss: 0.6505 - val_auc: 0.6052 - 8s/epoch - 100ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6774 - val_loss: 0.6506 - val_auc: 0.6031 - 8s/epoch - 103ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6823 - val_loss: 0.6493 - val_auc: 0.6031 - 8s/epoch - 100ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0449 - auc: 0.6856 - val_loss: 0.6474 - val_auc: 0.6035 - 8s/epoch - 101ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6860 - val_loss: 0.6463 - val_auc: 0.6026 - 8s/epoch - 100ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6866 - val_loss: 0.6444 - val_auc: 0.6011 - 8s/epoch - 101ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0446 - auc: 0.6916 - val_loss: 0.6444 - val_auc: 0.6003 - 8s/epoch - 100ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0446 - auc: 0.6909 - val_loss: 0.6450 - val_auc: 0.6022 - 8s/epoch - 100ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0444 - auc: 0.6931 - val_loss: 0.6412 - val_auc: 0.6013 - 8s/epoch - 99ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6917 - val_loss: 0.6440 - val_auc: 0.6011 - 8s/epoch - 99ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6964 - val_loss: 0.6403 - val_auc: 0.6020 - 8s/epoch - 100ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6966 - val_loss: 0.6393 - val_auc: 0.6015 - 8s/epoch - 100ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6961 - val_loss: 0.6391 - val_auc: 0.6018 - 8s/epoch - 99ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6945 - val_loss: 0.6379 - val_auc: 0.6038 - 8s/epoch - 101ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0441 - auc: 0.6963 - val_loss: 0.6379 - val_auc: 0.6022 - 8s/epoch - 100ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.6987 - val_loss: 0.6366 - val_auc: 0.6018 - 8s/epoch - 98ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.7010 - val_loss: 0.6377 - val_auc: 0.6017 - 8s/epoch - 100ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.7030 - val_loss: 0.6357 - val_auc: 0.6016 - 8s/epoch - 99ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0437 - auc: 0.7043 - val_loss: 0.6341 - val_auc: 0.6015 - 8s/epoch - 99ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 9s - loss: 0.0437 - auc: 0.7081 - val_loss: 0.6339 - val_auc: 0.6008 - 9s/epoch - 107ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7072 - val_loss: 0.6341 - val_auc: 0.6027 - 8s/epoch - 99ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7085 - val_loss: 0.6308 - val_auc: 0.6041 - 8s/epoch - 99ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7079 - val_loss: 0.6312 - val_auc: 0.6021 - 8s/epoch - 99ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7085 - val_loss: 0.6337 - val_auc: 0.6017 - 8s/epoch - 100ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7129 - val_loss: 0.6307 - val_auc: 0.6030 - 8s/epoch - 99ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7108 - val_loss: 0.6317 - val_auc: 0.6010 - 8s/epoch - 99ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7148 - val_loss: 0.6270 - val_auc: 0.6017 - 8s/epoch - 99ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7170 - val_loss: 0.6275 - val_auc: 0.6003 - 8s/epoch - 99ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7169 - val_loss: 0.6293 - val_auc: 0.6004 - 8s/epoch - 100ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0429 - auc: 0.7175 - val_loss: 0.6275 - val_auc: 0.6013 - 8s/epoch - 99ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7200 - val_loss: 0.6271 - val_auc: 0.5997 - 8s/epoch - 98ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7216 - val_loss: 0.6269 - val_auc: 0.6009 - 8s/epoch - 99ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0427 - auc: 0.7224 - val_loss: 0.6255 - val_auc: 0.6011 - 8s/epoch - 99ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7233 - val_loss: 0.6243 - val_auc: 0.5990 - 8s/epoch - 98ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7229 - val_loss: 0.6244 - val_auc: 0.5996 - 8s/epoch - 99ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7287 - val_loss: 0.6251 - val_auc: 0.5985 - 8s/epoch - 99ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7282 - val_loss: 0.6234 - val_auc: 0.5974 - 8s/epoch - 99ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7319 - val_loss: 0.6218 - val_auc: 0.5983 - 8s/epoch - 99ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0420 - auc: 0.7315 - val_loss: 0.6222 - val_auc: 0.5972 - 8s/epoch - 99ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7335 - val_loss: 0.6196 - val_auc: 0.5983 - 8s/epoch - 99ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0417 - auc: 0.7387 - val_loss: 0.6189 - val_auc: 0.5975 - 8s/epoch - 99ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0417 - auc: 0.7376 - val_loss: 0.6203 - val_auc: 0.5974 - 8s/epoch - 98ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7418 - val_loss: 0.6164 - val_auc: 0.5986 - 8s/epoch - 99ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7370 - val_loss: 0.6175 - val_auc: 0.5983 - 8s/epoch - 99ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0412 - auc: 0.7433 - val_loss: 0.6166 - val_auc: 0.5990 - 8s/epoch - 99ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7441 - val_loss: 0.6161 - val_auc: 0.5996 - 8s/epoch - 98ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7476 - val_loss: 0.6153 - val_auc: 0.6013 - 8s/epoch - 99ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0409 - auc: 0.7490 - val_loss: 0.6170 - val_auc: 0.6034 - 8s/epoch - 99ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0409 - auc: 0.7486 - val_loss: 0.6174 - val_auc: 0.6033 - 8s/epoch - 99ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0407 - auc: 0.7517 - val_loss: 0.6178 - val_auc: 0.6036 - 8s/epoch - 99ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7535 - val_loss: 0.6106 - val_auc: 0.6044 - 8s/epoch - 99ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7539 - val_loss: 0.6127 - val_auc: 0.6062 - 8s/epoch - 100ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7541 - val_loss: 0.6127 - val_auc: 0.6074 - 8s/epoch - 100ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7538 - val_loss: 0.6168 - val_auc: 0.6068 - 8s/epoch - 98ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 9s - loss: 0.0403 - auc: 0.7561 - val_loss: 0.6129 - val_auc: 0.6081 - 9s/epoch - 105ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0400 - auc: 0.7613 - val_loss: 0.6152 - val_auc: 0.6058 - 8s/epoch - 99ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0400 - auc: 0.7598 - val_loss: 0.6058 - val_auc: 0.6067 - 8s/epoch - 99ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0400 - auc: 0.7600 - val_loss: 0.6066 - val_auc: 0.6091 - 8s/epoch - 98ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0398 - auc: 0.7619 - val_loss: 0.6139 - val_auc: 0.6069 - 8s/epoch - 100ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0398 - auc: 0.7620 - val_loss: 0.6114 - val_auc: 0.6091 - 8s/epoch - 99ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7634 - val_loss: 0.6141 - val_auc: 0.6079 - 8s/epoch - 100ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7644 - val_loss: 0.6065 - val_auc: 0.6104 - 8s/epoch - 99ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7664 - val_loss: 0.6064 - val_auc: 0.6116 - 8s/epoch - 101ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 38ms/step - loss: 0.6687 - auc: 0.6291\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 37ms/step - loss: 0.6711 - auc: 0.6702\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 8\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 9s - loss: 0.0495 - auc: 0.5405 - val_loss: 0.6801 - val_auc: 0.6329 - 9s/epoch - 117ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0490 - auc: 0.6406 - val_loss: 0.6663 - val_auc: 0.6500 - 8s/epoch - 101ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0486 - auc: 0.6493 - val_loss: 0.6554 - val_auc: 0.6400 - 8s/epoch - 99ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0482 - auc: 0.6553 - val_loss: 0.6478 - val_auc: 0.6409 - 8s/epoch - 99ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0479 - auc: 0.6535 - val_loss: 0.6441 - val_auc: 0.6395 - 8s/epoch - 99ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 8s - loss: 0.0476 - auc: 0.6564 - val_loss: 0.6400 - val_auc: 0.6422 - 8s/epoch - 98ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0473 - auc: 0.6569 - val_loss: 0.6378 - val_auc: 0.6397 - 8s/epoch - 97ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0471 - auc: 0.6574 - val_loss: 0.6370 - val_auc: 0.6407 - 8s/epoch - 99ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0470 - auc: 0.6559 - val_loss: 0.6397 - val_auc: 0.6401 - 8s/epoch - 98ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0469 - auc: 0.6566 - val_loss: 0.6405 - val_auc: 0.6402 - 8s/epoch - 98ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6569 - val_loss: 0.6402 - val_auc: 0.6397 - 8s/epoch - 98ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0466 - auc: 0.6623 - val_loss: 0.6383 - val_auc: 0.6403 - 8s/epoch - 98ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0465 - auc: 0.6598 - val_loss: 0.6385 - val_auc: 0.6399 - 8s/epoch - 97ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6612 - val_loss: 0.6387 - val_auc: 0.6417 - 8s/epoch - 98ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6610 - val_loss: 0.6358 - val_auc: 0.6425 - 8s/epoch - 97ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6653 - val_loss: 0.6350 - val_auc: 0.6401 - 8s/epoch - 98ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6703 - val_loss: 0.6327 - val_auc: 0.6400 - 8s/epoch - 97ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0459 - auc: 0.6676 - val_loss: 0.6325 - val_auc: 0.6394 - 8s/epoch - 98ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6702 - val_loss: 0.6316 - val_auc: 0.6398 - 8s/epoch - 99ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6733 - val_loss: 0.6299 - val_auc: 0.6394 - 8s/epoch - 102ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6778 - val_loss: 0.6277 - val_auc: 0.6402 - 8s/epoch - 97ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6761 - val_loss: 0.6297 - val_auc: 0.6397 - 8s/epoch - 98ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0453 - auc: 0.6793 - val_loss: 0.6264 - val_auc: 0.6410 - 8s/epoch - 97ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6801 - val_loss: 0.6245 - val_auc: 0.6413 - 8s/epoch - 98ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6849 - val_loss: 0.6217 - val_auc: 0.6411 - 8s/epoch - 98ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0450 - auc: 0.6856 - val_loss: 0.6234 - val_auc: 0.6414 - 8s/epoch - 100ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6893 - val_loss: 0.6206 - val_auc: 0.6410 - 8s/epoch - 98ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0448 - auc: 0.6889 - val_loss: 0.6193 - val_auc: 0.6426 - 8s/epoch - 98ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6952 - val_loss: 0.6182 - val_auc: 0.6413 - 8s/epoch - 99ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6952 - val_loss: 0.6144 - val_auc: 0.6422 - 8s/epoch - 98ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6985 - val_loss: 0.6160 - val_auc: 0.6423 - 8s/epoch - 97ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.7001 - val_loss: 0.6140 - val_auc: 0.6435 - 8s/epoch - 98ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0441 - auc: 0.7022 - val_loss: 0.6141 - val_auc: 0.6437 - 8s/epoch - 99ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0440 - auc: 0.7009 - val_loss: 0.6132 - val_auc: 0.6445 - 8s/epoch - 98ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7055 - val_loss: 0.6101 - val_auc: 0.6457 - 8s/epoch - 98ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0437 - auc: 0.7066 - val_loss: 0.6105 - val_auc: 0.6460 - 8s/epoch - 98ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7105 - val_loss: 0.6087 - val_auc: 0.6459 - 8s/epoch - 98ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7084 - val_loss: 0.6053 - val_auc: 0.6464 - 8s/epoch - 98ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7092 - val_loss: 0.6089 - val_auc: 0.6455 - 8s/epoch - 98ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7131 - val_loss: 0.6060 - val_auc: 0.6466 - 8s/epoch - 98ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0433 - auc: 0.7116 - val_loss: 0.6073 - val_auc: 0.6485 - 8s/epoch - 99ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7193 - val_loss: 0.6044 - val_auc: 0.6489 - 8s/epoch - 98ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7182 - val_loss: 0.6041 - val_auc: 0.6482 - 8s/epoch - 98ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0429 - auc: 0.7191 - val_loss: 0.6056 - val_auc: 0.6495 - 8s/epoch - 97ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7199 - val_loss: 0.6030 - val_auc: 0.6495 - 8s/epoch - 98ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7265 - val_loss: 0.6009 - val_auc: 0.6501 - 8s/epoch - 98ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0423 - auc: 0.7294 - val_loss: 0.5974 - val_auc: 0.6513 - 8s/epoch - 98ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7264 - val_loss: 0.6033 - val_auc: 0.6503 - 8s/epoch - 97ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0421 - auc: 0.7297 - val_loss: 0.5978 - val_auc: 0.6521 - 8s/epoch - 98ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7325 - val_loss: 0.5967 - val_auc: 0.6524 - 8s/epoch - 98ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0417 - auc: 0.7384 - val_loss: 0.5922 - val_auc: 0.6528 - 8s/epoch - 103ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7383 - val_loss: 0.5903 - val_auc: 0.6534 - 8s/epoch - 98ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7416 - val_loss: 0.5902 - val_auc: 0.6533 - 8s/epoch - 97ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7433 - val_loss: 0.5891 - val_auc: 0.6534 - 8s/epoch - 98ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7473 - val_loss: 0.5825 - val_auc: 0.6549 - 8s/epoch - 100ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0406 - auc: 0.7523 - val_loss: 0.5764 - val_auc: 0.6568 - 8s/epoch - 99ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0408 - auc: 0.7487 - val_loss: 0.5814 - val_auc: 0.6580 - 8s/epoch - 98ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7540 - val_loss: 0.5780 - val_auc: 0.6577 - 8s/epoch - 97ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7546 - val_loss: 0.5816 - val_auc: 0.6574 - 8s/epoch - 98ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0402 - auc: 0.7564 - val_loss: 0.5813 - val_auc: 0.6580 - 8s/epoch - 98ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0401 - auc: 0.7580 - val_loss: 0.5754 - val_auc: 0.6595 - 8s/epoch - 98ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7580 - val_loss: 0.5766 - val_auc: 0.6603 - 8s/epoch - 100ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7620 - val_loss: 0.5709 - val_auc: 0.6621 - 8s/epoch - 98ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0396 - auc: 0.7627 - val_loss: 0.5734 - val_auc: 0.6622 - 8s/epoch - 100ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7653 - val_loss: 0.5682 - val_auc: 0.6611 - 8s/epoch - 99ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0395 - auc: 0.7639 - val_loss: 0.5676 - val_auc: 0.6608 - 8s/epoch - 97ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7664 - val_loss: 0.5687 - val_auc: 0.6607 - 8s/epoch - 97ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7682 - val_loss: 0.5720 - val_auc: 0.6614 - 8s/epoch - 98ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7731 - val_loss: 0.5649 - val_auc: 0.6643 - 8s/epoch - 98ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7750 - val_loss: 0.5635 - val_auc: 0.6617 - 8s/epoch - 97ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0386 - auc: 0.7760 - val_loss: 0.5661 - val_auc: 0.6652 - 8s/epoch - 97ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0383 - auc: 0.7806 - val_loss: 0.5652 - val_auc: 0.6635 - 8s/epoch - 97ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0384 - auc: 0.7789 - val_loss: 0.5683 - val_auc: 0.6650 - 8s/epoch - 97ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7811 - val_loss: 0.5622 - val_auc: 0.6667 - 8s/epoch - 99ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7835 - val_loss: 0.5611 - val_auc: 0.6666 - 8s/epoch - 97ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0376 - auc: 0.7894 - val_loss: 0.5580 - val_auc: 0.6670 - 8s/epoch - 98ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0378 - auc: 0.7859 - val_loss: 0.5552 - val_auc: 0.6690 - 8s/epoch - 99ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0379 - auc: 0.7856 - val_loss: 0.5570 - val_auc: 0.6687 - 8s/epoch - 97ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0374 - auc: 0.7940 - val_loss: 0.5589 - val_auc: 0.6688 - 8s/epoch - 98ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0374 - auc: 0.7921 - val_loss: 0.5545 - val_auc: 0.6700 - 8s/epoch - 98ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0371 - auc: 0.7968 - val_loss: 0.5576 - val_auc: 0.6694 - 8s/epoch - 97ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0369 - auc: 0.7988 - val_loss: 0.5527 - val_auc: 0.6693 - 8s/epoch - 98ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0372 - auc: 0.7936 - val_loss: 0.5595 - val_auc: 0.6677 - 8s/epoch - 97ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0368 - auc: 0.7985 - val_loss: 0.5638 - val_auc: 0.6696 - 8s/epoch - 97ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0366 - auc: 0.8021 - val_loss: 0.5582 - val_auc: 0.6702 - 8s/epoch - 99ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0366 - auc: 0.8027 - val_loss: 0.5495 - val_auc: 0.6712 - 8s/epoch - 103ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0362 - auc: 0.8083 - val_loss: 0.5556 - val_auc: 0.6736 - 8s/epoch - 99ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0363 - auc: 0.8050 - val_loss: 0.5531 - val_auc: 0.6695 - 8s/epoch - 98ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0363 - auc: 0.8037 - val_loss: 0.5570 - val_auc: 0.6705 - 8s/epoch - 98ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0360 - auc: 0.8099 - val_loss: 0.5540 - val_auc: 0.6730 - 8s/epoch - 98ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0356 - auc: 0.8147 - val_loss: 0.5460 - val_auc: 0.6721 - 8s/epoch - 97ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0357 - auc: 0.8134 - val_loss: 0.5461 - val_auc: 0.6705 - 8s/epoch - 98ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0355 - auc: 0.8150 - val_loss: 0.5404 - val_auc: 0.6727 - 8s/epoch - 98ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0354 - auc: 0.8135 - val_loss: 0.5502 - val_auc: 0.6712 - 8s/epoch - 98ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0354 - auc: 0.8174 - val_loss: 0.5470 - val_auc: 0.6703 - 8s/epoch - 98ms/step\n",
            "Epoch 96/500\n",
            "81/81 - 8s - loss: 0.0350 - auc: 0.8236 - val_loss: 0.5493 - val_auc: 0.6708 - 8s/epoch - 99ms/step\n",
            "Epoch 97/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8253 - val_loss: 0.5427 - val_auc: 0.6706 - 8s/epoch - 97ms/step\n",
            "Epoch 98/500\n",
            "81/81 - 8s - loss: 0.0348 - auc: 0.8270 - val_loss: 0.5491 - val_auc: 0.6697 - 8s/epoch - 97ms/step\n",
            "Epoch 99/500\n",
            "81/81 - 8s - loss: 0.0346 - auc: 0.8284 - val_loss: 0.5459 - val_auc: 0.6680 - 8s/epoch - 99ms/step\n",
            "Epoch 100/500\n",
            "81/81 - 8s - loss: 0.0347 - auc: 0.8266 - val_loss: 0.5547 - val_auc: 0.6663 - 8s/epoch - 97ms/step\n",
            "Epoch 101/500\n",
            "81/81 - 8s - loss: 0.0346 - auc: 0.8268 - val_loss: 0.5363 - val_auc: 0.6666 - 8s/epoch - 97ms/step\n",
            "Epoch 102/500\n",
            "81/81 - 8s - loss: 0.0344 - auc: 0.8299 - val_loss: 0.5466 - val_auc: 0.6654 - 8s/epoch - 97ms/step\n",
            "Epoch 103/500\n",
            "81/81 - 8s - loss: 0.0339 - auc: 0.8325 - val_loss: 0.5372 - val_auc: 0.6664 - 8s/epoch - 100ms/step\n",
            "Epoch 104/500\n",
            "81/81 - 8s - loss: 0.0342 - auc: 0.8271 - val_loss: 0.5458 - val_auc: 0.6660 - 8s/epoch - 98ms/step\n",
            "Epoch 105/500\n",
            "81/81 - 8s - loss: 0.0338 - auc: 0.8373 - val_loss: 0.5367 - val_auc: 0.6646 - 8s/epoch - 99ms/step\n",
            "Epoch 106/500\n",
            "81/81 - 8s - loss: 0.0338 - auc: 0.8331 - val_loss: 0.5353 - val_auc: 0.6638 - 8s/epoch - 99ms/step\n",
            "Epoch 107/500\n",
            "81/81 - 8s - loss: 0.0335 - auc: 0.8386 - val_loss: 0.5358 - val_auc: 0.6637 - 8s/epoch - 98ms/step\n",
            "Epoch 108/500\n",
            "81/81 - 8s - loss: 0.0332 - auc: 0.8429 - val_loss: 0.5276 - val_auc: 0.6653 - 8s/epoch - 99ms/step\n",
            "Epoch 109/500\n",
            "81/81 - 8s - loss: 0.0334 - auc: 0.8364 - val_loss: 0.5322 - val_auc: 0.6636 - 8s/epoch - 99ms/step\n",
            "Epoch 110/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8442 - val_loss: 0.5337 - val_auc: 0.6567 - 8s/epoch - 97ms/step\n",
            "Epoch 111/500\n",
            "81/81 - 8s - loss: 0.0331 - auc: 0.8426 - val_loss: 0.5387 - val_auc: 0.6581 - 8s/epoch - 99ms/step\n",
            "Epoch 112/500\n",
            "81/81 - 8s - loss: 0.0332 - auc: 0.8392 - val_loss: 0.5421 - val_auc: 0.6560 - 8s/epoch - 99ms/step\n",
            "Epoch 113/500\n",
            "81/81 - 8s - loss: 0.0329 - auc: 0.8408 - val_loss: 0.5453 - val_auc: 0.6558 - 8s/epoch - 99ms/step\n",
            "Epoch 114/500\n",
            "81/81 - 8s - loss: 0.0328 - auc: 0.8431 - val_loss: 0.5292 - val_auc: 0.6563 - 8s/epoch - 98ms/step\n",
            "Epoch 115/500\n",
            "81/81 - 8s - loss: 0.0325 - auc: 0.8483 - val_loss: 0.5293 - val_auc: 0.6551 - 8s/epoch - 100ms/step\n",
            "Epoch 116/500\n",
            "81/81 - 8s - loss: 0.0326 - auc: 0.8467 - val_loss: 0.5439 - val_auc: 0.6523 - 8s/epoch - 99ms/step\n",
            "Epoch 117/500\n",
            "81/81 - 8s - loss: 0.0322 - auc: 0.8480 - val_loss: 0.5297 - val_auc: 0.6542 - 8s/epoch - 99ms/step\n",
            "Epoch 118/500\n",
            "81/81 - 8s - loss: 0.0322 - auc: 0.8511 - val_loss: 0.5300 - val_auc: 0.6531 - 8s/epoch - 99ms/step\n",
            "Epoch 119/500\n",
            "81/81 - 8s - loss: 0.0320 - auc: 0.8532 - val_loss: 0.5280 - val_auc: 0.6500 - 8s/epoch - 99ms/step\n",
            "Epoch 120/500\n",
            "81/81 - 8s - loss: 0.0318 - auc: 0.8527 - val_loss: 0.5273 - val_auc: 0.6503 - 8s/epoch - 99ms/step\n",
            "Epoch 121/500\n",
            "81/81 - 9s - loss: 0.0319 - auc: 0.8536 - val_loss: 0.5248 - val_auc: 0.6537 - 9s/epoch - 107ms/step\n",
            "Epoch 122/500\n",
            "81/81 - 8s - loss: 0.0318 - auc: 0.8529 - val_loss: 0.5153 - val_auc: 0.6520 - 8s/epoch - 99ms/step\n",
            "Epoch 123/500\n",
            "81/81 - 8s - loss: 0.0315 - auc: 0.8575 - val_loss: 0.5267 - val_auc: 0.6519 - 8s/epoch - 98ms/step\n",
            "Epoch 124/500\n",
            "81/81 - 8s - loss: 0.0317 - auc: 0.8559 - val_loss: 0.5450 - val_auc: 0.6467 - 8s/epoch - 98ms/step\n",
            "Epoch 125/500\n",
            "81/81 - 8s - loss: 0.0313 - auc: 0.8567 - val_loss: 0.5217 - val_auc: 0.6506 - 8s/epoch - 100ms/step\n",
            "Epoch 126/500\n",
            "81/81 - 8s - loss: 0.0311 - auc: 0.8619 - val_loss: 0.5179 - val_auc: 0.6508 - 8s/epoch - 99ms/step\n",
            "Epoch 127/500\n",
            "81/81 - 8s - loss: 0.0311 - auc: 0.8573 - val_loss: 0.5186 - val_auc: 0.6528 - 8s/epoch - 99ms/step\n",
            "Epoch 128/500\n",
            "81/81 - 8s - loss: 0.0310 - auc: 0.8605 - val_loss: 0.5371 - val_auc: 0.6456 - 8s/epoch - 100ms/step\n",
            "Epoch 129/500\n",
            "81/81 - 8s - loss: 0.0310 - auc: 0.8623 - val_loss: 0.5176 - val_auc: 0.6495 - 8s/epoch - 100ms/step\n",
            "Epoch 130/500\n",
            "81/81 - 8s - loss: 0.0305 - auc: 0.8657 - val_loss: 0.5311 - val_auc: 0.6496 - 8s/epoch - 100ms/step\n",
            "Epoch 131/500\n",
            "81/81 - 8s - loss: 0.0307 - auc: 0.8612 - val_loss: 0.5331 - val_auc: 0.6472 - 8s/epoch - 100ms/step\n",
            "Epoch 132/500\n",
            "81/81 - 8s - loss: 0.0304 - auc: 0.8657 - val_loss: 0.5206 - val_auc: 0.6386 - 8s/epoch - 100ms/step\n",
            "Epoch 133/500\n",
            "81/81 - 8s - loss: 0.0304 - auc: 0.8659 - val_loss: 0.5090 - val_auc: 0.6405 - 8s/epoch - 100ms/step\n",
            "Epoch 134/500\n",
            "81/81 - 8s - loss: 0.0302 - auc: 0.8672 - val_loss: 0.5186 - val_auc: 0.6395 - 8s/epoch - 100ms/step\n",
            "Epoch 135/500\n",
            "81/81 - 8s - loss: 0.0299 - auc: 0.8695 - val_loss: 0.5187 - val_auc: 0.6407 - 8s/epoch - 100ms/step\n",
            "Epoch 136/500\n",
            "81/81 - 8s - loss: 0.0297 - auc: 0.8726 - val_loss: 0.5171 - val_auc: 0.6401 - 8s/epoch - 100ms/step\n",
            "Epoch 137/500\n",
            "81/81 - 8s - loss: 0.0297 - auc: 0.8713 - val_loss: 0.5093 - val_auc: 0.6394 - 8s/epoch - 100ms/step\n",
            "Epoch 138/500\n",
            "81/81 - 8s - loss: 0.0296 - auc: 0.8738 - val_loss: 0.5132 - val_auc: 0.6379 - 8s/epoch - 100ms/step\n",
            "Epoch 139/500\n",
            "81/81 - 8s - loss: 0.0296 - auc: 0.8739 - val_loss: 0.5166 - val_auc: 0.6393 - 8s/epoch - 100ms/step\n",
            "Epoch 140/500\n",
            "81/81 - 8s - loss: 0.0295 - auc: 0.8741 - val_loss: 0.5313 - val_auc: 0.6373 - 8s/epoch - 99ms/step\n",
            "Epoch 141/500\n",
            "81/81 - 8s - loss: 0.0290 - auc: 0.8800 - val_loss: 0.5225 - val_auc: 0.6369 - 8s/epoch - 101ms/step\n",
            "Epoch 142/500\n",
            "81/81 - 8s - loss: 0.0287 - auc: 0.8846 - val_loss: 0.5148 - val_auc: 0.6379 - 8s/epoch - 99ms/step\n",
            "Epoch 143/500\n",
            "81/81 - 8s - loss: 0.0291 - auc: 0.8748 - val_loss: 0.5265 - val_auc: 0.6364 - 8s/epoch - 97ms/step\n",
            "Epoch 144/500\n",
            "81/81 - 8s - loss: 0.0287 - auc: 0.8813 - val_loss: 0.5080 - val_auc: 0.6395 - 8s/epoch - 98ms/step\n",
            "Epoch 145/500\n",
            "81/81 - 9s - loss: 0.0287 - auc: 0.8805 - val_loss: 0.5060 - val_auc: 0.6406 - 9s/epoch - 108ms/step\n",
            "Epoch 146/500\n",
            "81/81 - 8s - loss: 0.0284 - auc: 0.8840 - val_loss: 0.4897 - val_auc: 0.6420 - 8s/epoch - 100ms/step\n",
            "Epoch 147/500\n",
            "81/81 - 8s - loss: 0.0287 - auc: 0.8823 - val_loss: 0.5337 - val_auc: 0.6370 - 8s/epoch - 98ms/step\n",
            "Epoch 148/500\n",
            "81/81 - 8s - loss: 0.0283 - auc: 0.8826 - val_loss: 0.5144 - val_auc: 0.6388 - 8s/epoch - 99ms/step\n",
            "Epoch 149/500\n",
            "81/81 - 8s - loss: 0.0285 - auc: 0.8826 - val_loss: 0.5237 - val_auc: 0.6384 - 8s/epoch - 99ms/step\n",
            "Epoch 150/500\n",
            "81/81 - 8s - loss: 0.0282 - auc: 0.8878 - val_loss: 0.5184 - val_auc: 0.6394 - 8s/epoch - 98ms/step\n",
            "Epoch 151/500\n",
            "81/81 - 8s - loss: 0.0281 - auc: 0.8866 - val_loss: 0.5316 - val_auc: 0.6388 - 8s/epoch - 100ms/step\n",
            "Epoch 152/500\n",
            "81/81 - 8s - loss: 0.0279 - auc: 0.8904 - val_loss: 0.5359 - val_auc: 0.6372 - 8s/epoch - 99ms/step\n",
            "Epoch 153/500\n",
            "81/81 - 8s - loss: 0.0278 - auc: 0.8890 - val_loss: 0.5190 - val_auc: 0.6299 - 8s/epoch - 98ms/step\n",
            "Epoch 154/500\n",
            "81/81 - 8s - loss: 0.0276 - auc: 0.8907 - val_loss: 0.5195 - val_auc: 0.6302 - 8s/epoch - 98ms/step\n",
            "Epoch 155/500\n",
            "81/81 - 8s - loss: 0.0275 - auc: 0.8888 - val_loss: 0.5113 - val_auc: 0.6327 - 8s/epoch - 98ms/step\n",
            "Epoch 156/500\n",
            "81/81 - 9s - loss: 0.0275 - auc: 0.8914 - val_loss: 0.5308 - val_auc: 0.6311 - 9s/epoch - 106ms/step\n",
            "Epoch 157/500\n",
            "81/81 - 8s - loss: 0.0272 - auc: 0.8955 - val_loss: 0.5191 - val_auc: 0.6310 - 8s/epoch - 98ms/step\n",
            "Epoch 158/500\n",
            "81/81 - 8s - loss: 0.0269 - auc: 0.8984 - val_loss: 0.5098 - val_auc: 0.6328 - 8s/epoch - 99ms/step\n",
            "Epoch 159/500\n",
            "81/81 - 8s - loss: 0.0271 - auc: 0.8948 - val_loss: 0.5241 - val_auc: 0.6344 - 8s/epoch - 100ms/step\n",
            "Epoch 160/500\n",
            "81/81 - 8s - loss: 0.0271 - auc: 0.8961 - val_loss: 0.5150 - val_auc: 0.6345 - 8s/epoch - 99ms/step\n",
            "Epoch 161/500\n",
            "81/81 - 8s - loss: 0.0267 - auc: 0.8993 - val_loss: 0.5316 - val_auc: 0.6330 - 8s/epoch - 99ms/step\n",
            "Epoch 162/500\n",
            "81/81 - 8s - loss: 0.0265 - auc: 0.9016 - val_loss: 0.5156 - val_auc: 0.6350 - 8s/epoch - 99ms/step\n",
            "Epoch 163/500\n",
            "81/81 - 8s - loss: 0.0265 - auc: 0.9020 - val_loss: 0.5411 - val_auc: 0.6325 - 8s/epoch - 99ms/step\n",
            "Epoch 164/500\n",
            "81/81 - 8s - loss: 0.0264 - auc: 0.9041 - val_loss: 0.5093 - val_auc: 0.6363 - 8s/epoch - 100ms/step\n",
            "Epoch 165/500\n",
            "81/81 - 8s - loss: 0.0263 - auc: 0.9009 - val_loss: 0.5189 - val_auc: 0.6360 - 8s/epoch - 98ms/step\n",
            "Epoch 166/500\n",
            "81/81 - 8s - loss: 0.0262 - auc: 0.9031 - val_loss: 0.5197 - val_auc: 0.6344 - 8s/epoch - 99ms/step\n",
            "Epoch 167/500\n",
            "81/81 - 8s - loss: 0.0258 - auc: 0.9079 - val_loss: 0.5287 - val_auc: 0.6354 - 8s/epoch - 98ms/step\n",
            "Epoch 168/500\n",
            "81/81 - 8s - loss: 0.0259 - auc: 0.9046 - val_loss: 0.5158 - val_auc: 0.6366 - 8s/epoch - 97ms/step\n",
            "Epoch 169/500\n",
            "81/81 - 8s - loss: 0.0258 - auc: 0.9058 - val_loss: 0.5114 - val_auc: 0.6354 - 8s/epoch - 97ms/step\n",
            "Epoch 170/500\n",
            "81/81 - 8s - loss: 0.0255 - auc: 0.9100 - val_loss: 0.5176 - val_auc: 0.6343 - 8s/epoch - 99ms/step\n",
            "Epoch 171/500\n",
            "81/81 - 8s - loss: 0.0255 - auc: 0.9094 - val_loss: 0.5140 - val_auc: 0.6385 - 8s/epoch - 98ms/step\n",
            "Epoch 172/500\n",
            "81/81 - 8s - loss: 0.0257 - auc: 0.9067 - val_loss: 0.5190 - val_auc: 0.6338 - 8s/epoch - 98ms/step\n",
            "Epoch 173/500\n",
            "81/81 - 8s - loss: 0.0253 - auc: 0.9123 - val_loss: 0.5105 - val_auc: 0.6377 - 8s/epoch - 98ms/step\n",
            "Epoch 174/500\n",
            "81/81 - 8s - loss: 0.0251 - auc: 0.9125 - val_loss: 0.5233 - val_auc: 0.6370 - 8s/epoch - 98ms/step\n",
            "Epoch 175/500\n",
            "81/81 - 8s - loss: 0.0251 - auc: 0.9116 - val_loss: 0.5023 - val_auc: 0.6405 - 8s/epoch - 97ms/step\n",
            "Epoch 176/500\n",
            "81/81 - 8s - loss: 0.0250 - auc: 0.9120 - val_loss: 0.5315 - val_auc: 0.6374 - 8s/epoch - 99ms/step\n",
            "Epoch 177/500\n",
            "81/81 - 8s - loss: 0.0250 - auc: 0.9110 - val_loss: 0.5457 - val_auc: 0.6337 - 8s/epoch - 101ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 35ms/step - loss: 0.5765 - auc: 0.6873\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 36ms/step - loss: 0.5556 - auc: 0.6736\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 9\n",
            "Resetting model..\n",
            "Epoch 1/500\n",
            "81/81 - 9s - loss: 0.0496 - auc: 0.5000 - val_loss: 0.6839 - val_auc: 0.7060 - 9s/epoch - 116ms/step\n",
            "Epoch 2/500\n",
            "81/81 - 8s - loss: 0.0493 - auc: 0.6351 - val_loss: 0.6708 - val_auc: 0.7203 - 8s/epoch - 102ms/step\n",
            "Epoch 3/500\n",
            "81/81 - 8s - loss: 0.0490 - auc: 0.6398 - val_loss: 0.6608 - val_auc: 0.7256 - 8s/epoch - 99ms/step\n",
            "Epoch 4/500\n",
            "81/81 - 8s - loss: 0.0487 - auc: 0.6446 - val_loss: 0.6530 - val_auc: 0.7306 - 8s/epoch - 99ms/step\n",
            "Epoch 5/500\n",
            "81/81 - 8s - loss: 0.0485 - auc: 0.6489 - val_loss: 0.6468 - val_auc: 0.7345 - 8s/epoch - 100ms/step\n",
            "Epoch 6/500\n",
            "81/81 - 9s - loss: 0.0483 - auc: 0.6480 - val_loss: 0.6423 - val_auc: 0.7311 - 9s/epoch - 107ms/step\n",
            "Epoch 7/500\n",
            "81/81 - 8s - loss: 0.0480 - auc: 0.6496 - val_loss: 0.6383 - val_auc: 0.7319 - 8s/epoch - 100ms/step\n",
            "Epoch 8/500\n",
            "81/81 - 8s - loss: 0.0479 - auc: 0.6477 - val_loss: 0.6361 - val_auc: 0.7287 - 8s/epoch - 100ms/step\n",
            "Epoch 9/500\n",
            "81/81 - 8s - loss: 0.0477 - auc: 0.6473 - val_loss: 0.6360 - val_auc: 0.7294 - 8s/epoch - 99ms/step\n",
            "Epoch 10/500\n",
            "81/81 - 8s - loss: 0.0475 - auc: 0.6466 - val_loss: 0.6366 - val_auc: 0.7296 - 8s/epoch - 99ms/step\n",
            "Epoch 11/500\n",
            "81/81 - 8s - loss: 0.0474 - auc: 0.6484 - val_loss: 0.6375 - val_auc: 0.7288 - 8s/epoch - 100ms/step\n",
            "Epoch 12/500\n",
            "81/81 - 8s - loss: 0.0472 - auc: 0.6494 - val_loss: 0.6384 - val_auc: 0.7307 - 8s/epoch - 100ms/step\n",
            "Epoch 13/500\n",
            "81/81 - 8s - loss: 0.0472 - auc: 0.6457 - val_loss: 0.6393 - val_auc: 0.7283 - 8s/epoch - 97ms/step\n",
            "Epoch 14/500\n",
            "81/81 - 8s - loss: 0.0470 - auc: 0.6508 - val_loss: 0.6369 - val_auc: 0.7281 - 8s/epoch - 99ms/step\n",
            "Epoch 15/500\n",
            "81/81 - 8s - loss: 0.0469 - auc: 0.6507 - val_loss: 0.6390 - val_auc: 0.7252 - 8s/epoch - 99ms/step\n",
            "Epoch 16/500\n",
            "81/81 - 8s - loss: 0.0468 - auc: 0.6513 - val_loss: 0.6393 - val_auc: 0.7251 - 8s/epoch - 99ms/step\n",
            "Epoch 17/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6519 - val_loss: 0.6385 - val_auc: 0.7279 - 8s/epoch - 99ms/step\n",
            "Epoch 18/500\n",
            "81/81 - 8s - loss: 0.0467 - auc: 0.6526 - val_loss: 0.6372 - val_auc: 0.7228 - 8s/epoch - 99ms/step\n",
            "Epoch 19/500\n",
            "81/81 - 8s - loss: 0.0466 - auc: 0.6538 - val_loss: 0.6380 - val_auc: 0.7241 - 8s/epoch - 100ms/step\n",
            "Epoch 20/500\n",
            "81/81 - 8s - loss: 0.0464 - auc: 0.6557 - val_loss: 0.6362 - val_auc: 0.7225 - 8s/epoch - 98ms/step\n",
            "Epoch 21/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6587 - val_loss: 0.6331 - val_auc: 0.7212 - 8s/epoch - 99ms/step\n",
            "Epoch 22/500\n",
            "81/81 - 8s - loss: 0.0463 - auc: 0.6546 - val_loss: 0.6331 - val_auc: 0.7191 - 8s/epoch - 97ms/step\n",
            "Epoch 23/500\n",
            "81/81 - 8s - loss: 0.0461 - auc: 0.6606 - val_loss: 0.6327 - val_auc: 0.7222 - 8s/epoch - 98ms/step\n",
            "Epoch 24/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6636 - val_loss: 0.6303 - val_auc: 0.7193 - 8s/epoch - 98ms/step\n",
            "Epoch 25/500\n",
            "81/81 - 8s - loss: 0.0460 - auc: 0.6613 - val_loss: 0.6319 - val_auc: 0.7181 - 8s/epoch - 99ms/step\n",
            "Epoch 26/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6650 - val_loss: 0.6314 - val_auc: 0.7155 - 8s/epoch - 98ms/step\n",
            "Epoch 27/500\n",
            "81/81 - 8s - loss: 0.0458 - auc: 0.6667 - val_loss: 0.6294 - val_auc: 0.7145 - 8s/epoch - 100ms/step\n",
            "Epoch 28/500\n",
            "81/81 - 8s - loss: 0.0457 - auc: 0.6667 - val_loss: 0.6281 - val_auc: 0.7137 - 8s/epoch - 97ms/step\n",
            "Epoch 29/500\n",
            "81/81 - 8s - loss: 0.0456 - auc: 0.6696 - val_loss: 0.6270 - val_auc: 0.7147 - 8s/epoch - 97ms/step\n",
            "Epoch 30/500\n",
            "81/81 - 8s - loss: 0.0455 - auc: 0.6732 - val_loss: 0.6258 - val_auc: 0.7126 - 8s/epoch - 98ms/step\n",
            "Epoch 31/500\n",
            "81/81 - 8s - loss: 0.0454 - auc: 0.6720 - val_loss: 0.6242 - val_auc: 0.7125 - 8s/epoch - 98ms/step\n",
            "Epoch 32/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6759 - val_loss: 0.6226 - val_auc: 0.7125 - 8s/epoch - 99ms/step\n",
            "Epoch 33/500\n",
            "81/81 - 8s - loss: 0.0452 - auc: 0.6750 - val_loss: 0.6234 - val_auc: 0.7110 - 8s/epoch - 97ms/step\n",
            "Epoch 34/500\n",
            "81/81 - 8s - loss: 0.0451 - auc: 0.6764 - val_loss: 0.6228 - val_auc: 0.7095 - 8s/epoch - 97ms/step\n",
            "Epoch 35/500\n",
            "81/81 - 8s - loss: 0.0449 - auc: 0.6817 - val_loss: 0.6202 - val_auc: 0.7103 - 8s/epoch - 98ms/step\n",
            "Epoch 36/500\n",
            "81/81 - 8s - loss: 0.0449 - auc: 0.6828 - val_loss: 0.6182 - val_auc: 0.7091 - 8s/epoch - 98ms/step\n",
            "Epoch 37/500\n",
            "81/81 - 8s - loss: 0.0446 - auc: 0.6891 - val_loss: 0.6157 - val_auc: 0.7098 - 8s/epoch - 103ms/step\n",
            "Epoch 38/500\n",
            "81/81 - 8s - loss: 0.0447 - auc: 0.6861 - val_loss: 0.6174 - val_auc: 0.7086 - 8s/epoch - 99ms/step\n",
            "Epoch 39/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6893 - val_loss: 0.6158 - val_auc: 0.7077 - 8s/epoch - 101ms/step\n",
            "Epoch 40/500\n",
            "81/81 - 8s - loss: 0.0445 - auc: 0.6875 - val_loss: 0.6159 - val_auc: 0.7053 - 8s/epoch - 99ms/step\n",
            "Epoch 41/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6891 - val_loss: 0.6152 - val_auc: 0.7060 - 8s/epoch - 98ms/step\n",
            "Epoch 42/500\n",
            "81/81 - 8s - loss: 0.0443 - auc: 0.6926 - val_loss: 0.6131 - val_auc: 0.7035 - 8s/epoch - 98ms/step\n",
            "Epoch 43/500\n",
            "81/81 - 8s - loss: 0.0442 - auc: 0.6933 - val_loss: 0.6130 - val_auc: 0.7038 - 8s/epoch - 99ms/step\n",
            "Epoch 44/500\n",
            "81/81 - 8s - loss: 0.0441 - auc: 0.6947 - val_loss: 0.6119 - val_auc: 0.7028 - 8s/epoch - 99ms/step\n",
            "Epoch 45/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.6972 - val_loss: 0.6103 - val_auc: 0.7027 - 8s/epoch - 98ms/step\n",
            "Epoch 46/500\n",
            "81/81 - 8s - loss: 0.0439 - auc: 0.6967 - val_loss: 0.6100 - val_auc: 0.7035 - 8s/epoch - 98ms/step\n",
            "Epoch 47/500\n",
            "81/81 - 8s - loss: 0.0438 - auc: 0.7020 - val_loss: 0.6100 - val_auc: 0.7035 - 8s/epoch - 99ms/step\n",
            "Epoch 48/500\n",
            "81/81 - 8s - loss: 0.0436 - auc: 0.7042 - val_loss: 0.6076 - val_auc: 0.7016 - 8s/epoch - 98ms/step\n",
            "Epoch 49/500\n",
            "81/81 - 8s - loss: 0.0437 - auc: 0.7021 - val_loss: 0.6092 - val_auc: 0.7014 - 8s/epoch - 99ms/step\n",
            "Epoch 50/500\n",
            "81/81 - 8s - loss: 0.0435 - auc: 0.7058 - val_loss: 0.6083 - val_auc: 0.6990 - 8s/epoch - 99ms/step\n",
            "Epoch 51/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7069 - val_loss: 0.6065 - val_auc: 0.6991 - 8s/epoch - 98ms/step\n",
            "Epoch 52/500\n",
            "81/81 - 8s - loss: 0.0434 - auc: 0.7076 - val_loss: 0.6073 - val_auc: 0.6971 - 8s/epoch - 97ms/step\n",
            "Epoch 53/500\n",
            "81/81 - 8s - loss: 0.0431 - auc: 0.7101 - val_loss: 0.6051 - val_auc: 0.6974 - 8s/epoch - 98ms/step\n",
            "Epoch 54/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7134 - val_loss: 0.6058 - val_auc: 0.6947 - 8s/epoch - 99ms/step\n",
            "Epoch 55/500\n",
            "81/81 - 8s - loss: 0.0430 - auc: 0.7125 - val_loss: 0.6061 - val_auc: 0.6949 - 8s/epoch - 97ms/step\n",
            "Epoch 56/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7177 - val_loss: 0.6055 - val_auc: 0.6929 - 8s/epoch - 98ms/step\n",
            "Epoch 57/500\n",
            "81/81 - 8s - loss: 0.0428 - auc: 0.7178 - val_loss: 0.6059 - val_auc: 0.6916 - 8s/epoch - 97ms/step\n",
            "Epoch 58/500\n",
            "81/81 - 8s - loss: 0.0426 - auc: 0.7209 - val_loss: 0.6030 - val_auc: 0.6922 - 8s/epoch - 98ms/step\n",
            "Epoch 59/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7236 - val_loss: 0.6047 - val_auc: 0.6892 - 8s/epoch - 98ms/step\n",
            "Epoch 60/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7247 - val_loss: 0.6013 - val_auc: 0.6887 - 8s/epoch - 98ms/step\n",
            "Epoch 61/500\n",
            "81/81 - 8s - loss: 0.0424 - auc: 0.7210 - val_loss: 0.6041 - val_auc: 0.6881 - 8s/epoch - 99ms/step\n",
            "Epoch 62/500\n",
            "81/81 - 8s - loss: 0.0422 - auc: 0.7247 - val_loss: 0.6007 - val_auc: 0.6880 - 8s/epoch - 98ms/step\n",
            "Epoch 63/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7319 - val_loss: 0.5998 - val_auc: 0.6865 - 8s/epoch - 98ms/step\n",
            "Epoch 64/500\n",
            "81/81 - 8s - loss: 0.0419 - auc: 0.7293 - val_loss: 0.5999 - val_auc: 0.6851 - 8s/epoch - 98ms/step\n",
            "Epoch 65/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7360 - val_loss: 0.5982 - val_auc: 0.6842 - 8s/epoch - 98ms/step\n",
            "Epoch 66/500\n",
            "81/81 - 8s - loss: 0.0416 - auc: 0.7347 - val_loss: 0.5996 - val_auc: 0.6821 - 8s/epoch - 99ms/step\n",
            "Epoch 67/500\n",
            "81/81 - 8s - loss: 0.0414 - auc: 0.7391 - val_loss: 0.5943 - val_auc: 0.6814 - 8s/epoch - 99ms/step\n",
            "Epoch 68/500\n",
            "81/81 - 8s - loss: 0.0412 - auc: 0.7413 - val_loss: 0.5965 - val_auc: 0.6786 - 8s/epoch - 98ms/step\n",
            "Epoch 69/500\n",
            "81/81 - 8s - loss: 0.0413 - auc: 0.7424 - val_loss: 0.5952 - val_auc: 0.6780 - 8s/epoch - 99ms/step\n",
            "Epoch 70/500\n",
            "81/81 - 8s - loss: 0.0412 - auc: 0.7414 - val_loss: 0.6000 - val_auc: 0.6770 - 8s/epoch - 99ms/step\n",
            "Epoch 71/500\n",
            "81/81 - 8s - loss: 0.0410 - auc: 0.7465 - val_loss: 0.5918 - val_auc: 0.6767 - 8s/epoch - 99ms/step\n",
            "Epoch 72/500\n",
            "81/81 - 8s - loss: 0.0408 - auc: 0.7496 - val_loss: 0.5943 - val_auc: 0.6752 - 8s/epoch - 104ms/step\n",
            "Epoch 73/500\n",
            "81/81 - 8s - loss: 0.0405 - auc: 0.7534 - val_loss: 0.5948 - val_auc: 0.6734 - 8s/epoch - 100ms/step\n",
            "Epoch 74/500\n",
            "81/81 - 8s - loss: 0.0405 - auc: 0.7529 - val_loss: 0.5948 - val_auc: 0.6725 - 8s/epoch - 99ms/step\n",
            "Epoch 75/500\n",
            "81/81 - 8s - loss: 0.0404 - auc: 0.7517 - val_loss: 0.5922 - val_auc: 0.6713 - 8s/epoch - 97ms/step\n",
            "Epoch 76/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7529 - val_loss: 0.5933 - val_auc: 0.6696 - 8s/epoch - 98ms/step\n",
            "Epoch 77/500\n",
            "81/81 - 8s - loss: 0.0403 - auc: 0.7530 - val_loss: 0.5952 - val_auc: 0.6700 - 8s/epoch - 100ms/step\n",
            "Epoch 78/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7567 - val_loss: 0.5919 - val_auc: 0.6684 - 8s/epoch - 99ms/step\n",
            "Epoch 79/500\n",
            "81/81 - 8s - loss: 0.0400 - auc: 0.7581 - val_loss: 0.5949 - val_auc: 0.6685 - 8s/epoch - 99ms/step\n",
            "Epoch 80/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7578 - val_loss: 0.5932 - val_auc: 0.6659 - 8s/epoch - 97ms/step\n",
            "Epoch 81/500\n",
            "81/81 - 8s - loss: 0.0399 - auc: 0.7581 - val_loss: 0.5946 - val_auc: 0.6643 - 8s/epoch - 98ms/step\n",
            "Epoch 82/500\n",
            "81/81 - 8s - loss: 0.0397 - auc: 0.7572 - val_loss: 0.5972 - val_auc: 0.6641 - 8s/epoch - 99ms/step\n",
            "Epoch 83/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7657 - val_loss: 0.5914 - val_auc: 0.6635 - 8s/epoch - 98ms/step\n",
            "Epoch 84/500\n",
            "81/81 - 8s - loss: 0.0393 - auc: 0.7650 - val_loss: 0.5944 - val_auc: 0.6646 - 8s/epoch - 98ms/step\n",
            "Epoch 85/500\n",
            "81/81 - 8s - loss: 0.0394 - auc: 0.7633 - val_loss: 0.5941 - val_auc: 0.6619 - 8s/epoch - 99ms/step\n",
            "Epoch 86/500\n",
            "81/81 - 8s - loss: 0.0391 - auc: 0.7697 - val_loss: 0.5923 - val_auc: 0.6614 - 8s/epoch - 99ms/step\n",
            "Epoch 87/500\n",
            "81/81 - 8s - loss: 0.0390 - auc: 0.7694 - val_loss: 0.5920 - val_auc: 0.6625 - 8s/epoch - 98ms/step\n",
            "Epoch 88/500\n",
            "81/81 - 8s - loss: 0.0389 - auc: 0.7698 - val_loss: 0.5897 - val_auc: 0.6609 - 8s/epoch - 97ms/step\n",
            "Epoch 89/500\n",
            "81/81 - 8s - loss: 0.0386 - auc: 0.7740 - val_loss: 0.5920 - val_auc: 0.6603 - 8s/epoch - 96ms/step\n",
            "Epoch 90/500\n",
            "81/81 - 8s - loss: 0.0387 - auc: 0.7723 - val_loss: 0.5948 - val_auc: 0.6600 - 8s/epoch - 97ms/step\n",
            "Epoch 91/500\n",
            "81/81 - 8s - loss: 0.0386 - auc: 0.7744 - val_loss: 0.5891 - val_auc: 0.6603 - 8s/epoch - 98ms/step\n",
            "Epoch 92/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7804 - val_loss: 0.5914 - val_auc: 0.6603 - 8s/epoch - 99ms/step\n",
            "Epoch 93/500\n",
            "81/81 - 8s - loss: 0.0382 - auc: 0.7806 - val_loss: 0.5875 - val_auc: 0.6617 - 8s/epoch - 98ms/step\n",
            "Epoch 94/500\n",
            "81/81 - 8s - loss: 0.0381 - auc: 0.7788 - val_loss: 0.5901 - val_auc: 0.6614 - 8s/epoch - 97ms/step\n",
            "Epoch 95/500\n",
            "81/81 - 8s - loss: 0.0380 - auc: 0.7825 - val_loss: 0.5880 - val_auc: 0.6595 - 8s/epoch - 99ms/step\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "test set:\n",
            "23/23 [==============================] - 2s 37ms/step - loss: 0.6473 - auc: 0.6206\n",
            " \n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "-\n",
            "val set:\n",
            "9/9 [==============================] - 1s 39ms/step - loss: 0.6468 - auc: 0.7345\n",
            "Saving model...\n",
            "Saving files...\n",
            "FINISHED CYCLE NUMBER: 10\n",
            "\n",
            "CV Test AUC----------------------------\n",
            "Individual scores: [0.6836272478103638, 0.6699686050415039, 0.6256222128868103, 0.6246102452278137, 0.7018936276435852, 0.6614848375320435, 0.678069531917572, 0.6290812492370605, 0.6872913837432861, 0.6206453442573547]\n",
            "Mean: 0.6582294285297394\n",
            "std: 0.02897223524209062\n",
            "\n",
            "CV Val AUC-----------------------------\n",
            "Individual scores: [0.573874294757843, 0.6731975078582764, 0.6190398931503296, 0.6732228398323059, 0.7420203685760498, 0.6850412487983704, 0.6743444204330444, 0.6702035665512085, 0.6735681295394897, 0.7345088124275208]\n",
            "Mean: 0.6719021081924439\n",
            "std: 0.04629008620478762\n",
            "CPU times: user 29min 53s, sys: 5min 8s, total: 35min 1s\n",
            "Wall time: 3h 23min 16s\n"
          ]
        }
      ],
      "source": [
        "#@title K-Fold CV Model \n",
        "%%time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Global Score List Buckets\n",
        "cv_test_scores=[]\n",
        "cv_val_scores=[]\n",
        "\n",
        "# K fold parameters \n",
        "seed = 7\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "# run K-fold \n",
        "count = 1\n",
        "for train, val in kfold.split(X_train, y_train):\n",
        "  \n",
        "  # Create New Training Set \n",
        "  X_training = X_train[train]\n",
        "  y_training = y_train[train]\n",
        "  # Create new Validation Sets \n",
        "  X_val = X_train[val]\n",
        "  y_val = y_train[val]\n",
        "\n",
        "  # Reset model \n",
        "  print(\"Resetting model..\")\n",
        "  reset_model()\n",
        "  # Fit model\n",
        "  fit_model(X_training, y_training, X_val, y_val)\n",
        "  # Eval model \n",
        "  model_eval()\n",
        "  # Save model \n",
        "  print(\"Saving model...\")\n",
        "  save_model(count)\n",
        "  # Save files\n",
        "  print(\"Saving files...\")\n",
        "  save_files(count)\n",
        "\n",
        "  # increment \n",
        "  print(\"FINISHED CYCLE NUMBER:\", count)\n",
        "  count += 1 \n",
        "\n",
        "# Score Eval\n",
        "print(\"\\nCV Test AUC----------------------------\")\n",
        "print(\"Individual scores:\", cv_test_scores)\n",
        "print(\"Mean:\", np.mean(cv_test_scores))\n",
        "print(\"std:\", np.std(cv_test_scores))\n",
        "print(\"\\nCV Val AUC-----------------------------\")\n",
        "print(\"Individual scores:\", cv_val_scores)\n",
        "print(\"Mean:\", np.mean(cv_val_scores))\n",
        "print(\"std:\", np.std(cv_val_scores))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yJesTgXd6zS"
      },
      "source": [
        "#Note for future \n",
        "- Analyze hdf5 files for SHAP analysis\n",
        "- Analyze data files (pred, train, test, val) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "IzzQjVsLRRuR",
        "6yx1mlI3TEV5",
        "MK6Ia1wXX1aQ"
      ],
      "name": "K-Fold CV Stacked Conv-LSTM.ipynb",
      "provenance": [],
      "mount_file_id": "1e_ug8NIzU7c7IeuuQaCHE_QSyZV30XX3",
      "authorship_tag": "ABX9TyOcYSKFkhJDNck6eqn1Q3UT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}